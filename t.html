<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>交互式面试背诵手册 (AI增强版 - 完整内容)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .sidebar {
            width: 280px;
            transition: transform 0.3s ease-in-out;
        }
        .content-area {
            margin-left: 280px;
            transition: margin-left 0.3s ease-in-out;
        }
        .sidebar-collapsed .sidebar {
            transform: translateX(-100%);
        }
        .sidebar-collapsed .content-area {
            margin-left: 0;
        }
        .answer {
            display: none;
            border-left: 3px solid #38bdf8; /* sky-500 */
            transition: max-height 0.5s ease-in-out, opacity 0.5s ease-in-out;
            max-height: 0;
            opacity: 0;
            overflow: hidden;
        }
        .answer.active {
            display: block;
            max-height: 3000px; /* Increased for potentially longer answers */
            opacity: 1;
        }
        .code-block {
            background-color: #1e293b; /* slate-800 */
            color: #e2e8f0; /* slate-200 */
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.875rem;
            line-height: 1.5;
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
        .code-block code {
            white-space: pre;
        }
        .sidebar-link.active {
            background-color: #0ea5e9; /* sky-600 */
            color: white;
        }
        .difficulty-star {
            color: #fbbf24; /* amber-400 */
        }
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #f1f5f9; /* slate-100 */
            border-radius: 10px;
        }
        ::-webkit-scrollbar-thumb {
            background: #94a3b8; /* slate-400 */
            border-radius: 10px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #64748b; /* slate-500 */
        }
        .ai-button {
            background-color: #7dd3fc; /* sky-300 */
            color: #0c4a6e; /* sky-900 */
            padding: 0.25rem 0.5rem;
            border-radius: 0.375rem;
            font-size: 0.75rem;
            line-height: 1rem;
            transition: background-color 0.2s;
            margin-left: 0.5rem;
            border: none;
            cursor: pointer;
        }
        .ai-button:hover {
            background-color: #38bdf8; /* sky-500 */
        }
        .modal {
            background-color: rgba(0,0,0,0.5);
            transition: opacity 0.3s ease;
        }
        .modal-content {
            max-height: 80vh;
        }
        .spinner {
            border-top-color: #38bdf8; /* sky-500 */
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        .answer p, .answer ol, .answer ul, .answer table { margin-bottom: 0.75rem; }
        .answer strong { font-weight: 600; }
        .answer table { border-collapse: collapse; width: auto; margin-top:1em; margin-bottom:1em;}
        .answer th, .answer td { border: 1px solid #cbd5e1; padding: 0.5rem; text-align: left;}
        .answer th { background-color: #f1f5f9; }
        .answer ul { list-style-type: disc; margin-left: 1.5rem;}
        .answer ol { list-style-type: decimal; margin-left: 1.5rem;}
        .answer li { margin-bottom: 0.25rem;}
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app-container" class="flex h-screen overflow-hidden">
        <nav id="sidebar" class="sidebar fixed top-0 left-0 h-full bg-slate-800 text-slate-100 p-4 overflow-y-auto shadow-lg z-20">
            <div class="flex justify-between items-center mb-6">
                <h1 class="text-xl font-semibold">面试手册目录</h1>
                <button id="toggle-sidebar-desktop" class="lg:hidden p-2 rounded-md hover:bg-slate-700 focus:outline-none focus:ring-2 focus:ring-slate-500">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
                    </svg>
                </button>
            </div>
            <ul id="chapter-nav-list" class="space-y-2"></ul>
        </nav>

        <main id="content-area" class="content-area flex-1 p-4 sm:p-6 lg:p-8 overflow-y-auto">
            <header class="mb-8 flex flex-col sm:flex-row justify-between items-start sm:items-center">
                <div class="flex items-center mb-4 sm:mb-0">
                    <button id="toggle-sidebar-mobile" class="lg:hidden mr-4 p-2 rounded-md bg-slate-200 hover:bg-slate-300 text-slate-700 focus:outline-none focus:ring-2 focus:ring-sky-500">
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6">
                          <path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
                        </svg>
                    </button>
                    <h2 id="current-chapter-title" class="text-2xl sm:text-3xl font-bold text-slate-700">欢迎使用面试背诵手册</h2>
                </div>
                 <div class="relative w-full sm:w-auto">
                    <input type="text" id="search-input" placeholder="搜索问题关键字..." class="px-4 py-2 border border-slate-300 rounded-lg focus:ring-2 focus:ring-sky-500 focus:border-sky-500 transition-all w-full sm:w-64">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 absolute right-3 top-1/2 transform -translate-y-1/2 text-slate-400">
                        <path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z" />
                    </svg>
                </div>
            </header>
            <div id="questions-container" class="space-y-6">
                <p class="text-slate-600 text-lg">请从左侧选择一个章节开始学习，或使用上方搜索框查找问题。</p>
            </div>
             <p id="no-results-message" class="text-slate-600 text-lg hidden">未找到匹配的问题。</p>
        </main>
    </div>

    <div id="ai-modal" class="modal fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center p-4 z-50 hidden">
        <div class="modal-content bg-white p-6 rounded-lg shadow-xl w-full max-w-2xl overflow-y-auto">
            <div class="flex justify-between items-center mb-4">
                <h3 id="ai-modal-title" class="text-xl font-semibold text-slate-700">AI助手</h3>
                <button id="close-ai-modal" class="p-2 rounded-md hover:bg-slate-200">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6 text-slate-600">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
                    </svg>
                </button>
            </div>
            <div id="ai-modal-body" class="text-slate-600 space-y-3 prose max-w-none">
            </div>
             <div id="ai-loading-spinner" class="hidden flex justify-center items-center py-8">
                <div class="spinner w-12 h-12 border-4 border-slate-200 rounded-full"></div>
            </div>
        </div>
    </div>

    <script>
        // 这个脚本应该尽可能早地执行，以防止未登录用户看到页面内容
        (function() {
            // 从 localStorage 获取之前在 index.html 登录成功时设置的标记
            const isLoggedIn = localStorage.getItem('isLoggedIn');
            const loggedInUser = localStorage.getItem('loggedInUser'); // 同时获取用户名，确保不是伪造的isLoggedIn

            // 检查登录状态
            // 在真实的生产环境中，这里应该向后端发送一个请求来验证会话/token的有效性
            if (isLoggedIn !== 'true' || !loggedInUser) { 
                // 如果 'isLoggedIn' 不存在、不为 'true'，或者没有 'loggedInUser'，则认为未登录
                alert("您尚未登录或登录已过期，将跳转到登录页面。");
                // 执行重定向到登录页面
                // 确保 index.html 与 t.html 在同一目录下或使用正确的相对/绝对路径
                window.location.href = 'index.html'; 
            } else {
                // 如果已登录，可以在控制台输出信息，或者在页面上显示欢迎信息
                console.log(`用户 '${loggedInUser}' 已登录，允许访问。`);
                
                // 可选：在页面DOM加载完成后，显示欢迎信息
                // 这部分可以根据你的HTML结构调整
                // document.addEventListener('DOMContentLoaded', function() {
                //     const welcomeMessageElement = document.getElementById('welcome-user-message'); // 假设你有一个ID为welcome-user-message的元素
                //     if (welcomeMessageElement) {
                //         welcomeMessageElement.textContent = `欢迎您，${loggedInUser}！`;
                //     }
                // });
            }
        })(); // 立即执行函数 (IIFE)，确保脚本加载后立即运行
        const manualData = [
            {
                "chapterTitle": "第一章-Java基础篇",
    "questions": [
        {
            "id": "java-basic-1",
            "question": "1、你是怎样理解OOP面向对象",
            "difficulty": "★",
            "answer": "<p>面向对象是利用语言对现实事物进行抽象的过程，使得程序设计更符合人的思维方式。面向对象具有以下核心特征：</p><ol><li><strong>继承 (Inheritance)</strong>: 继承是从已有类（父类或超类）得到信息创建新类（子类或派生类）的过程。子类可以继承父类的属性和方法，并可以添加自己的特性或重写父类的方法，实现了代码的复用和扩展。</li><li><strong>封装 (Encapsulation)</strong>: 封装是把数据（属性）和操作数据的方法（函数）捆绑在一起，形成一个独立的单元（即对象）。对象对外部隐藏其内部实现细节，只通过已定义的接口（公共方法）与外部交互，从而保护了数据的安全性和完整性，也提高了模块的可维护性。</li><li><strong>多态性 (Polymorphism)</strong>: 多态性是指允许不同子类型的对象对同一消息（方法调用）作出不同的响应。它主要通过方法的重写（override）和重载（overload）以及接口实现来实现。多态性增强了程序的灵活性和可扩展性。</li></ol>"
        },
        {
            "id": "java-basic-2",
            "question": "2、重载与重写区别",
            "difficulty": "★",
            "answer": "<p>重载（Overloading）和重写（Overriding）是Java中多态性的两种体现，它们的主要区别如下：</p><ol><li><strong>发生范围</strong>:<ul><li>重载：发生在本类中，一个类可以有多个同名方法。</li><li>重写：发生在父类与子类之间，子类重新定义父类中已有的方法。</li></ul></li><li><strong>方法签名</strong>:<ul><li>重载：方法名必须相同，但参数列表必须不同（参数的类型、个数或顺序至少有一项不同）。返回值类型可以相同也可以不同，但仅有返回值类型不同不足以构成重载。</li><li>重写：方法名、参数列表必须与父类中被重写的方法完全相同。 返回值类型必须与父类相同或者是其子类（从JDK 1.5开始，称为协变返回类型）。抛出的异常类型必须与父类相同或者是其子类，或者不抛出异常。</li></ul></li><li><strong>访问权限</strong>:<ul><li>重载：对访问权限没有特殊要求。</li><li>重写：子类重写方法的访问权限不能比父类中被重写的方法的访问权限更低（例如，父类是protected，子类可以是protected或public，但不能是private）。</li></ul></li><li><strong>构造方法</strong>:<ul><li>构造方法可以被重载，但不能被重写。</li></ul></li><li><strong>静态方法与私有方法</strong>:<ul><li>静态方法可以被重载，但不能被重写（子类中定义同名同参的静态方法，这叫隐藏或重新定义，不属于重写）。</li><li>私有方法不能被重写，因为它们在子类中不可见。</li></ul></li></ol>"
        },
        {
            "id": "java-basic-3",
            "question": "3、接口与抽象类的区别",
            "difficulty": "★",
            "answer": "<p>接口（Interface）和抽象类（Abstract Class）都是Java中实现抽象的方式，但它们之间存在一些关键区别：</p><ol><li><strong>继承/实现方式</strong>:<ul><li>抽象类：一个类只能单继承一个抽象类（Java是单继承）。 子类使用<code>extends</code>关键字继承抽象类。</li><li>接口：一个类可以实现多个接口。 类使用<code>implements</code>关键字实现接口。接口之间可以多继承接口。</li></ul></li><li><strong>构造器</strong>:<ul><li>抽象类：可以有构造器，主要用于被子类调用以完成父类的初始化。 但抽象类本身不能被实例化。</li><li>接口：不能有构造器。</li></ul></li><li><strong>成员变量</strong>:<ul><li>抽象类：可以有普通成员变量（实例变量、静态变量），可以是各种访问修饰符，可以有常量。</li><li>接口：成员变量默认且只能是<code>public static final</code>常量（即编译时常量），必须在声明时初始化。 (Java 8 以后接口可以有静态方法和默认方法，但成员变量规则不变)</li></ul></li><li><strong>方法</strong>:<ul><li>抽象类：可以包含抽象方法（没有方法体，用<code>abstract</code>修饰）和具体方法（有方法体）。子类继承抽象类后，必须实现所有抽象方法，除非子类也是抽象类。抽象方法可以有<code>public</code>、<code>protected</code>和<code>default</code>修饰符。</li><li>接口：在Java 8之前，所有方法默认都是<code>public abstract</code>的（可以省略修饰符）。实现接口的类必须实现所有方法。在Java 8之后，接口可以包含<code>default</code>方法（默认方法，有方法体）和<code>static</code>方法（静态方法，有方法体）。Java 9之后还可以有私有方法。接口中的抽象方法只能是<code>public</code>。</li></ul></li><li><strong>设计目的</strong>:<ul><li>抽象类：主要用于代码复用和体现is-a关系（例如，Dog is an Animal）。当多个相关的类有共同的行为和属性时，可以将这些共性提取到抽象类中。它更像一个不完整的类，等待子类去具体化。</li><li>接口：主要用于定义契约或规范（can-do关系，例如 Bird can Fly）。它定义了一组类应该遵守的行为，而不关心具体的实现。接口更侧重于行为的抽象。</li></ul></li><li><strong>与普通类的关系</strong>:<ul><li>抽象类：除了不能实例化之外，它和普通Java类在结构上没有本质区别。</li></ul></li></ol>"
        },
        {
            "id": "java-basic-4",
            "question": "4、深拷贝与浅拷贝的理解",
            "difficulty": "★",
            "answer": "<p>深拷贝（Deep Copy）和浅拷贝（Shallow Copy）是指对象的复制行为，特别是当对象内部包含对其他对象的引用时，这两种拷贝方式表现不同。</p><p>一个对象中通常存在两种类型的属性：一种是基本数据类型（如int, boolean等），另一种是引用数据类型（即实例对象的引用）。</p><ol><li><strong>浅拷贝 (Shallow Copy)</strong>:<ul><li>浅拷贝在复制对象时，对于基本数据类型的属性，会直接复制其值。</li><li>对于引用数据类型的属性，只会复制引用地址（内存地址），而不会复制引用所指向的对象本身。</li><li>因此，拷贝出来的对象和原始对象内部的引用类型属性将指向堆内存中同一个对象。 如果通过一个副本修改了这个共享对象的内容，那么另一个副本中对应的引用属性也会反映这个变化。</li><li>Java中<code>Object</code>类的<code>clone()</code>方法默认执行的是浅拷贝。</li></ul></li><li><strong>深拷贝 (Deep Copy)</strong>:<ul><li>深拷贝在复制对象时，对于基本数据类型的属性，同样会直接复制其值。</li><li>对于引用数据类型的属性，深拷贝不仅会复制引用地址，还会递归地复制引用地址所指向的对象本身，以及这个对象内部可能包含的其他引用对象，直到所有层级的对象都被新复制一份。</li><li>因此，拷贝出来的对象和原始对象内部的引用类型属性将指向堆内存中完全独立的、内容相同的新对象。 修改一个副本中的引用对象内容，不会影响另一个副本。</li><li>实现深拷贝通常需要自定义逻辑，例如重写<code>clone()</code>方法并对内部的引用对象也进行<code>clone()</code>调用，或者通过序列化和反序列化来实现。</li></ul></li></ol><p><strong>总结：</strong>主要区别在于处理对象内部的引用类型属性时，浅拷贝只复制引用，深拷贝会创建引用的新副本。</p>"
        },
        {
            "id": "java-basic-5",
            "question": "5、sleep和wait区别",
            "difficulty": "★",
            "answer": "<p><code>sleep()</code> 和 <code>wait()</code> 都是Java中用于线程控制的方法，但它们有本质的区别：</p><ol><li><strong><code>sleep</code>方法</strong>:<ul><li>属于<code>Thread</code>类中的静态方法 (<code>Thread.sleep(long millis)</code>)。</li><li>调用<code>sleep()</code>方法会使当前线程暂停执行指定的毫秒数，进入限时等待状态（TIMED_WAITING）。</li><li>在<code>sleep()</code>期间，线程**不会释放它所持有的任何对象锁（监视器锁）**。 其他线程无法进入该锁保护的同步代码块。</li><li><code>sleep()</code>时间到达后，线程会自动转换到就绪（RUNNABLE）状态，等待CPU调度。</li><li><code>sleep()</code>可以被<code>interrupt()</code>方法中断，中断时会抛出<code>InterruptedException</code>。</li></ul></li><li><strong><code>wait</code>方法</strong>:<ul><li>属于<code>Object</code>类中的实例方法 (<code>wait()</code>, <code>wait(long timeout)</code>, <code>wait(long timeout, int nanos)</code>)。</li><li>调用<code>wait()</code>方法必须在当前线程已经持有该对象的锁（即在<code>synchronized</code>代码块或方法中针对该对象加锁）的前提下进行，否则会抛出<code>IllegalMonitorStateException</code>。</li><li>执行<code>wait()</code>后，当前线程会**立即释放它所持有的该对象的锁**，并进入等待状态（WAITING 或 TIMED_WAITING，取决于是否带超时参数）。 这允许其他线程获取该对象的锁并执行同步代码。</li><li>线程会一直等待，直到其他线程调用相同对象上的<code>notify()</code>或<code>notifyAll()</code>方法将其唤醒，或者（如果使用了带超时的<code>wait</code>）等待时间超时。</li><li>被唤醒或超时后，线程并不会立即继续执行，而是会重新尝试获取该对象的锁。只有成功获取锁后，才能从<code>wait()</code>方法返回并继续执行。</li><li><code>wait()</code>也可以被<code>interrupt()</code>方法中断，中断时同样会抛出<code>InterruptedException</code>，并且在抛出异常前会清除中断状态并尝试重新获取锁。</li></ul></li></ol><p><strong>释放时机代码演示 (根据PDF Page 5, 10-11 补充):</strong></p><div class=\"code-block\"><code>import java.time.LocalDateTime;\n\npublic class SleepWaitDemo {\n    public static void main(String[] args) {\n        Object lock = new Object();\n\n        Thread threadA = new Thread(() -> {\n            synchronized (lock) {\n                System.out.println(\"Thread A 获取锁时间: \" + LocalDateTime.now() + \" 线程名称: \" + Thread.currentThread().getName());\n                try {\n                    System.out.println(\"Thread A 调用 lock.wait() 前\");\n                    // wait 会释放 lock 对象的锁\n                    lock.wait(2000); \n                    // 或者 Thread.sleep(2000); // sleep 不会释放 lock 对象的锁\n                    System.out.println(\"Thread A 从 wait() 返回/sleep结束，重新获取/持有锁时间: \" + LocalDateTime.now() + \" 线程名称: \" + Thread.currentThread().getName());\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(\"Thread A 释放锁时间: \" + LocalDateTime.now() + \" 线程名称: \" + Thread.currentThread().getName());\n            }\n        }, \"Thread A\");\n\n        Thread threadB = new Thread(() -> {\n            try {\n                // 确保Thread A先运行并进入等待\n                Thread.sleep(100); \n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            synchronized (lock) {\n                System.out.println(\"Thread B 获取锁时间: \" + LocalDateTime.now() + \" 线程名称: \" + Thread.currentThread().getName());\n                // 如果Thread A调用的是wait(), Thread B可以获取到锁\n                // 如果Thread A调用的是sleep(), Thread B会在此阻塞直到Thread A的sleep结束并释放锁\n                System.out.println(\"Thread B 执行完毕，准备释放锁时间: \" + LocalDateTime.now() + \" 线程名称: \" + Thread.currentThread().getName());\n                 lock.notifyAll(); // 尝试唤醒等待在lock对象上的线程\n            }\n        }, \"Thread B\");\n\n        threadA.start();\n        threadB.start();\n    }\n}</code></div>"
        },
        {
            "id": "java-basic-6",
            "question": "6、什么是自动拆装箱 int和Integer有什么区别",
            "difficulty": "★",
            "answer": "<p>Java中的基本数据类型（如<code>int</code>, <code>float</code>, <code>double</code>, <code>boolean</code>, <code>char</code>, <code>byte</code>等）不具备对象的特征，不能调用方法，也不能存入泛型集合中。 为了方便操作这些基本数据类型，Java为每种基本数据类型都提供了对应的包装类（Wrapper Class），例如<code>Integer</code>对应<code>int</code>。</p><p><strong>自动装箱 (Autoboxing) 和自动拆箱 (Unboxing):</strong></p><p>这是Java 5引入的特性，是一种语法糖，使得基本数据类型和其对应的包装类之间的转换更加便捷。</p><ol><li><strong>装箱 (Boxing)</strong>: 将基本数据类型自动转换成对应的包装类对象。 例如：<code>Integer i = 10;</code> (编译器会自动处理成 <code>Integer i = Integer.valueOf(10);</code>)</li><li><strong>拆箱 (Unboxing)</strong>: 将包装类对象自动转换成对应的基本数据类型的值。 例如：<code>int n = i;</code> (编译器会自动处理成 <code>int n = i.intValue();</code>)</li></ol><p><strong>为什么需要自动拆装箱?</strong></p><p>主要是为了方便在需要对象的上下文中使用基本数据类型，尤其是在Java集合框架中。例如，<code>List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();</code> 这个集合只能存放<code>Integer</code>对象，不能直接存放<code>int</code>基本类型。通过自动装箱，我们可以直接写<code>list.add(100);</code>，编译器会自动将<code>100</code>装箱成<code>Integer</code>对象。</p><p><strong>实现原理:</strong></p><p>自动拆装箱是Javac编译器的语法糖，底层实际上是通过调用包装类的<code>valueOf()</code>方法（装箱）和<code>xxxValue()</code>方法（如<code>intValue()</code>，拆箱）来实现的。</p><p><strong><code>int</code> 和 <code>Integer</code> 的区别:</strong></p><ol><li><strong>类型</strong>:<ul><li><code>Integer</code>是<code>int</code>的包装类，是一个对象（引用数据类型）。</li><li><code>int</code>是Java的一种基本数据类型。</li></ul></li><li><strong>存储方式</strong>:<ul><li><code>Integer</code>实际是对象的引用，当<code>new</code>一个<code>Integer</code>时，实际上是生成一个指针指向此对象；变量存储的是对象的内存地址。</li><li><code>int</code>则是直接存储数据值。</li></ul></li><li><strong>默认值</strong>:<ul><li><code>Integer</code>的默认值是<code>null</code>。</li><li><code>int</code>的默认值是<code>0</code>。</li></ul></li><li><strong>使用方式</strong>:<ul><li><code>Integer</code>变量必须实例化后才能使用（除非是<code>null</code>）。</li><li><code>int</code>变量不需要实例化。</li></ul></li><li><strong>比较</strong>:<ul><li><code>Integer</code>对象之间使用<code>==</code>比较的是内存地址（除非值在-128到127之间，这时会从缓存池中取对象，可能导致<code>==</code>为true）。比较内容应使用<code>equals()</code>方法。</li><li><code>int</code>之间使用<code>==</code>比较的是值。</li></ul></li><li><strong>泛型</strong>: <code>Integer</code>可以用作泛型参数，而<code>int</code>不能。</li></ol>"
        },
        {
            "id": "java-basic-7",
            "question": "7、==和equals区别",
            "difficulty": "★",
            "answer": "<p><code>==</code> 和 <code>equals()</code> 方法都用于比较，但它们的比较方式和适用场景有所不同：</p><ol><li><strong><code>==</code> 运算符</strong>:<ul><li><strong>比较基本数据类型</strong>: 当<code>==</code>用于比较基本数据类型（如 <code>int</code>, <code>char</code>, <code>boolean</code>, <code>float</code>, <code>double</code> 等）时，它比较的是变量所存储的**值**是否相等。</li><li><strong>比较引用数据类型</strong>: 当<code>==</code>用于比较引用数据类型（即对象，如 <code>String</code>, <code>Integer</code>, 自定义对象等）时，它比较的是这两个引用变量是否指向堆内存中的**同一个对象实例**，即比较的是它们的内存地址是否相同。</li></ul></li><li><strong><code>equals()</code> 方法</strong>:<ul><li><code>equals()</code>是<code>java.lang.Object</code>类中定义的一个方法，因此所有Java对象都继承了这个方法。</li><li><strong><code>Object</code>类中的默认实现</strong>: 在<code>Object</code>类中，<code>equals()</code>方法的默认实现就是使用<code>==</code>来比较两个对象的内存地址。源码如下：<div class=\"code-block\"><code>public boolean equals(Object obj) {\n    return (this == obj);\n}</code></div></li><li><strong>重写<code>equals()</code>方法</strong>: 很多类（如<code>String</code>, <code>Integer</code>, <code>Date</code>等包装类和集合类）都重写了<code>equals()</code>方法。重写后的<code>equals()</code>方法通常用于比较两个对象的**内容（或逻辑状态）**是否相等，而不是比较它们的内存地址。 例如，<code>String</code>类的<code>equals()</code>方法比较的是两个字符串的字符序列是否相同。</li><li><strong>自定义类中的<code>equals()</code></strong>: 当我们创建自定义类时，如果希望根据对象的属性内容来判断对象是否相等，就需要重写<code>equals()</code>方法。同时，按照Java规范，如果重写了<code>equals()</code>方法，通常也应该重写<code>hashCode()</code>方法，以保证相等的对象具有相同的哈希码，这对于在哈希集合（如<code>HashSet</code>, <code>HashMap</code>）中正确使用这些对象至关重要。</li></ul></li></ol><p><strong>总结：</strong></p><ul><li><code>==</code>: 对于基本类型比较值，对于引用类型比较内存地址。</li><li><code>equals()</code>: 默认行为同<code>==</code>（比较地址），但许多类重写它来比较对象内容。在比较对象内容是否相同时，应优先使用<code>equals()</code>方法，并确保其已被正确重写。</li></ul>"
        },
        {
            "id": "java-basic-8",
            "question": "8、String能被继承吗 为什么用final修饰",
            "difficulty": "★",
            "answer": "<ol><li><strong><code>String</code>类不能被继承</strong>，因为它被<code>final</code>关键字修饰。在Java中，被<code>final</code>修饰的类是最终类，不能有子类。</li><li><strong>为什么用<code>final</code>修饰<code>String</code>类？主要有以下原因：</strong><ul><li><strong>效率 (Efficiency)</strong>: <code>String</code>是最常用的类之一。Java运行时环境中的字符串常量池（String Pool）依赖于<code>String</code>对象的不可变性来共享字符串实例，从而节省内存和提高性能。如果<code>String</code>可以被继承，子类可能会改变其行为（例如，重写方法使得字符串内容可变），这将破坏字符串常量池的机制和<code>String</code>的不可变性保证，导致性能下降和潜在错误。禁止继承保证了<code>String</code>的行为是固定和可预测的。</li><li><strong>安全性 (Security)</strong>: 字符串在Java中广泛用于表示文件名、网络连接、安全凭证（如密码、令牌）等敏感信息。如果<code>String</code>可以被继承和修改，恶意子类可能会改变字符串的值或行为，从而绕过安全检查或导致安全漏洞。例如，一个方法可能依赖于一个特定的字符串值进行权限验证，如果这个字符串可以被子类修改，验证就可能被破坏。<code>final</code>修饰确保了<code>String</code>对象的不可变性和行为的确定性，有助于维护系统的安全性。 <code>String</code>类中有些方法是native的，调用了操作系统的API，如果可以被重写，可能植入恶意代码。</li><li><strong>保证哈希码的不可变性 (Immutable HashCode)</strong>: <code>String</code>对象经常被用作<code>HashMap</code>等哈希集合的键。<code>String</code>类重写了<code>hashCode()</code>方法，其哈希码是根据字符串内容计算的。由于<code>String</code>是不可变的，其内容一旦创建就不会改变，因此其哈希码也是固定的。这对于哈希集合的正确和高效运作至关重要。如果<code>String</code>可变，其哈希码可能会在对象存入集合后发生变化，导致无法在集合中正确定位该对象。</li></ul></li></ol><p>综上所述，将<code>String</code>类设计为<code>final</code>是为了保证其不可变性，从而带来性能、安全和哈希稳定性方面的好处。</p>"
        },
        {
            "id": "java-basic-9",
            "question": "9、String buffer和String builder区别",
            "difficulty": "★",
            "answer": "<p><code>StringBuffer</code> 和 <code>StringBuilder</code> 都是用于处理可变字符序列的类，它们提供了相似的API（如<code>append</code>, <code>insert</code>, <code>delete</code>, <code>substring</code>等），并且在功能上基本等价。 它们与不可变的<code>String</code>类不同，后者的内容一旦创建就不能更改，每次对<code>String</code>进行修改操作（如拼接）都会产生新的<code>String</code>对象。</p><p>它们的主要区别在于**线程安全性**和**性能**：</p><ol><li><strong><code>StringBuffer</code></strong>:<ul><li><strong>线程安全</strong>: <code>StringBuffer</code>中的大多数主要方法（如<code>append</code>, <code>insert</code>等）都使用了<code>synchronized</code>关键字进行修饰，因此它是线程安全的。 这意味着在多线程环境下，多个线程可以安全地同时访问同一个<code>StringBuffer</code>对象而不会导致数据不一致的问题。</li><li><strong>性能</strong>: 由于同步操作会带来额外的开销（如锁的获取和释放），所以在单线程环境下，或者在不需要线程安全的情况下，<code>StringBuffer</code>的性能通常会低于<code>StringBuilder</code>。</li></ul></li><li><strong><code>StringBuilder</code></strong>:<ul><li><strong>线程不安全</strong>: <code>StringBuilder</code>的方法没有进行同步处理，因此它不是线程安全的。 如果在多线程环境下共享一个<code>StringBuilder</code>对象并进行修改，可能会导致数据错乱或其他并发问题。</li><li><strong>性能</strong>: 由于没有同步开销，<code>StringBuilder</code>在单线程环境下的性能通常优于<code>StringBuffer</code>。</li></ul></li></ol><p><strong>选择依据：</strong></p><ul><li>如果在**单线程**环境下操作字符串缓冲区，或者能确保在多线程环境下该对象不会被多个线程并发修改（例如，对象是方法内的局部变量，或者通过其他同步机制保证了访问安全），那么应该优先选择<code>StringBuilder</code>，因为它具有更高的性能。</li><li>如果在**多线程**环境下，多个线程需要共享并修改同一个字符串缓冲区对象，那么应该使用<code>StringBuffer</code>来保证线程安全。</li></ul><p>在JDK 5.0中引入了<code>StringBuilder</code>，作为对<code>StringBuffer</code>在单线程性能方面的一个改进。在此之前，<code>StringBuffer</code>是处理可变字符串的唯一选择。</p>"
        },
        {
            "id": "java-basic-10",
            "question": "10 final finally、finalize",
            "difficulty": "★",
            "answer": "<p><code>final</code>, <code>finally</code>, 和 <code>finalize</code> 是Java中三个具有不同含义和用途的关键字或方法：</p><ol><li><strong><code>final</code> (关键字)</strong>:<ul><li><code>final</code> 是一个修饰符，可以用来修饰类、方法和变量。</li><li><strong>修饰类</strong>: 当<code>final</code>修饰一个类时，表示这个类是最终类，不能被继承。 因此，它与<code>abstract</code>关键字是互斥的。例如，<code>String</code>类就是<code>final</code>类。</li><li><strong>修饰方法</strong>: 当<code>final</code>修饰一个方法时，表示这个方法是最终方法，不能被子类重写（Override）。 这有助于保证方法行为的一致性。父类的私有方法默认是<code>final</code>的（因为子类不可见，自然无法重写）。</li><li><strong>修饰变量</strong>:<ul><li><strong>成员变量（实例变量或静态变量）</strong>: 如果被<code>final</code>修饰，表示该变量是一个常量，其值一旦被初始化后就不能再改变。 对于实例变量，必须在声明时、构造器中或实例初始化块中赋值；对于静态变量，必须在声明时或静态初始化块中赋值。</li><li><strong>局部变量</strong>: 如果被<code>final</code>修饰，表示该变量的值在初始化后不能被修改。</li><li><strong>引用变量</strong>: 如果一个引用变量被<code>final</code>修饰，表示这个引用变量不能再指向其他对象，但它所指向的对象的内容是可以改变的（除非对象本身也是不可变的）。</li></ul></li></ul></li><li><strong><code>finally</code> (关键字)</strong>:<ul><li><code>finally</code> 是异常处理机制中的一个关键字，用于定义一个代码块，该代码块**总是在<code>try...catch</code>结构执行完毕后执行**（无论<code>try</code>块中是否发生异常，以及发生的异常是否被<code>catch</code>块捕获）。</li><li>主要用途是确保某些资源（如文件流、数据库连接、网络套接字等）得到释放，即使在发生异常的情况下。</li><li>只有少数几种情况<code>finally</code>块不会执行：例如，在<code>try</code>或<code>catch</code>块中调用了<code>System.exit()</code>使JVM退出了；或者当前线程在执行<code>try</code>或<code>catch</code>块时被杀死或无限循环。</li></ul></li><li><strong><code>finalize()</code> (方法)</strong>:<ul><li><code>finalize()</code> 是定义在<code>java.lang.Object</code>类中的一个<code>protected</code>方法。</li><li>它的主要目的是允许对象在被垃圾收集器（Garbage Collector, GC）回收之前执行一些清理操作，例如释放该对象占用的本地资源（非Java堆内存资源，如文件句柄、本地内存分配等）。</li><li>当GC确定一个对象不再被引用并且准备回收它时，如果该对象重写了<code>finalize()</code>方法并且该方法之前没有被执行过，GC会调用该对象的<code>finalize()</code>方法（通常是在一个低优先级的专门线程中异步执行）。</li><li><strong>不推荐依赖<code>finalize()</code>进行资源清理</strong>：<ul><li><code>finalize()</code>的执行时机不确定，甚至不保证一定会执行（例如JVM退出时）。</li><li>它可能导致对象复活（在<code>finalize()</code>方法中重新建立对自身的强引用），使GC过程复杂化。</li><li>执行<code>finalize()</code>可能会带来性能开销。</li><li>Java 7引入了<code>try-with-resources</code>语句，Java 9引入了<code>Cleaner</code> API，这些是更推荐的资源管理方式，比<code>finalize()</code>更可靠和高效。</li></ul></li></ul></li></ol>"
        },
        {
            "id": "java-basic-11",
            "question": "11、Object中有哪些方法",
            "difficulty": "★",
            "answer": "<p><code>java.lang.Object</code> 类是Java中所有类的根类（直接或间接父类）。它提供了一些所有对象都应具备的基本方法。以下是<code>Object</code>类中定义的主要方法：</p><ol><li><strong><code>protected Object clone() throws CloneNotSupportedException</code></strong>:<ul><li>创建并返回此对象的一个副本（浅拷贝）。</li><li>要使一个类能够被克隆，该类必须实现<code>java.lang.Cloneable</code>标记接口，否则调用<code>clone()</code>会抛出<code>CloneNotSupportedException</code>。</li></ul></li><li><strong><code>boolean equals(Object obj)</code></strong>:<ul><li>指示某个其他对象是否与此对象“相等”。</li><li>默认实现是比较两个对象的内存地址（即 <code>this == obj</code>）。通常需要根据业务逻辑重写此方法来比较对象的内容。</li></ul></li><li><strong><code>protected void finalize() throws Throwable</code></strong>:<ul><li>当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法，用于对象被回收前的清理工作。 (如前所述，不推荐依赖此方法)</li></ul></li><li><strong><code>Class&lt;?&gt; getClass()</code></strong>:<ul><li>返回一个对象的运行时类。 返回的<code>Class</code>对象是被<code>static synchronized</code>方法锁定的对象。</li><li>这是一个<code>native</code>方法。</li></ul></li><li><strong><code>int hashCode()</code></strong>:<ul><li>返回该对象的哈希码值。</li><li>默认情况下，哈希码通常是通过将对象的内部地址转换成一个整数来实现的。如果重写了<code>equals()</code>方法，通常也必须重写<code>hashCode()</code>方法，以满足“相等的对象必须有相等的哈希码”这一约定。</li></ul></li><li><strong><code>void notify()</code></strong>:<ul><li>唤醒在此对象监视器（monitor）上等待的单个线程。</li><li>必须在当前线程持有该对象的锁时调用（即在<code>synchronized</code>块或方法中）。</li><li>具体唤醒哪个线程是不确定的。</li></ul></li><li><strong><code>void notifyAll()</code></strong>:<ul><li>唤醒在此对象监视器上等待的所有线程。</li><li>同样必须在当前线程持有该对象的锁时调用。</li></ul></li><li><strong><code>String toString()</code></strong>:<ul><li>返回该对象的字符串表示。</li><li>默认实现返回“类名@哈希码的十六进制表示”。通常建议重写此方法以提供更有意义的对象信息。</li></ul></li><li><strong><code>void wait() throws InterruptedException</code></strong>:<ul><li>导致当前的线程等待，直到其他线程调用此对象的<code>notify()</code>方法或<code>notifyAll()</code>方法，或者当前线程被中断。</li><li>必须在当前线程持有该对象的锁时调用，调用后会释放锁。</li></ul></li><li><strong><code>void wait(long timeout) throws InterruptedException</code></strong>:<ul><li>导致当前的线程等待，直到其他线程调用此对象的<code>notify()</code>方法或<code>notifyAll()</code>方法，或者超过指定的等待时间量（毫秒），或者当前线程被中断。</li></ul></li><li><strong><code>void wait(long timeout, int nanos) throws InterruptedException</code></strong>:<ul><li>导致当前的线程等待，直到其他线程调用此对象的<code>notify()</code>方法或<code>notifyAll()</code>方法，或者超过指定的等待时间量（毫秒+纳秒），或者当前线程被中断。 (纳秒参数的额外等待时间，范围0-999999)</li></ul></li></ol>"
        },
        {
            "id": "java-basic-12",
            "question": "12、说一下集合体系",
            "difficulty": "★",
            "answer": "<p>Java集合框架（Java Collections Framework, JCF）提供了一套性能优良、使用方便的接口和类，用于存储和操作对象集合。它主要位于<code>java.util</code>包下。</p><p>集合框架主要包括两大类接口：<code>Collection</code> 和 <code>Map</code>。</p><p><strong>1. <code>Collection</code> 接口</strong>: 是处理一组单个元素的根接口。其下有两个主要的子接口：</p><ul><li><strong><code>List</code> 接口</strong>:<ul><li>特点：有序集合（元素按插入顺序存储，或可按索引访问），允许包含重复元素。</li><li>可以通过索引访问元素。</li><li>主要实现类:<ul><li><code>ArrayList</code>: 基于动态数组实现。查询快（随机访问O(1)），增删慢（在非末尾位置增删涉及元素移动O(n)）。线程不安全。</li><li><code>LinkedList</code>: 基于双向链表实现。查询慢（顺序访问O(n)），增删快（尤其是在首尾O(1)）。线程不安全。还实现了<code>Deque</code>接口，可以作为队列或栈使用。</li><li><code>Vector</code>: (遗留类) 基于动态数组实现，与<code>ArrayList</code>类似，但是线程安全的（方法基本都用<code>synchronized</code>修饰），性能较低，一般不推荐使用。其子类<code>Stack</code>是栈的实现。</li></ul></li></ul></li><li><strong><code>Set</code> 接口</strong>:<ul><li>特点：无序集合（通常，不保证元素的排列顺序，但有些实现类可以保证），不允许包含重复元素。判断元素是否重复通常依赖元素的<code>equals()</code>和<code>hashCode()</code>方法。</li><li>主要实现类:<ul><li><code>HashSet</code>: 基于哈希表（内部使用<code>HashMap</code>的key来实现）实现。不能保证元素的排列顺序。允许存入一个<code>null</code>元素。查询、添加、删除操作的平均时间复杂度为O(1)。线程不安全。</li><li><code>LinkedHashSet</code>: 继承自<code>HashSet</code>，同时使用链表维护元素的插入顺序。因此，遍历<code>LinkedHashSet</code>时，元素会按照插入的顺序输出。性能略低于<code>HashSet</code>，但高于<code>TreeSet</code>。线程不安全。</li><li><code>TreeSet</code>: 基于红黑树（一种自平衡二叉查找树）实现。元素会进行自然排序（如果元素实现了<code>Comparable</code>接口）或者根据构造时传入的<code>Comparator</code>进行定制排序。不允许存入<code>null</code>元素（除非比较器支持）。查询、添加、删除操作的时间复杂度为O(log n)。线程不安全。</li></ul></li></ul></li><li><strong><code>Queue</code> 接口</strong>: (也是<code>Collection</code>的子接口)<ul><li>特点：队列，通常遵循先进先出（FIFO）的原则（但也有其他类型的队列如优先队列）。</li><li>主要实现类:<ul><li><code>LinkedList</code>: 实现了<code>Queue</code>接口，可作为FIFO队列。</li><li><code>PriorityQueue</code>: 优先队列，元素根据其自然顺序或比较器定义的顺序进行排序。</li><li><code>ArrayDeque</code>: 基于数组的双端队列，也可以用作栈或队列。</li></ul></li></ul></li></ul><p><strong>2. <code>Map</code> 接口</strong>: 是处理键值对（key-value pairs）映射关系的根接口。Key是唯一的，Value可以重复。</p><ul><li>主要实现类:<ul><li><code>HashMap</code>: 基于哈希表实现（JDK 1.8后为数组+链表/红黑树）。不能保证键值对的排列顺序。允许一个<code>null</code>键和多个<code>null</code>值。查询、添加、删除操作的平均时间复杂度为O(1)。线程不安全。</li><li><code>LinkedHashMap</code>: 继承自<code>HashMap</code>，同时使用双向链表维护键值对的插入顺序或访问顺序（取决于构造参数）。遍历时可以按插入顺序或最近最少使用（LRU）顺序输出。线程不安全。</li><li><code>TreeMap</code>: 基于红黑树实现。键会进行自然排序（如果键实现了<code>Comparable</code>接口）或者根据构造时传入的<code>Comparator</code>进行定制排序。不允许<code>null</code>键（除非比较器支持）。查询、添加、删除操作的时间复杂度为O(log n)。线程不安全。</li><li><code>Hashtable</code>: (遗留类) 基于哈希表实现，线程安全的（方法基本都用<code>synchronized</code>修饰），性能较低。不允许<code>null</code>键和<code>null</code>值。一般不推荐使用，可使用<code>ConcurrentHashMap</code>替代。</li></ul></li></ul><p><strong>相关工具类和接口：</strong></p><ul><li><code>Iterator</code>接口: 用于遍历集合中的元素，提供了统一的遍历方式。</li><li><code>ListIterator</code>接口: 继承自<code>Iterator</code>，专用于<code>List</code>类型，支持双向遍历和修改元素。</li><li><code>Collections</code>类: 提供了操作集合的静态工具方法，如排序、查找、同步包装等。</li><li><code>Arrays</code>类: 提供了操作数组的静态工具方法，如排序、查找、转换为List等。</li></ul>"
        },
        {
            "id": "java-basic-13",
            "question": "13、ArrarList和LinkedList区别",
            "difficulty": "★",
            "answer": "<p><code>ArrayList</code> 和 <code>LinkedList</code> 都是 <code>java.util.List</code> 接口的常用实现类，它们在底层数据结构、性能特点和适用场景上有所不同：</p><ol><li><strong>底层数据结构</strong>:<ul><li><code>ArrayList</code>: 内部是基于**动态数组**（<code>Object[] elementData</code>）实现的。它封装了一个可增长的数组，当数组容量不足时会自动扩容。</li><li><code>LinkedList</code>: 内部是基于**双向链表**（每个节点包含数据以及指向前一个和后一个节点的引用）实现的。 它还实现了<code>Deque</code>接口，因此可以作为栈或队列使用。</li></ul></li><li><strong>随机访问效率 (Get/Set操作)</strong>:<ul><li><code>ArrayList</code>: 由于是数组结构，支持通过索引进行快速的随机访问。获取指定索引的元素（<code>get(index)</code>）的时间复杂度是 O(1)。</li><li><code>LinkedList</code>: 不支持高效的随机访问。获取指定索引的元素需要从链表的头部或尾部（取决于索引位置）开始遍历，时间复杂度是 O(n)。</li></ul></li><li><strong>增删操作效率 (Add/Remove操作)</strong>:<ul><li><code>ArrayList</code>:<ul><li>在数组末尾添加/删除元素时，效率较高，平均时间复杂度是 O(1)（不考虑扩容）。</li><li>在数组中间或开头添加/删除元素时，效率较低，因为需要移动后续所有元素来填补或腾出空间，时间复杂度是 O(n)。 数组扩容也会带来额外开销。</li></ul></li><li><code>LinkedList</code>:<ul><li>在链表的首部或尾部添加/删除元素时，效率非常高，时间复杂度是 O(1)，因为只需要修改少量指针。</li><li>在链表中间添加/删除元素时（如果已经定位到该节点），也只需要修改指针，时间复杂度是 O(1)。但如果需要先通过索引定位到该节点，则定位过程是 O(n)。</li></ul></li></ul></li><li><strong>内存开销</strong>:<ul><li><code>ArrayList</code>: 主要开销是数组本身。可能会有部分预留空间未被使用，导致一定的空间浪费，但每个元素的存储开销相对较小。</li><li><code>LinkedList</code>: 每个元素都需要存储数据本身以及两个额外的指针（指向前驱和后继节点），因此每个元素的内存开销比<code>ArrayList</code>中的元素要大。</li></ul></li><li><strong>线程安全性</strong>:<ul><li>两者都是线程不安全的。如果在多线程环境中使用，需要外部同步（例如使用<code>Collections.synchronizedList()</code>包装）或者使用并发集合类（如<code>CopyOnWriteArrayList</code>）。</li></ul></li><li><strong>适用场景</strong>:<ul><li><code>ArrayList</code>: 适用于**查询（随机访问）操作频繁，而增删操作（尤其是在列表中间）较少**的场景。</li><li><code>LinkedList</code>: 适用于**增删操作（尤其是在列表首尾）频繁，而查询操作较少**的场景。也适合用作栈或队列。</li></ul></li></ol><p>PDF中提到“若只对单条数据插入或删除,ArrayList的速度反而优于LinkedList。但若是批量随机的插入删除数据,LinkedList的速度大大优于ArrayList”。这点需要澄清：单个元素在指定索引处插入/删除，LinkedList的节点操作是O(1)，但定位索引是O(n)；ArrayList的定位是O(1)，但移动是O(n)。如果是在迭代过程中进行增删（使用<code>ListIterator</code>），LinkedList更有优势。对于首尾操作，LinkedList的O(1)通常优于ArrayList（末尾O(1)均摊，开头O(n)）。</p>"
        },
        {
            "id": "java-basic-14",
            "question": "14.HashMap底层是数组+链表+红黑树,为什么要用这几类结构",
            "difficulty": "★★",
            "answer": "<p><code>HashMap</code> (自JDK 1.8起) 的底层数据结构采用“数组 + 链表 + 红黑树”是为了在查询效率、空间利用率和哈希冲突处理之间取得一个良好的平衡。</p><ol><li><strong>数组 (<code>Node&lt;K,V&gt;[] table</code>)</strong>:<ul><li><strong>作用</strong>: 作为哈希表的主体结构，提供基础的寻址能力。</li><li><strong>原理</strong>: 当我们向<code>HashMap</code>中存入一个键值对时，会根据键(key)的哈希值（经过扰动函数处理后）计算出一个在数组中的索引位置。理想情况下（没有哈希冲突），可以直接通过这个索引快速定位到存储的元素，实现O(1)时间复杂度的存取。</li></ul></li><li><strong>链表 (<code>Node&lt;K,V&gt;</code>)</strong>:<ul><li><strong>作用</strong>: 主要用于解决哈希冲突。 哈希冲突是指不同的键计算出相同的数组索引。</li><li><strong>原理</strong>: 当发生哈希冲突时，即多个键值对映射到数组的同一个索引位置（称为一个桶或bin），这些键值对会以链表的形式存储在该索引位置。新来的元素通常采用尾插法（JDK 1.8，JDK 1.7是头插法）加入链表。查询时，如果定位到某个桶，并且该桶中是链表，就需要遍历链表，通过<code>equals()</code>方法找到目标键。</li><li><strong>缺点</strong>: 如果哈希函数设计不佳或数据特性导致大量哈希冲突，某个桶中的链表可能会变得很长。在这种情况下，查询链表的时间复杂度会退化到O(n)，其中n是链表长度，严重影响性能。</li></ul></li><li><strong>红黑树 (<code>TreeNode&lt;K,V&gt;</code>)</strong>:<ul><li><strong>作用</strong>: 为了优化在哈希冲突严重情况下链表的查询性能。</li><li><strong>原理</strong>: 在JDK 1.8中引入。当同一个哈希桶中的链表长度达到一定阈值（默认为<code>TREEIFY_THRESHOLD = 8</code>），并且<code>HashMap</code>的总容量（数组长度）也达到一定阈值（默认为<code>MIN_TREEIFY_CAPACITY = 64</code>）时，这条链表就会被转换为红黑树结构。</li><li>红黑树是一种自平衡的二叉查找树，其查找、插入、删除操作的平均和最坏时间复杂度都是O(log n)，其中n是树中节点的数量。这远优于链表的O(n)。</li><li>如果红黑树中的节点数量在删除等操作后减少到一定阈值（默认为<code>UNTREEIFY_THRESHOLD = 6</code>），它会再转换回链表结构，以节省空间和避免不必要的树操作开销。</li></ul></li></ol><p><strong>总结原因</strong>:</p><ul><li><strong>数组</strong>提供基础的快速定位（O(1)理想情况）。</li><li><strong>链表</strong>是解决哈希冲突的一种简单有效的方式。</li><li><strong>红黑树</strong>则是在哈希冲突变得严重时，对链表性能的一种优化，防止查询效率急剧下降，将最坏情况下的查询时间复杂度从O(n)降低到O(log n)。</li></ul><p>这种组合结构使得<code>HashMap</code>在大多数情况下能保持高效的性能，同时也能应对极端哈希冲突的情况。</p>"
        },
        {
            "id": "java-basic-15",
            "question": "15、HashMap和HashTable区别",
            "difficulty": "★",
            "answer": "<p><code>HashMap</code> 和 <code>Hashtable</code> 都是Java集合框架中<code>Map</code>接口的实现类，用于存储键值对，但它们之间存在一些重要的区别：</p><ol><li><strong>线程安全性</strong>:<ul><li><code>HashMap</code>: **线程不安全**。 如果在多线程环境中使用<code>HashMap</code>并且有并发修改操作，必须由外部进行同步控制（例如使用<code>Collections.synchronizedMap(new HashMap&lt;&gt;())</code>或者使用<code>ConcurrentHashMap</code>）。</li><li><code>Hashtable</code>: **线程安全**。 <code>Hashtable</code>中的大部分方法（如<code>put</code>, <code>get</code>, <code>remove</code>等）都使用了<code>synchronized</code>关键字进行修饰，保证了多线程环境下的操作安全。但也因此，在高并发场景下，其性能通常低于<code>HashMap</code>或<code>ConcurrentHashMap</code>，因为锁的粒度较大（锁整个表）。</li></ul></li><li><strong>对<code>null</code>键和<code>null</code>值的支持</strong>:<ul><li><code>HashMap</code>: **允许**键和值为<code>null</code>。 具体来说，<code>HashMap</code>允许一个<code>null</code>键和多个<code>null</code>值。</li><li><code>Hashtable</code>: **不允许**键或值为<code>null</code>。 如果尝试存入<code>null</code>键或<code>null</code>值，会抛出<code>NullPointerException</code>。</li></ul></li><li><strong>初始容量和扩容机制</strong>:<ul><li><code>HashMap</code>: 默认初始容量为16。 扩容时，容量变为原来的2倍。 <code>HashMap</code>要求底层数组的容量（包括初始容量和扩容后的容量）必须是2的整数次幂，这有助于通过位运算（<code>hash & (length-1)</code>）快速计算索引，减少哈希冲突。</li><li><code>Hashtable</code>: 默认初始容量为11。 扩容时，容量变为原来的2倍加1。 不要求容量必须是2的整数次幂。</li></ul></li><li><strong>父类和继承体系</strong>:<ul><li><code>HashMap</code>: 继承自<code>AbstractMap</code>类。</li><li><code>Hashtable</code>: 继承自<code>Dictionary</code>类 (一个遗留类，已被<code>Map</code>接口取代)。</li></ul></li><li><strong>迭代器 (Iterator)</strong>:<ul><li><code>HashMap</code>的迭代器（通过<code>keySet().iterator()</code>, <code>values().iterator()</code>, <code>entrySet().iterator()</code>获取）是**fail-fast**机制的。这意味着如果在迭代过程中，<code>HashMap</code>的结构被修改（非通过迭代器自身的<code>remove</code>方法），迭代器会快速抛出<code>ConcurrentModificationException</code>。</li><li><code>Hashtable</code>返回的<code>Enumerator</code>（通过<code>keys()</code>, <code>elements()</code>获取，是遗留接口）不是fail-fast的。不过，通过<code>entrySet().iterator()</code>等获取的<code>Iterator</code>通常也是fail-fast的。</li></ul></li><li><strong>性能</strong>:<ul><li>由于<code>HashMap</code>是非同步的，所以在单线程环境下或外部已进行同步控制的多线程环境下，其性能通常优于<code>Hashtable</code>。</li><li><code>Hashtable</code>的同步机制在高并发下会导致严重的锁竞争，性能较差。</li></ul></li><li><strong>contains方法</strong>:<ul><li>PDF提到“HashMap只有containsValue和containsKey方法;HashTable有contains、containsKey和containsValue三个方法,其中contains和containsValue方法功能相同。” （注意：<code>Hashtable</code>的<code>contains(Object value)</code>方法确实等同于<code>containsValue(Object value)</code>）。</li></ul></li></ol><p><strong>总结与推荐：</strong></p><p>由于性能和对<code>null</code>支持的灵活性，在新代码中，如果不需要线程安全，通常推荐使用<code>HashMap</code>。如果需要线程安全的Map，则推荐使用<code>java.util.concurrent.ConcurrentHashMap</code>，它提供了比<code>Hashtable</code>更优的并发性能和更细粒度的锁控制。</p>"
        },
        {
            "id": "java-basic-16",
            "question": "16、线程的创建方式",
            "difficulty": "★",
            "answer": "<p>Java中创建线程主要有以下几种方式：</p><ol><li><strong>继承<code>Thread</code>类</strong>:<ul><li>创建一个新类继承自<code>java.lang.Thread</code>类。</li><li>重写父类<code>Thread</code>的<code>run()</code>方法，将线程需要执行的任务逻辑放在<code>run()</code>方法中。</li><li>创建该子类的实例，然后调用其<code>start()</code>方法来启动线程。<code>start()</code>方法会使得Java虚拟机调用该线程的<code>run()</code>方法。</li></ul></li><li><strong>实现<code>Runnable</code>接口</strong>:<ul><li>创建一个新类实现<code>java.lang.Runnable</code>接口。</li><li>实现接口中的<code>run()</code>方法，将线程任务逻辑放在<code>run()</code>方法中。</li><li>创建该实现类的实例。</li><li>创建一个<code>Thread</code>对象，并将<code>Runnable</code>接口的实现类实例作为参数传递给<code>Thread</code>的构造函数 (<code>new Thread(runnableInstance)</code>)。</li><li>调用<code>Thread</code>对象的<code>start()</code>方法来启动线程。</li><li>这种方式更推荐，因为它避免了Java单继承的限制，类可以继承其他类的同时实现<code>Runnable</code>接口，实现了任务逻辑与线程创建的分离。</li></ul></li><li><strong>实现<code>Callable</code>接口 (通常与<code>FutureTask</code>或线程池配合使用)</strong>:<ul><li>创建一个新类实现<code>java.util.concurrent.Callable&lt;V&gt;</code>接口。<code>V</code>是返回值的类型。</li><li>实现接口中的<code>call()</code>方法。<code>call()</code>方法可以有返回值，并且可以抛出受检查异常。</li><li>创建<code>Callable</code>实现类的实例。</li><li>通常将<code>Callable</code>实例包装在一个<code>FutureTask&lt;V&gt;</code>对象中 (<code>FutureTask</code>实现了<code>RunnableFuture</code>，而<code>RunnableFuture</code>又继承了<code>Runnable</code>和<code>Future</code>)。</li><li>然后可以像处理<code>Runnable</code>一样，将<code>FutureTask</code>对象传递给<code>Thread</code>构造器并启动，或者提交给线程池执行。</li><li>通过<code>FutureTask</code>对象的<code>get()</code>方法可以获取线程执行完毕后的返回值（该方法会阻塞直到结果可用）。</li></ul></li><li><strong>使用线程池 (<code>ExecutorService</code>)</strong>:<ul><li>通过<code>java.util.concurrent.Executors</code>工具类提供的静态工厂方法（如<code>newFixedThreadPool()</code>, <code>newCachedThreadPool()</code>, <code>newSingleThreadExecutor()</code>, <code>newScheduledThreadPool()</code>）创建线程池。</li><li>或者直接创建<code>ThreadPoolExecutor</code>类的实例，进行更细致的配置。</li><li>将实现了<code>Runnable</code>或<code>Callable</code>接口的任务提交给线程池（通过<code>execute(Runnable)</code>或<code>submit(Runnable/Callable)</code>方法）。</li><li>线程池会管理线程的创建、复用和销毁，能够有效控制并发线程数量，提高系统性能和稳定性。这是现代并发编程中推荐的方式。</li></ul></li></ol><p><strong>代码演示 (根据PDF Page 8, 15-16 调整和补充):</strong></p><div class=\"code-block\"><code>import java.util.concurrent.*;\n\n// 1. 继承Thread类\nclass ThreadClass extends Thread {\n    @Override\n    public void run() {\n        System.out.println(\"方式1: 我是继承Thread形式: \" + Thread.currentThread().getName());\n    }\n}\n\n// 2. 实现Runnable接口\nclass RunnableClass implements Runnable {\n    @Override\n    public void run() {\n        System.out.println(\"方式2: 我是实现Runnable接口: \" + Thread.currentThread().getName());\n    }\n}\n\n// 3. 实现Callable接口\nclass CallableClass implements Callable&lt;String&gt; {\n    @Override\n    public String call() throws Exception {\n        System.out.println(\"方式3: 我是实现Callable接口: \" + Thread.currentThread().getName());\n        return \"我是Callable的返回值,可以通过FutureTask.get()获取\";\n    }\n}\n\npublic class ThreadCreationTest {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        // 方式1: 继承Thread类\n        ThreadClass thread1 = new ThreadClass();\n        thread1.start();\n        Thread.sleep(100); // 等待线程执行\n        System.out.println(\"----------------------------\");\n\n        // 方式2: 实现Runnable接口\n        RunnableClass runnableInstance = new RunnableClass();\n        Thread thread2 = new Thread(runnableInstance);\n        thread2.start();\n        Thread.sleep(100);\n        System.out.println(\"----------------------------\");\n\n        // 方式3: 实现Callable接口 (配合FutureTask)\n        CallableClass callableInstance = new CallableClass();\n        FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(callableInstance);\n        Thread thread3 = new Thread(futureTask);\n        thread3.start();\n        // 获取返回值 (get()会阻塞)\n        System.out.println(\"Callable返回值: \" + futureTask.get());\n        Thread.sleep(100);\n        System.out.println(\"----------------------------\");\n\n        // 方式4: 使用线程池 (ExecutorService)\n        // ExecutorService executorService = Executors.newFixedThreadPool(2);\n        ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(\n                1, // corePoolSize\n                1, // maximumPoolSize\n                0L, TimeUnit.MILLISECONDS, // keepAliveTime\n                new LinkedBlockingQueue&lt;Runnable&gt;() // workQueue\n        );\n\n        System.out.println(\"方式4: 使用线程池提交Runnable任务\");\n        executorService.execute(new RunnableClass()); // 提交Runnable任务\n\n        System.out.println(\"方式4: 使用线程池提交Callable任务\");\n        Future&lt;String&gt; futureFromPool = executorService.submit(new CallableClass()); // 提交Callable任务\n        System.out.println(\"线程池中Callable返回值: \" + futureFromPool.get());\n\n        executorService.shutdown(); // 关闭线程池\n        System.out.println(\"----------------------------\");\n    }\n}</code></div>"
        },
        {
            "id": "java-basic-17",
            "question": "17、线程的状态转换有什么(生命周期)",
            "difficulty": "★",
            "answer": "<p>Java线程在其生命周期中会经历多种状态。这些状态定义在<code>java.lang.Thread.State</code>枚举中。主要状态及其转换如下：</p><ol><li><strong>新建 (NEW)</strong>:<ul><li>当使用<code>new</code>关键字创建了一个<code>Thread</code>类的实例后，线程对象就处于新建状态。 例如, <code>Thread t = new MyThread();</code>。</li><li>此时，线程对象已经创建，但操作系统中尚未创建真正的线程，它还没有开始执行。</li></ul></li><li><strong>就绪 (RUNNABLE)</strong>:<ul><li>也称为“可运行状态”。当线程对象调用了<code>start()</code>方法后，线程就进入就绪状态。 例如, <code>t.start();</code>。</li><li>处于就绪状态的线程表示它已经具备了运行的条件，正在等待CPU调度器分配CPU时间片。一旦获得CPU时间，它就可以开始执行<code>run()</code>方法中的代码。</li><li>Java虚拟机规范中，将等待CPU执行和正在CPU上执行的线程都归为RUNNABLE状态。操作系统层面可能会区分“就绪”和“运行中”。</li></ul></li><li><strong>运行 (RUNNING)</strong>:<ul><li>这个状态在Java的<code>Thread.State</code>枚举中并没有显式定义，通常被包含在RUNNABLE状态中。</li><li>当就绪状态的线程获得了CPU时间片，就开始执行其<code>run()</code>方法中的代码，此时可以认为它处于运行状态。</li></ul></li><li><strong>阻塞 (BLOCKED / WAITING / TIMED_WAITING)</strong>:<ul><li>线程因为某种原因暂时放弃CPU使用权，停止运行，进入阻塞状态。 直到特定条件满足，线程才会重新转换到就绪（RUNNABLE）状态，等待再次被CPU调度。</li><li>Java中阻塞状态可以细分为：<ul><li><strong>BLOCKED (阻塞)</strong>: 线程在等待获取一个监视器锁（monitor lock）时进入此状态。例如，线程试图进入一个被其他线程持有的<code>synchronized</code>代码块或方法。当持有锁的线程释放锁后，此线程会尝试获取锁并转为RUNNABLE。</li><li><strong>WAITING (无限期等待)</strong>: 线程因为调用了没有超时参数的<code>Object.wait()</code>, <code>Thread.join()</code>, 或 <code>LockSupport.park()</code>方法而进入此状态。它需要被其他线程显式地唤醒（如通过<code>Object.notify()</code>, <code>Object.notifyAll()</code>，或者目标<code>join()</code>的线程结束，或者<code>LockSupport.unpark()</code>）。唤醒后进入RUNNABLE状态（通常是先进入BLOCKED状态尝试重新获取锁）。</li><li><strong>TIMED_WAITING (限时等待)</strong>: 线程因为调用了带有超时参数的方法而进入此状态，例如<code>Thread.sleep(long millis)</code>, <code>Object.wait(long millis)</code>, <code>Thread.join(long millis)</code>, <code>LockSupport.parkNanos()</code>, <code>LockSupport.parkUntil()</code>。线程会等待指定的时间，或者被显式唤醒/中断。超时或被唤醒/中断后，转为RUNNABLE状态（同样，对于<code>wait</code>和<code>join</code>，通常需要重新获取锁）。</li></ul></li><li>PDF中提到的阻塞分类：等待阻塞 (<code>wait()</code>)，同步阻塞 (获取<code>synchronized</code>锁失败)，其他阻塞 (<code>sleep()</code>, <code>join()</code>, I/O请求)。这可以对应到<code>WAITING</code>/<code>TIMED_WAITING</code>和<code>BLOCKED</code>状态。</li></ul></li><li><strong>终止/死亡 (TERMINATED / DEAD)</strong>:<ul><li>当线程的<code>run()</code>方法执行完毕（正常结束或因未捕获的异常而终止），或者线程的<code>stop()</code>方法被调用（已废弃，不推荐使用）时，线程就进入终止状态。</li><li>处于终止状态的线程不能再被重新启动。</li></ul></li></ol><p><strong>状态转换关系：</strong></p><ul><li>NEW <code>-(start())-&gt;</code> RUNNABLE</li><li>RUNNABLE <code>-(CPU调度执行)-&gt;</code> (概念上的RUNNING)</li><li>RUNNABLE/RUNNING <code>-(synchronized锁竞争失败)-&gt;</code> BLOCKED</li><li>BLOCKED <code>-(获取到锁)-&gt;</code> RUNNABLE</li><li>RUNNABLE/RUNNING <code>-(obj.wait(), t.join(), LockSupport.park())-&gt;</code> WAITING</li><li>RUNNABLE/RUNNING <code>-(Thread.sleep(), obj.wait(timeout), t.join(timeout), LockSupport.parkNanos/Until())-&gt;</code> TIMED_WAITING</li><li>WAITING/TIMED_WAITING <code>-(obj.notify()/notifyAll(), unpark(), 中断, 超时, join的线程结束)-&gt;</code> RUNNABLE (或先到BLOCKED)</li><li>RUNNABLE/RUNNING <code>-(run()方法结束或异常)-&gt;</code> TERMINATED</li></ul>"
        },
        {
            "id": "java-basic-18",
            "question": "18、Java中有几种类型的流",
            "difficulty": "★",
            "answer": "<p>Java中的IO流主要按照以下两种方式进行分类：</p><p><strong>1. 按处理数据的单位不同：</strong></p><ul><li><strong>字节流 (Byte Streams)</strong>:<ul><li>以字节（8位）为单位进行数据读写。</li><li>能够处理所有类型的数据，包括二进制文件（如图片、音频、视频）和文本文件（但处理文本文件时不直接处理字符编码，可能导致乱码）。</li><li>抽象基类：<code>java.io.InputStream</code> (输入字节流) 和 <code>java.io.OutputStream</code> (输出字节流)。</li><li>常见子类：<ul><li><code>FileInputStream</code> / <code>FileOutputStream</code>: 用于文件读写。</li><li><code>BufferedInputStream</code> / <code>BufferedOutputStream</code>: 增加缓冲功能，提高读写效率。</li><li><code>DataInputStream</code> / <code>DataOutputStream</code>: (处理流/包装流) 提供了读写Java基本数据类型和字符串的方法。</li><li><code>ObjectInputStream</code> / <code>ObjectOutputStream</code>: (处理流/包装流) 用于对象的序列化和反序列化。</li><li><code>ByteArrayInputStream</code> / <code>ByteArrayOutputStream</code>: 在内存中（字节数组）进行读写。</li></ul></li></ul></li><li><strong>字符流 (Character Streams)</strong>:<ul><li>以字符（通常是16位Unicode字符）为单位进行数据读写。</li><li>专门用于处理文本数据，会自动处理字符编码和解码。</li><li>抽象基类：<code>java.io.Reader</code> (输入字符流) 和 <code>java.io.Writer</code> (输出字符流)。</li><li>常见子类：<ul><li><code>FileReader</code> / <code>FileWriter</code>: 用于文本文件读写。</li><li><code>BufferedReader</code> / <code>BufferedWriter</code>: 增加缓冲功能，可以按行读取/写入，提高效率。</li><li><code>InputStreamReader</code> / <code>OutputStreamWriter</code>: (转换流/桥接流) 是字节流和字符流之间的桥梁。可以将字节输入流转换为字符输入流（解码），或将字符输出流转换为字节输出流（编码），并可以指定字符集。</li><li><code>PrintWriter</code>: 提供了方便的打印方法，可以按行打印各种数据类型。</li><li><code>StringReader</code> / <code>StringWriter</code>: 在内存中（字符串）进行读写。</li></ul></li></ul></li></ul><p><strong>2. 按数据流动的方向不同：</strong></p><ul><li><strong>输入流 (Input Streams / Readers)</strong>: 从数据源（如文件、网络、内存）读取数据到程序中。</li><li><strong>输出流 (Output Streams / Writers)</strong>: 将程序中的数据写入到目标（如文件、网络、内存）。</li></ul><p><strong>3. 按流的角色不同 (另一种分类视角)：</strong></p><ul><li><strong>节点流 (Node Streams)</strong>: 直接与数据源或目标相连接的流，负责实际的读写操作。例如：<code>FileInputStream</code>, <code>FileOutputStream</code>, <code>FileReader</code>, <code>FileWriter</code>。</li><li><strong>处理流/包装流 (Filter Streams / Wrapper Streams)</strong>: 不直接连接到数据源或目标，而是对已存在的节点流进行包装或处理，以提供更强大的功能或更高的性能。例如：<code>BufferedInputStream</code>, <code>DataInputStream</code>, <code>InputStreamReader</code>, <code>PrintWriter</code>。处理流通常需要一个已存在的流作为其构造参数。</li></ul><p>在实际使用中，常常将不同类型的流组合起来使用，例如用<code>BufferedReader</code>包装一个<code>FileReader</code>来高效地按行读取文本文件。</p>"
        },
        {
            "id": "java-basic-19",
            "question": "19、请写出你最常见的5个RuntimeException",
            "difficulty": "★",
            "answer": "<p><code>RuntimeException</code> (运行时异常) 及其子类是在程序运行时可能出现的异常，Java编译器不强制要求我们必须捕获或声明抛出这些异常（即它们是非受检异常 Unchecked Exception）。以下是一些常见的<code>RuntimeException</code>：</p><ol><li><strong><code>NullPointerException</code> (空指针异常)</strong>:<ul><li>原因：当应用程序试图在需要对象的地方使用<code>null</code>时抛出。例如，调用一个<code>null</code>对象的实例方法、访问或修改<code>null</code>对象的字段、获取<code>null</code>作为数组时的长度、或者将<code>null</code>作为<code>Throwable</code>值抛出。</li><li>常见场景：调用了未经初始化的对象或者不存在的对象的方法或属性。</li></ul></li><li><strong><code>ArrayIndexOutOfBoundsException</code> (数组索引越界异常)</strong>:<ul><li>原因：当使用非法索引访问数组时抛出。如果索引为负或大于等于数组大小，则索引为非法。</li><li>常见场景：操作数组对象时，使用的索引超出了数组的有效范围（0 到 length-1）。</li></ul></li><li><strong><code>ClassCastException</code> (类转换异常)</strong>:<ul><li>原因：当试图将对象强制转换为不是其实例的子类型时抛出。</li><li>常见场景：在进行向下转型（downcasting）时，如果对象实际类型与目标类型不兼容。例如，<code>Object obj = new String(\"hello\"); Integer num = (Integer)obj;</code></li></ul></li><li><strong><code>NumberFormatException</code> (数字格式异常)</strong>:<ul><li>原因：当应用程序试图将字符串转换为一种数值类型，但该字符串不能被解析为适当的格式时抛出。</li><li>常见场景：例如，调用<code>Integer.parseInt(\"abc\")</code>。</li></ul></li><li><strong><code>IllegalArgumentException</code> (非法参数异常)</strong>:<ul><li>原因：当向方法传递了一个不合法或不正确的参数时抛出。</li><li>常见场景：方法的参数值超出了期望的范围或不符合约定的格式。</li></ul></li></ol><p><strong>其他也比较常见的 RuntimeException 包括：</strong></p><ul><li><strong><code>ArithmeticException</code> (算术异常)</strong>: 通常是由于整数除以零等算术错误。</li><li><strong><code>IllegalStateException</code> (非法状态异常)</strong>: 当在Java环境或应用程序尚未处于某个操作所要求的适当状态时，表明该方法已被调用。例如，在对象未正确初始化时调用其某个方法。</li><li><strong><code>ConcurrentModificationException</code> (并发修改异常)</strong>: 当方法检测到对象的并发修改，但不允许这种修改时，拋出此异常。例如，在使用迭代器遍历集合时，如果通过集合自身的方法（而不是迭代器的<code>remove()</code>）修改了集合的结构。</li></ul>"
        },
        {
            "id": "java-basic-20",
            "question": "20、谈谈你对反射的理解",
            "difficulty": "★",
            "answer": "<p>反射（Reflection）是Java语言的一项强大机制，它允许程序在**运行时**动态地获取自身的信息（自观能力）以及操作任意类的属性和方法。 这种动态获取信息以及动态调用对象方法的功能使得程序更加灵活和具有扩展性。</p><p><strong>1. 反射机制的核心组件:</strong></p><p>Java的反射机制主要借助于以下几个核心类，它们位于<code>java.lang.reflect</code>包下：</p><ul><li><strong><code>Class</code></strong>: 代表一个类或接口的运行时表示。获取<code>Class</code>对象是反射的入口。有多种方式获取<code>Class</code>对象，例如：<ul><li><code>对象.getClass()</code></li><li><code>类名.class</code></li><li><code>Class.forName(\"类的全限定名\")</code></li></ul></li><li><strong><code>Constructor</code></strong>: 代表类的构造器对象。通过<code>Class</code>对象可以获取类的构造器，并用其创建类的实例。</li><li><strong><code>Field</code></strong>: 代表类的成员变量（属性）对象。通过<code>Class</code>对象可以获取类的字段，并动态地读取或设置对象属性的值，即使是私有字段（需要设置可访问性）。</li><li><strong><code>Method</code></strong>: 代表类的方法对象。通过<code>Class</code>对象可以获取类的方法，并动态地调用对象的方法，即使是私有方法（需要设置可访问性）。</li></ul><p><strong>2. Java反射的主要功能/作用:</strong></p><ul><li>在运行时判断任意一个对象所属的类。</li><li>在运行时构造任意一个类的对象（即使构造器是私有的，通过设置可访问性）。</li><li>在运行时判断任意一个类所具有的成员变量和方法（包括父类的成员，以及私有成员）。</li><li>在运行时调用任意一个对象的方法（包括私有方法）。</li><li>在运行时获取和设置任意一个对象的属性值（包括私有属性）。</li><li>生成动态代理。</li><li>处理注解。</li></ul><p><strong>3. 应用场景:</strong></p><p>反射广泛应用于各种Java框架和工具中，例如：</p><ul><li><strong>Spring框架</strong>: 依赖注入（DI）就是通过反射动态地为对象的属性赋值；AOP（面向切面编程）的动态代理也依赖反射。</li><li><strong>ORM框架 (如MyBatis, Hibernate)</strong>: 在对象和数据库表之间进行映射时，需要通过反射来读取对象属性和调用setter方法。</li><li><strong>JDBC驱动加载</strong>: <code>Class.forName(\"com.mysql.jdbc.Driver\")</code> 就是通过反射加载数据库驱动。</li><li><strong>IDE和调试工具</strong>: 利用反射来检查和操作运行时的对象。</li><li><strong>单元测试框架 (如JUnit)</strong>: 通过反射调用测试方法。</li><li><strong>注解处理器</strong>: 在运行时读取和处理注解信息。</li></ul><p><strong>4. 优缺点:</strong></p><ul><li><strong>优点</strong>:<ul><li><strong>灵活性和动态性</strong>: 使得程序可以在运行时操作类和对象，增加了程序的适应性和扩展性。</li><li><strong>通用性</strong>: 可以编写更通用的代码来处理不同类型的对象。</li></ul></li><li><strong>缺点</strong>:<ul><li><strong>性能开销</strong>: 反射操作（如方法调用、字段访问）通常比直接代码调用要慢，因为它涉及到动态解析和类型检查等步骤。</li><li><strong>破坏封装性</strong>: 反射可以访问和修改类的私有成员，可能破坏类的封装性和安全性。</li><li><strong>类型安全问题</strong>: 由于很多操作是在运行时进行的，编译时无法进行严格的类型检查，可能在运行时抛出异常（如<code>NoSuchMethodException</code>, <code>IllegalAccessException</code>）。</li><li><strong>代码可读性和维护性</strong>: 过度使用反射可能使代码变得复杂，难以理解和维护。</li></ul></li></ul><p>因此，在使用反射时需要权衡其带来的灵活性和潜在的开销及风险，应谨慎使用。</p>"
        },
        {
            "id": "java-basic-21",
            "question": "21、什么是java序列化,如何实现 java 序列化",
            "difficulty": "★",
            "answer": "<p><strong>1. 什么是Java序列化 (Serialization)</strong>:</p><p>Java序列化是一种将Java对象的状态（即其成员变量的值）转换为一个字节序列（byte stream）的过程。 这个字节序列可以被存储到文件、数据库中，或者通过网络进行传输到其他Java虚拟机（JVM）。</p><p>相对地，**反序列化 (Deserialization)** 则是将这个字节序列恢复为原始Java对象的过程。</p><p>序列化的主要目的：</p><ul><li><strong>持久化 (Persistence)</strong>: 将对象的状态保存下来（例如存到磁盘文件），以便在程序下次运行时可以恢复对象的状态。</li><li><strong>网络传输 (Remote Communication)</strong>: 在不同的Java进程之间或通过网络传输对象。例如，在RPC（远程过程调用）如RMI（远程方法调用）中，参数和返回值对象需要序列化后在网络上传输。</li><li><strong>深拷贝对象</strong>: 虽然不是主要目的，但通过将对象序列化后再反序列化，可以得到一个该对象的深拷贝副本。</li></ul><p><strong>2. 如何实现Java序列化</strong>:</p><p>要使一个类的对象能够被序列化，通常需要遵循以下步骤：</p><ol><li><strong>实现<code>java.io.Serializable</code>接口</strong>:<ul><li>需要被序列化的类必须实现<code>java.io.Serializable</code>接口。</li><li>这是一个标记接口（marker interface），它本身没有定义任何方法。它只是向JVM表明这个类的对象是可以被序列化的。</li></ul></li><li><strong>使用<code>ObjectOutputStream</code>进行序列化</strong>:<ul><li>创建一个<code>ObjectOutputStream</code>对象，它通常包装一个底层的<code>OutputStream</code>（例如<code>FileOutputStream</code>，用于将对象写入文件）。</li><li>调用<code>ObjectOutputStream</code>的<code>writeObject(Object obj)</code>方法，将需要序列化的对象作为参数传入。此方法会将对象转换为字节序列并写入到底层输出流。</li></ul><p>   示例：</p><div class=\"code-block\"><code>   MyClass obj = new MyClass();\n   FileOutputStream fos = new FileOutputStream(\"object.dat\");\n   ObjectOutputStream oos = new ObjectOutputStream(fos);\n   oos.writeObject(obj);\n   oos.close();</code></div></li><li><strong>使用<code>ObjectInputStream</code>进行反序列化</strong>:<ul><li>创建一个<code>ObjectInputStream</code>对象，它通常包装一个底层的<code>InputStream</code>（例如<code>FileInputStream</code>，用于从文件读取对象）。</li><li>调用<code>ObjectInputStream</code>的<code>readObject()</code>方法，它会从输入流中读取字节序列并将其转换回Java对象。返回的是<code>Object</code>类型，需要强制类型转换为原始类型。</li></ul><p>   示例：</p><div class=\"code-block\"><code>   FileInputStream fis = new FileInputStream(\"object.dat\");\n   ObjectInputStream ois = new ObjectInputStream(fis);\n   MyClass restoredObj = (MyClass) ois.readObject();\n   ois.close();</code></div></li></ol><p><strong>注意事项</strong>:</p><ul><li><strong><code>transient</code>关键字</strong>: 如果类中的某个成员变量不希望被序列化，可以使用<code>transient</code>关键字修饰它。被<code>transient</code>修饰的变量在反序列化后其值会是对应类型的默认值（如对象为<code>null</code>，数值为0）。</li><li><strong><code>static</code>变量</strong>: 静态变量属于类而不是对象，因此它们不会被序列化（序列化的是对象的状态）。</li><li><strong><code>serialVersionUID</code></strong>: 建议为所有可序列化的类显式声明一个<code>private static final long serialVersionUID</code>常量。这个ID用于在反序列化时验证发送方和接收方加载的类版本是否兼容。如果类结构发生变化（如增删字段），而<code>serialVersionUID</code>保持不变，反序列化时可能会出问题（除非变化是兼容的）。如果未显式声明，JVM会根据类的结构自动生成一个，但类的任何微小改动都可能导致自动生成的ID变化，从而造成反序列化失败。</li><li><strong>父类的序列化</strong>: 如果一个类实现了<code>Serializable</code>接口，其父类没有实现，则父类中的字段不会被序列化（除非父类有可访问的无参构造函数，反序列化时会调用它来初始化父类部分）。如果父类也实现了<code>Serializable</code>，则父类的字段也会被序列化。</li><li><strong>自定义序列化</strong>: 类可以通过实现<code>java.io.Externalizable</code>接口，或者在实现了<code>Serializable</code>接口的类中提供<code>writeObject(ObjectOutputStream out)</code>和<code>readObject(ObjectInputStream in)</code>等特殊方法来自定义序列化和反序列化的过程。</li></ul>"
        },
        {
            "id": "java-basic-22",
            "question": "22、Http 常见的状态码",
            "difficulty": "★",
            "answer": "<p>HTTP状态码由三位数字组成，第一个数字定义了响应的类别。以下是一些常见的HTTP状态码及其含义：</p><p><strong>1xx (信息性状态码 Informational)</strong>: 表示请求已被接收，继续处理。</p><ul><li><code>100 Continue</code>: 服务器已接收到请求的初始部分，客户端应继续发送请求的其余部分。</li></ul><p><strong>2xx (成功状态码 Success)</strong>: 表示请求已成功被服务器接收、理解、并接受。</p><ul><li><code>200 OK</code>: 请求成功。 GET请求的响应体中会包含请求的资源；POST请求的响应体中会包含操作的结果。</li><li><code>201 Created</code>: 请求成功并且服务器创建了新的资源。通常在POST或PUT请求成功后返回。</li><li><code>204 No Content</code>: 服务器成功处理了请求，但没有返回任何内容。响应体为空。通常用于PUT或DELETE操作成功，且不需要返回额外信息。</li></ul><p><strong>3xx (重定向状态码 Redirection)</strong>: 表示需要客户端采取进一步的操作才能完成请求。</p><ul><li><code>301 Moved Permanently</code>: 请求的资源已被永久移动到新的URI。 客户端/浏览器应在后续请求中使用新的URI。</li><li><code>302 Found</code> (原为 <code>Temporarily Moved</code>): 请求的资源临时从不同的URI响应请求。 客户端应继续使用原有URI进行后续请求。常用于临时重定向。</li><li><code>304 Not Modified</code>: 客户端发送附带条件的GET请求时（通常基于缓存的<code>If-Modified-Since</code>或<code>If-None-Match</code>头），服务器表明资源自上次请求以来未被修改，客户端可以直接使用本地缓存的副本。响应体为空。</li></ul><p><strong>4xx (客户端错误状态码 Client Error)</strong>: 表示客户端看起来可能发生了错误，妨碍了服务器的处理。</p><ul><li><code>400 Bad Request</code>: 客户端请求有语法错误，服务器无法理解。 例如，请求参数格式错误或缺失。</li><li><code>401 Unauthorized</code>: 请求未经授权。 表示客户端需要进行身份验证才能获取所请求的响应。通常会 همراه一个<code>WWW-Authenticate</code>头。</li><li><code>403 Forbidden</code>: 服务器收到请求，但是拒绝提供服务（权限不足）。 即使客户端已认证，也可能因为权限问题被拒绝访问。</li><li><code>404 Not Found</code>: 服务器无法找到请求的资源。 例如，URL输入错误或资源已被删除。</li><li><code>405 Method Not Allowed</code>: 请求行中指定的请求方法不被目标资源所支持。响应中必须包含一个<code>Allow</code>头，列出支持的方法。</li></ul><p><strong>5xx (服务器错误状态码 Server Error)</strong>: 表示服务器在处理请求的过程中有错误或者异常状态发生。</p><ul><li><code>500 Internal Server Error</code>: 服务器发生不可预期的错误，导致无法完成请求。 这是一个通用的服务器内部错误码。</li><li><code>502 Bad Gateway</code>: 作为网关或者代理工作的服务器，从上游服务器接收到无效的响应。</li><li><code>503 Service Unavailable</code>: 服务器当前不能处理客户端的请求，一段时间后可能恢复正常。 例如，服务器过载或停机维护。通常会包含一个<code>Retry-After</code>头，指示客户端何时可以重试。</li></ul>"
        },
        {
            "id": "java-basic-23",
            "question": "23、GET 和POST 的区别",
            "difficulty": "★",
            "answer": "<p>GET 和 POST 是 HTTP 协议中定义的两种最常用的请求方法，它们在用途、数据传递方式、安全性、幂等性等方面存在显著区别：</p><ol><li><strong>参数传递方式与位置</strong>:<ul><li><strong>GET</strong>: 请求参数会附加在 URL 的末尾，作为查询字符串（query string）的一部分。 URL 和参数之间用<code>?</code>分隔，参数之间用<code>&</code>相连。例如: <code>/search?query=java&page=1</code>。参数直接暴露在URL中。</li><li><strong>POST</strong>: 请求参数通常放置在 HTTP 请求的包体（Request Body）中。 URL中不直接显示参数。</li></ul></li><li><strong>数据大小限制</strong>:<ul><li><strong>GET</strong>: 由于参数在URL中传递，而URL的长度通常受到浏览器和服务器的限制（例如，IE限制为2083字节），所以GET请求能携带的数据量较小。 （HTTP协议本身未对URL长度做限制，限制来自具体实现）。</li><li><strong>POST</strong>: 理论上没有数据大小限制（或限制远大于GET），适合传输大量数据，如文件上传。实际限制可能受服务器配置影响。</li></ul></li><li><strong>安全性</strong>:<ul><li><strong>GET</strong>: 安全性相对较低。参数直接暴露在URL中，容易被查看到（如浏览器历史记录、服务器日志、网络嗅探等）。 不适合传递敏感信息（如密码）。可能导致CSRF攻击（如果操作是修改性的）。</li><li><strong>POST</strong>: 安全性相对较高。参数在请求体中，不会直接显示在URL中，相对隐蔽。但注意，这只是相对的，“安全”并非指加密，HTTP本身是明文的，要保证传输过程的安全需要使用HTTPS。</li></ul></li><li><strong>幂等性 (Idempotence)</strong>:<ul><li><strong>GET</strong>: 一般是幂等的。幂等性指多次执行相同的GET请求，对服务器资源的状态产生的影响是相同的（通常是无副作用的查询）。</li><li><strong>POST</strong>: 一般是非幂等的。多次执行相同的POST请求，可能会在服务器上产生不同的结果或多次创建资源（例如，多次提交订单会创建多个订单）。</li></ul></li><li><strong>缓存</strong>:<ul><li><strong>GET</strong>: GET请求的结果可以被浏览器主动缓存，也可以被网络中的代理服务器缓存。</li><li><strong>POST</strong>: POST请求的结果默认不被浏览器缓存，也不能被代理服务器缓存（除非有明确的Cache-Control或Expires头）。</li></ul></li><li><strong>用途</strong>:<ul><li><strong>GET</strong>: 主要用于从服务器获取（索取）数据，如查询信息、请求页面等。</li><li><strong>POST</strong>: 主要用于向服务器提交数据，导致服务器状态的改变，如创建资源、更新资源、提交表单等。</li></ul></li><li><strong>浏览器行为</strong>:<ul><li>后退/刷新：GET请求的页面后退或刷新通常无害；POST请求的页面后退或刷新，浏览器一般会提示用户是否重新提交表单数据。</li><li>书签：GET请求的URL可以被收藏为书签；POST请求通常不能。</li></ul></li></ol><p>PDF中提到“GET和POST只是发送机制不同,并不是一个取一个发!” 这是强调两者本质上都是发送请求给服务器，但其设计意图和规范用途是不同的。</p>"
        },
        {
            "id": "java-basic-24",
            "question": "24、Cookie 和Session 的区别",
            "difficulty": "★",
            "answer": "<p>Cookie 和 Session 都是用于在Web应用程序中跟踪用户状态和会话管理的技术，但它们在存储位置、数据大小、安全性、生命周期等方面有显著区别：</p><ol><li><strong>存储位置</strong>:<ul><li><strong>Cookie</strong>: 数据存储在**客户端浏览器**中。 Web服务器通过HTTP响应头（<code>Set-Cookie</code>）将Cookie发送给浏览器，浏览器在后续对该服务器的请求中，会自动通过HTTP请求头（<code>Cookie</code>）将相关的Cookie发送回去。</li><li><strong>Session</strong>: 数据存储在**Web服务器端**。 服务器为每个用户会话创建一个唯一的Session ID，并将这个Session ID通过Cookie（最常见的方式，名为JSESSIONID等）或其他方式（如URL重写）发送给客户端。客户端后续请求时带上Session ID，服务器根据ID找到对应的Session数据。</li></ul></li><li><strong>数据类型和大小限制</strong>:<ul><li><strong>Cookie</strong>: 通常只能存储少量文本数据（字符串类型），大小一般限制在4KB左右（具体因浏览器而异）。</li><li><strong>Session</strong>: 理论上可以存储任意类型的Java对象（只要对象是可序列化的），数据大小主要受服务器内存限制。</li></ul></li><li><strong>安全性</strong>:<ul><li><strong>Cookie</strong>: 由于存储在客户端，相对不安全。数据容易被用户查看、篡改，甚至被恶意脚本窃取（XSS攻击）。敏感信息不应直接存储在Cookie中，或者需要加密。</li><li><strong>Session</strong>: 相对安全，因为实际数据存储在服务器端。客户端只持有无意义的Session ID。但如果Session ID被劫持（Session Hijacking），攻击者也可能冒充用户访问Session数据。因此，保护Session ID的传输安全（如使用HTTPS）很重要。</li></ul></li><li><strong>生命周期</strong>:<ul><li><strong>Cookie</strong>: 生命周期可以由服务器设置（通过<code>Expires</code>或<code>Max-Age</code>属性）。可以是会话Cookie（浏览器关闭即失效）或持久Cookie（存储在硬盘上，直到过期时间到达或被用户删除）。</li><li><strong>Session</strong>: 生命周期通常是用户会话期间。当用户关闭浏览器（如果Session ID通过会话Cookie传递）或Session在服务器端因超时（可配置，如30分钟无活动）而被销毁时，Session会失效。</li></ul></li><li><strong>对服务器的资源消耗</strong>:<ul><li><strong>Cookie</strong>: 基本不占用服务器资源，因为数据存储在客户端。</li><li><strong>Session</strong>: 会占用服务器的内存资源来存储Session对象。如果并发用户量大，或者Session中存储的数据过多，可能会对服务器内存造成压力。在分布式环境中，Session共享也是一个需要考虑的问题（如使用粘性Session、Session复制、或集中式Session存储如Redis）。</li></ul></li><li><strong>工作方式</strong>:<ul><li><strong>Cookie</strong>: 浏览器自动管理，每次请求时携带匹配的Cookie。</li><li><strong>Session</strong>: 需要服务器端维护Session数据，并通过Session ID与客户端关联。</li></ul></li><li><strong>客户端禁用Cookie的影响</strong>:<ul><li>如果客户端禁用了Cookie，依赖于Cookie的Session机制将无法正常工作（除非采用URL重写等替代方案传递Session ID）。而Cookie本身如果被禁用，则完全无法使用。</li></ul></li></ol><p><strong>总结：</strong>Cookie轻量，存储在客户端，适合存少量非敏感信息；Session存储在服务器端，相对安全，适合存储用户会话相关的复杂或敏感信息。</p>"
        }
    ]
            },
            {
                "chapterTitle": "第二章-Java高级篇",
    "questions": [
        {
            "id": "java-adv-1",
            "question": "1. HashMap底层源码",
            "difficulty": "★★★",
            "answer": "<p>HashMap的底层结构在JDK1.7中由<strong>数组+链表</strong>实现,在JDK1.8中由<strong>数组+链表+红黑树</strong>实现。</p><p><strong>JDK1.8之后Put方法 (putVal部分源码示例):</strong></p><div class=\"code-block\"><code>final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {\n    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;\n    // 1. 判断当前哈希表是否为空,如果为空则进行初始化 (resize 方法会初始化)\n    if ((tab = table) == null || (n = tab.length) == 0)\n        n = (tab = resize()).length;\n    // 2. 判断相应的哈希桶位置是否有元素,如果当前哈希桶为空则直接插入新节点\n    if ((p = tab[i = (n - 1) &amp; hash]) == null)\n        tab[i] = newNode(hash, key, value, null);\n    // 3. 如果哈希桶不为空 (发生哈希冲突)\n    else {\n        Node&lt;K,V&gt; e; K k;\n        // 3a. 判断桶内第一个元素的key是否与待插入的key相同 (hash值和equals都相同)\n        if (p.hash == hash &amp;&amp;\n            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))\n            e = p; // 如果相同,直接覆盖\n        // 3b. 判断当前桶是否是红黑树结构\n        else if (p instanceof TreeNode)\n            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 调用红黑树的插入方法\n        // 3c. 如果是链表结构\n        else {\n            for (int binCount = 0; ; ++binCount) { // 遍历链表\n                // 到达链表尾部,说明没有相同的key,则直接插入到链表尾部\n                if ((e = p.next) == null) {\n                    p.next = newNode(hash, key, value, null);\n                    // 判断链表长度是否达到阈值 (TREEIFY_THRESHOLD, 默认为8), 看是否需要将链表转化为红黑树\n                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                        treeifyBin(tab, hash); // 注意: treeifyBin不仅仅是转红黑树,还会检查table长度是否小于MIN_TREEIFY_CAPACITY(默认64),如果小于会优先扩容\n                    break;\n                }\n                // 如果在链表中找到相同的key,跳出循环,进行value替换\n                if (e.hash == hash &amp;&amp;\n                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))\n                    break;\n                p = e;\n            }\n        }\n        // 4. 如果找到了已存在的key (e不为null), 则替换旧值\n        if (e != null) { // existing mapping for key\n            V oldValue = e.value;\n            if (!onlyIfAbsent || oldValue == null)\n                e.value = value;\n            afterNodeAccess(e); // 回调方法 (例如 LinkedHashMap 中用于维护访问顺序)\n            return oldValue;\n        }\n    }\n    ++modCount; // 修改次数增加\n    // 5. 判断实际元素数量是否超过阈值,如果超过则扩容\n    if (++size &gt; threshold)\n        resize();\n    afterNodeInsertion(evict); // 回调方法\n    return null;\n}</code></div><p>HashMap基于哈希表的Map接口实现,是以key-value存储形式存在。它的实现不是同步的，这意味着它不是线程安全的。它的key、value都可以为null。此外,HashMap中的映射不是有序的。</p><p><strong>JDK1.8 之前</strong>: HashMap 由数组+链表组成。数组是HashMap的主体，链表主要为了解决哈希冲突（“拉链法”）。</p><p><strong>JDK1.8以后</strong>: 在解决哈希冲突时有较大变化。当链表长度大于阈值（默认为8）并且当前数组的长度大于64时，链表会转换为红黑树存储，以提高查询效率从O(n)到O(log n)。</p><p><strong>补充</strong>: 将链表转换成红黑树前会判断，即使链表长度大于8，但数组长度小于64时，并不会转为红黑树，而是优先进行数组扩容。这是为了避免在数组较小时红黑树操作（左旋、右旋、变色）带来的额外开销，此时搜索时间相对也较快。)</em></p>"
        },
        {
            "id": "java-adv-2",
            "question": "2、JVM内存分哪几个区,每个区的作用是什么",
            "difficulty": "★★",
            "answer": "<p>Java虚拟机主要分为以下几个区（运行时数据区）:</p><ol><li><strong>方法区 (Method Area)</strong>:<ul><li>有时候也称为永久代(PermGen)，但在JDK 1.8后被元空间(Metaspace)取代，元空间使用的是本地内存。 [cite: 32]</li><li>主要用来存储已被虚拟机加载的类信息、常量、静态变量和即时编译器编译后的代码等数据。 [cite: 32]</li><li>该区域是被线程共享的。 [cite: 32]</li><li>方法区里有一个运行时常量池，用于存放静态编译产生的字面量和符号引用，具有动态性。 [cite: 34]</li></ul></li><li><strong>虚拟机栈 (VM Stack / Java Stack)</strong>:<ul><li>平常所称的栈内存，它为Java方法服务。 [cite: 34] 每个方法在执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接和方法出口等信息。 [cite: 34]</li><li>虚拟机栈是线程私有的，它的生命周期与线程相同。 [cite: 34]</li><li>局部变量表里存储的是基本数据类型、returnAddress类型和对象引用。 [cite: 34]</li></ul></li><li><strong>本地方法栈 (Native Method Stack)</strong>:<ul><li>与虚拟机栈类似，只不过本地方法栈为Native方法（通常是C/C++实现）服务。 [cite: 34]</li></ul></li><li><strong>堆 (Heap)</strong>:<ul><li>Java堆是所有线程所共享的一块内存区域，在虚拟机启动时创建。 [cite: 34]</li><li>几乎所有的对象实例都在这里创建，因此该区域经常发生垃圾回收操作。 [cite: 34] (通常分为年轻代和老年代)</li></ul></li><li><strong>程序计数器 (Program Counter Register)</strong>:<ul><li>一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。 [cite: 34]</li><li>字节码解释器工作时通过改变这个计数值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理和线程恢复等功能都需要依赖这个计数器完成。 [cite: 34]</li><li>此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 [cite: 34]</li><li>线程私有。</li></ul></li></ol><p>备注: JEP 122 移除了永久代，JDK 1.8之后，类的元数据放到了元空间（Metaspace），字符串常量池和静态变量放到了Java堆中。 [cite: 34]</p>"
        },
        {
            "id": "java-adv-3",
            "question": "3、Java中垃圾收集的方法有哪些",
            "difficulty": "★",
            "answer": "<p>Java中的垃圾收集方法通常结合分代回收思想，主要有以下几种算法：</p><ol><li><strong>复制算法 (Copying)</strong>:<ul><li>常用于年轻代（新生代）的Minor GC。 [cite: 34]</li><li>原理：将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</li><li>优点：实现简单，运行高效，不容易产生内存碎片。 [cite: 34]</li><li>缺点：将内存缩小为了原来的一半，代价较高，比较耗内存。 [cite: 34]</li><li>新生代的Eden区和两个Survivor区（From, To）就是用了这种算法的变种（Appel式回收）。</li></ul></li><li><strong>标记-清除算法 (Mark-Sweep)</strong>:<ul><li>常用于老年代。 [cite: 34]</li><li>原理：算法分为“标记”和“清除”两个阶段。首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 [cite: 34]</li><li>优点：实现相对简单。</li><li>缺点：效率不高（标记和清除两个过程的效率都不高）；会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 [cite: 34]</li></ul></li><li><strong>标记-整理算法 (Mark-Compact)</strong>:<ul><li>也常用于老年代。 [cite: 34]</li><li>原理：标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 [cite: 34]</li><li>优点：解决了内存碎片问题，清扫后内存规整。 [cite: 34]</li><li>缺点：效率较低，需要移动对象，过程相对复杂。 [cite: 34]</li></ul></li></ol><p>现代的垃圾收集器通常会混合使用这些算法，例如：新生代采用复制算法，老年代采用标记-清除或标记-整理算法（或者它们的结合）。</p>"
        },
        {
            "id": "java-adv-4",
            "question": "4、如何判断一个对象是否存活(或者GC对象的判定方法)",
            "difficulty": "★",
            "answer": "<p>判断一个对象是否存活，主要有两种方法：</p><ol><li><strong>引用计数法 (Reference Counting)</strong>:<ul><li>给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1。 [cite: 34] 任何时刻计数器为零的对象就是不可能再被使用的。 [cite: 34]</li><li><strong>优点</strong>: 实现简单，判定效率高。</li><li><strong>缺点</strong>: 很难解决对象之间互相循环引用的问题。 [cite: 35] 例如对象A引用对象B，对象B也引用对象A，此时它们的引用计数器都不为零，但实际上这两个对象可能已经无法通过其他途径访问，应该被回收。因此，主流的Java虚拟机都没有采用引用计数法来管理内存。 [cite: 35]</li></ul></li><li><strong>可达性分析算法 (Reachability Analysis)</strong>:<ul><li>这是当前主流的商用程序语言（如Java、C#）进行对象存活判定的算法。</li><li>该算法的基本思路就是通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain）。 [cite: 35]</li><li>当一个对象到GC Roots没有任何引用链相连时（即从GC Roots到这个对象不可达），则证明此对象是不可能再被使用的，即为“死对象”。 [cite: 35]</li><li>在Java语言中，可作为GC Roots的对象包括以下几种： [cite: 35]<ul><li>虚拟机栈（栈帧中的本地变量表）中引用的对象。 [cite: 35]</li><li>方法区中类静态属性引用的对象。 [cite: 35]</li><li>方法区中常量引用的对象。 [cite: 35]</li><li>本地方法栈中JNI（即通常所说的Native方法）引用的对象。 [cite: 35]</li><li>Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如NullPointerException、OutOfMemoryError）等，还有系统类加载器。</li><li>被同步锁（synchronized关键字）持有的对象。</li><li>反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。</li></ul></li></ul></li></ol>"
        },
        {
            "id": "java-adv-5",
            "question": "5、什么情况下会产生StackOverflowError (栈溢出) 和OutOfMemoryError (堆溢出)怎么排查",
            "difficulty": "★★",
            "answer": "<p><strong>1. StackOverflowError (栈溢出)</strong>: 当线程请求的栈深度大于虚拟机所允许的深度时会抛出StackOverflowError。 [cite: 35] 每个线程都有自己的栈，栈的大小是有限的。</p><ul><li><strong>常见原因</strong>:<ul><li>无限递归调用（最常见原因）。 [cite: 35]</li><li>执行了大量方法调用，导致线程栈空间耗尽。 [cite: 35]</li><li>方法内声明了海量的局部变量 (较少见，但理论上可能)。 [cite: 35]</li><li>代码中有栈上分配大对象的逻辑，并且要求的内存较大 (如某些JNI调用在栈上分配大缓存)。 [cite: 35]</li></ul></li><li><strong>排查方法</strong>:<ul><li>查看异常堆栈跟踪信息，定位发生无限递归或过多方法调用的代码位置。</li><li>检查递归的终止条件是否正确。</li><li>考虑优化算法，减少方法调用深度。</li><li>可以通过<code>-Xss</code>参数调整线程栈的大小 (需谨慎，过大会减少可创建线程数)。</li></ul></li></ul><p><strong>2. OutOfMemoryError (堆溢出)</strong>: 当Java虚拟机无法再为新对象分配内存，并且垃圾收集器也无法回收更多内存时会抛出OutOfMemoryError。这通常指Java堆内存不足。</p><ul><li><strong>常见原因</strong>:<ul><li>内存中加载的数据量过于庞大，例如一次从数据库查询出过多数据并存储在集合中。 [cite: 36]</li><li>集合类（如List, Map）中有对对象的强引用，使用完后未及时清空（例如置为null），导致JVM无法回收这些对象，造成内存泄漏。 [cite: 36]</li><li>代码中存在死循环或循环产生过多重复的对象实体。 [cite: 36]</li><li>启动参数内存值设定的过小 (例如 <code>-Xmx</code>, <code>-Xms</code>)。 [cite: 36]</li><li>永久代/元空间不足 (PermGen/Metaspace OutOfMemoryError): 如果加载了大量的类、方法、常量等，可能导致此区域溢出。</li><li>堆外内存溢出 (Direct Buffer Memory OutOfMemoryError): 使用了NIO的DirectByteBuffer，但没有正确管理。</li></ul></li><li><strong>排查方法</strong>:<ul><li>分析错误信息，确定是哪个内存区域溢出 (例如 \"Java heap space\", \"PermGen space\", \"Metaspace\", \"Direct buffer memory\")。</li><li>使用内存分析工具（如MAT - Memory Analyzer Tool, JVisualVM, JProfiler, YourKit等）分析堆转储文件（heap dump）。可以在OOM发生时通过JVM参数自动生成堆转储文件 (例如 <code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path/to/dump.hprof</code>)。</li><li>内存分析工具可以帮助找到：<ul><li>占用内存最多的对象（Shallow Heap vs Retained Heap）。</li><li>对象的引用链，从而定位内存泄漏的源头。</li><li>是否存在不合理的大集合或对象。</li></ul></li><li>检查代码中是否有资源未关闭（如文件流、数据库连接等）。</li><li>检查是否有不合理的缓存机制。</li><li>适当调整JVM启动参数 (如<code>-Xms</code>, <code>-Xmx</code>, <code>-XX:MaxMetaspaceSize</code>等)。 [cite: 36]</li><li>对于栈溢出和堆溢出的代码演示：<em>[图片占位符: 栈溢出和堆溢出Java代码示例及运行结果 - 根据PDF Page 18, CSDN @leader_song]</em> [cite: 38, 39, 40, 41]</li></ul></li></ul><p><em>参考链接: <a href='https://www.cnblogs.com/boboooo/p/13164071.html' target='_blank'>cnblogs.com/boboooo/p/13164071.html</a> [cite: 36]</em></p>"
        },
        {
            "id": "java-adv-6",
            "question": "6、什么是线程池,线程池有哪些(创建)",
            "difficulty": "★",
            "answer": "<p><strong>什么是线程池</strong>:</p><p>线程池是一种线程使用和管理的机制。它会预先创建一定数量的线程并保存在一个池中。当有任务需要执行时，不是立即创建新线程，而是从池中获取一个空闲线程来执行任务。任务执行完毕后，线程并不会销毁，而是返回池中等待下一个任务。 [cite: 42] 这样可以避免频繁创建和销毁线程带来的开销，节省了开辟子线程的时间，提高了代码执行效率。 [cite: 42]</p><p><strong>线程池的创建方式 (通过<code>java.util.concurrent.Executors</code>工具类提供的静态方法)</strong>:</p><p>在JDK的<code>java.util.concurrent.Executors</code>中提供了生成多种线程池的静态方法： [cite: 42]</p><ol><li><strong><code>Executors.newCachedThreadPool()</code></strong>:<ul><li>创建一个可缓存线程池。 [cite: 42, 43] 如果线程池长度超过处理需要，可灵活回收空闲线程（默认60秒），若无可回收，则新建线程。 [cite: 43]</li><li>特点：工作线程的创建数量几乎没有限制（理论上为Integer.MAX_VALUE）。 [cite: 43] 如果长时间没有任务提交导致工作线程空闲，则该工作线程将自动终止。 [cite: 43]</li><li>注意：使用时需控制任务数量，否则大量线程并发可能导致系统瘫痪。 [cite: 43]</li></ul></li><li><strong><code>Executors.newFixedThreadPool(int nThreads)</code></strong>:<ul><li>创建一个指定工作线程数量的定长线程池。 [cite: 42, 43] 每当提交一个任务就创建一个工作线程（如果当前线程数小于核心线程数），如果工作线程数量达到线程池最大数，则将提交的任务存入到任务队列中。 [cite: 43]</li><li>特点：是一个典型且优秀的线程池，能提高程序效率并节省创建线程的开销。 [cite: 43] 但在线程池空闲时，不会释放工作线程，会占用一定系统资源。 [cite: 43]</li></ul></li><li><strong><code>Executors.newSingleThreadExecutor()</code></strong>:<ul><li>创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务。 [cite: 43]</li><li>特点：保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 [cite: 43] 如果这个线程异常结束，会有另一个线程取代它，保证顺序执行。 [cite: 43]</li></ul></li><li><strong><code>Executors.newScheduledThreadPool(int corePoolSize)</code></strong>:<ul><li>创建一个定长的线程池，支持定时的以及周期性的任务执行。 [cite: 42, 43] 例如延迟3秒执行。 [cite: 43]</li></ul></li></ol><p><strong>重要提示</strong>:</p><p>阿里巴巴《Java开发手册》中强制线程池不允许使用<code>Executors</code>去创建，而是通过<code>ThreadPoolExecutor</code>的方式进行自定义。 [cite: 42] 这样的处理方式让开发者更加明确线程池的运行规则，规避资源耗尽的风险。实际开发中也推荐直接使用<code>ThreadPoolExecutor</code>进行详细配置。</p>"
        },
        {
            "id": "java-adv-7",
            "question": "7、为什么要使用线程池",
            "difficulty": "★",
            "answer": "<p>使用线程池主要有以下几个优点：</p><ol><li><strong>降低资源消耗</strong>: 通过重复利用已创建的线程，降低线程创建和销毁造成的系统开销。 [cite: 43] 创建和销毁线程是昂贵的操作。</li><li><strong>提高响应速度</strong>: 当任务到达时，可以不需要等待线程创建就能立即执行，因为线程池中通常有立即可用的线程。 [cite: 43]</li><li><strong>提高线程的可管理性</strong>: 线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性。 [cite: 43] 使用线程池可以进行统一的分配、调优和监控，可以控制最大并发线程数，防止因线程过多导致系统崩溃。 [cite: 43]</li><li><strong>提供更多功能</strong>: 线程池可以提供定时执行、周期执行、单线程执行、并发数控制等更丰富的功能。</li></ol><p>线程池的工作主要是控制运行的线程数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，超出的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 [cite: 43]</p>"
        },
        {
            "id": "java-adv-8",
            "question": "8、线程池底层工作原理",
            "difficulty": "★",
            "answer": "<p>以<code>ThreadPoolExecutor</code>为例，其核心工作流程如下：</p><ol><li><strong>线程池创建初期</strong>: 线程池刚创建的时候，里面可能没有任何线程。等到有任务过来的时候才会创建线程。 [cite: 44] (也可以调用 <code>prestartAllCoreThreads()</code>或<code>prestartCoreThread()</code>方法预创建核心线程)。 [cite: 44]</li><li><strong>提交任务 (调用<code>execute()</code>)</strong>:<ul><li>如果当前运行的工作线程数小于核心线程数 (<code>corePoolSize</code>)，则线程池会直接创建新的线程来执行这个任务。 [cite: 44]</li></ul></li><li><strong>任务入队</strong>:<ul><li>如果当前工作线程数量大于或等于核心线程数 (<code>corePoolSize</code>)，线程池会将任务放入内部的任务队列 (<code>workQueue</code>) 中缓存。 [cite: 44]</li></ul></li><li><strong>创建非核心线程</strong>:<ul><li>如果任务队列已满，并且线程池中当前工作线程的数量小于最大线程数 (<code>maximumPoolSize</code>)，线程池还是会创建新的非核心线程来执行这个任务。 [cite: 44]</li></ul></li><li><strong>执行拒绝策略</strong>:<ul><li>如果任务队列已满，并且线程池中的线程数量已达到最大线程数 (<code>maximumPoolSize</code>)，这个时候会执行拒绝策略 (<code>RejectedExecutionHandler</code>)。 [cite: 44] Java线程池默认的策略是<code>AbortPolicy</code>，即抛出<code>RejectedExecutionException</code>异常。 [cite: 44]</li></ul></li><li><strong>线程复用与销毁</strong>:<ul><li>当一个工作线程完成任务后，它会从任务队列中获取下一个任务来执行。</li><li>如果线程池中的线程数量超过核心线程数，当一个非核心线程的空闲时间超过了<code>keepAliveTime</code>，这个线程就会被终止，直到线程数量不大于核心线程数为止（除非设置了<code>allowCoreThreadTimeOut(true)</code>，核心线程也会超时终止）。</li></ul></li></ol>"
        },
        {
            "id": "java-adv-9",
            "question": "9. ThreadPoolExecutor对象有哪些参数怎么设定核心线程数和最大线程数拒绝策略有哪些",
            "difficulty": "★",
            "answer": "<p><code>ThreadPoolExecutor</code>是线程池的核心实现类，其构造函数有7个主要参数：</p><ol><li><strong><code>corePoolSize</code> (核心线程数)</strong>: 线程池中保持存活的线程数量，即使它们是空闲的。 [cite: 44] 如果<code>allowCoreThreadTimeOut</code>设置为true（默认为false），核心线程在空闲时间超过<code>keepAliveTime</code>时也会被回收。 [cite: 44]</li><li><strong><code>maximumPoolSize</code> (最大线程数)</strong>: 线程池能容纳的最大线程数量。 [cite: 44] 当线程数达到最大且工作队列已满时，新任务会触发拒绝策略。 [cite: 44] (当使用无界队列如<code>LinkedBlockingDeque</code>时，此参数可能无效，因为队列永远不会满，线程数不会超过<code>corePoolSize</code>)。 [cite: 44]</li><li><strong><code>keepAliveTime</code> (存活时间)</strong>: 当线程池中线程数量超过<code>corePoolSize</code>时，多余的空闲线程在被终止前等待新任务的最长时间。 [cite: 44] 核心线程的超时回收也受此参数和<code>allowCoreThreadTimeOut</code>影响。 [cite: 44]</li><li><strong><code>unit</code> (时间单位)</strong>: <code>keepAliveTime</code>的时间单位 (如<code>TimeUnit.SECONDS</code>, <code>TimeUnit.MILLISECONDS</code>等)。 [cite: 44]</li><li><strong><code>workQueue</code> (任务队列)</strong>: 用于保存等待执行的任务的阻塞队列。 [cite: 44] 常用的有：<ul><li><code>SynchronousQueue</code>: 不存储元素的队列，每个插入操作必须等待一个移除操作。</li><li><code>LinkedBlockingDeque</code>: 基于链表的阻塞队列，容量可以是有界的也可以是无界的（默认<code>Integer.MAX_VALUE</code>）。 [cite: 44]</li><li><code>ArrayBlockingQueue</code>: 基于数组的有界阻塞队列。 [cite: 44]</li></ul></li><li><strong><code>threadFactory</code> (线程工厂)</strong>: 用于创建新线程的工厂。 [cite: 44] 可以通过它自定义线程的名称、是否为守护线程、优先级等。 [cite: 44] 默认会直接新建线程。 [cite: 44]</li><li><strong><code>handler</code> (<code>RejectedExecutionHandler</code> 拒绝策略)</strong>: 当队列和线程池都满了，无法处理新任务时所采取的策略。 [cite: 44] 内置策略有：<ul><li><code>AbortPolicy</code> (默认): 直接抛出<code>RejectedExecutionException</code>异常。 [cite: 45]</li><li><code>CallerRunsPolicy</code>: 由调用<code>execute</code>方法的线程来执行该任务。 [cite: 45]</li><li><code>DiscardPolicy</code>: 直接丢弃任务，不处理也不抛异常。 [cite: 46]</li><li><code>DiscardOldestPolicy</code>: 丢弃阻塞队列中靠最前的任务，并尝试执行当前任务。 [cite: 45]</li><li>也可以根据应用场景实现<code>RejectedExecutionHandler</code>接口自定义策略。 [cite: 46]</li></ul></li></ol><p><strong>设定核心线程数和最大线程数</strong>:</p><p>线程池大小的设置需要根据任务的特性、执行时长以及系统资源来综合考虑： [cite: 44]</p><ul><li><strong>CPU密集型任务</strong>: 任务主要消耗CPU资源，计算量大，响应时间快。 [cite: 44] CPU利用率高。线程数不宜过多，一般设置为CPU核心数或CPU核心数+1，以减少线程上下文切换的开销。 [cite: 44]</li><li><strong>IO密集型任务</strong>: 任务主要涉及IO操作（如网络请求、文件读写），CPU空闲时间较多，CPU利用率不高。 [cite: 44] 这种情况下可以设置较多的线程数，例如CPU核心数的2倍。 [cite: 44] 或根据公式：<code>线程数 = CPU核心数 / (1 - 阻塞系数)</code> (阻塞系数通常在0.8-0.9之间)。另一个经验公式是：最佳线程数目 = <code>((线程等待时间 + 线程CPU时间) / 线程CPU时间) * CPU数目</code>。 [cite: 45]</li></ul><p>实际中通常需要通过压力测试来调整和优化线程池参数。</p>"
        },
        {
            "id": "java-adv-10",
            "question": "10、常见线程安全的并发容器有哪些",
            "difficulty": "★",
            "answer": "<p>Java的<code>java.util.concurrent</code>包下提供了许多线程安全的并发容器，常见的有：</p><ul><li><code>CopyOnWriteArrayList</code> 和 <code>CopyOnWriteArraySet</code>: 它们采用写时复制（Copy-On-Write）策略实现线程安全。 [cite: 46] 适用于读多写少的场景。写入操作（add, set, remove等）会创建一个底层数组的新副本进行修改，开销较大；但读取操作不需要加锁，非常快。</li><li><code>ConcurrentHashMap</code>: 采用分段锁（JDK 1.7及之前）或CAS + synchronized（JDK 1.8及之后，锁粒度更细）的方式实现线程安全。 [cite: 46] 是<code>Hashtable</code>和<code>Collections.synchronizedMap</code>的推荐替代品，性能更好。</li></ul><p>除了PDF中简要提及的以上三种，并发包中还有其他重要的线程安全容器，例如：</p><p><strong>Queue/Deque类型 (阻塞队列)</strong>:</p><ul><li><code>ArrayBlockingQueue</code>: 基于数组的有界阻塞队列。</li><li><code>LinkedBlockingQueue</code>: 基于链表的阻塞队列（容量可选，默认为无界）。</li><li><code>PriorityBlockingQueue</code>: 支持优先级的无界阻塞队列。</li><li><code>DelayQueue</code>: 无界阻塞延迟队列，元素只有在其指定的延迟时间到了，才能够从队列中获取。</li><li><code>SynchronousQueue</code>: 不存储元素的阻塞队列，每个插入操作必须等待一个移出操作。</li><li><code>LinkedTransferQueue</code>: 基于链表的无界阻塞队列，功能更强大。</li><li><code>LinkedBlockingDeque</code>: 基于链表的双端阻塞队列。</li></ul><p><strong>Set类型</strong>:</p><ul><li><code>ConcurrentSkipListSet</code>: 基于跳表实现的有序Set，支持较高的并发。</li></ul><p><strong>Map类型</strong>:</p><ul><li><code>ConcurrentSkipListMap</code>: 基于跳表实现的有序Map，支持较高的并发。</li></ul><p>这些并发容器通过不同的机制（如锁、CAS、写时复制、特定数据结构）来保证在多线程环境下的数据一致性和操作的原子性。</p>"
        },
        {
            "id": "java-adv-11",
            "question": "11、Atomic原子类了解多少原理是什么",
            "difficulty": "★",
            "answer": "<p>Java的<code>java.util.concurrent.atomic</code>包提供了一系列原子操作类，用于在多线程环境下执行无锁的原子更新操作，相比使用<code>synchronized</code>等锁机制，通常具有更高的性能。</p><p><strong>主要分类</strong>: [cite: 46]</p><ul><li><strong>基本类型原子类</strong>: <code>AtomicInteger</code> (整型原子类), <code>AtomicLong</code> (长整型原子类), <code>AtomicBoolean</code> (布尔型原子类)。 [cite: 46]</li><li><strong>数组类型原子类</strong>: <code>AtomicIntegerArray</code> (整形数组原子类), <code>AtomicLongArray</code> (长整形数组原子类), <code>AtomicReferenceArray</code> (引用类型数组原子类)。 [cite: 46] (对数组中的元素进行原子更新)。</li><li><strong>引用类型原子类</strong>:<ul><li><code>AtomicReference</code>: 引用类型原子类。 [cite: 46]</li><li><code>AtomicStampedReference</code>: 原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决使用CAS进行原子更新时可能出现的ABA问题。 [cite: 46]</li><li><code>AtomicMarkableReference</code>: 原子更新带有标记位的引用类。 [cite: 46]</li></ul></li><li><strong>字段更新器原子类</strong>: <code>AtomicIntegerFieldUpdater</code> (原子更新整形字段的更新器), <code>AtomicLongFieldUpdater</code> (原子更新长整形字段的更新器), <code>AtomicReferenceFieldUpdater</code> (原子更新引用类型字段的更新器)。 [cite: 46] (对指定对象的volatile字段进行原子更新)。</li><li><strong>JDK 8新增的累加器 (未在PDF图片中完全列出，但属于原子类范畴)</strong>: <code>LongAdder</code>, <code>DoubleAdder</code>, <code>LongAccumulator</code>, <code>DoubleAccumulator</code> (在高并发下比<code>AtomicLong</code>等有更好的性能，通过分散热点更新)。</li></ul><p><strong>原理</strong>:</p><p>Atomic原子类的实现核心是<strong>CAS (Compare-And-Swap) 操作</strong>，结合<code>volatile</code>关键字和<code>Unsafe</code>类（部分实现）。 [cite: 46]</p><ol><li><strong>CAS (Compare-And-Swap)</strong>: CAS是一种CPU指令级别的乐观锁机制。它包含三个操作数——内存位置V（变量的当前值）、预期原值A（上次读取到的值）、新值B。 [cite: 47] 当且仅当内存位置V的值与预期原值A相同时，处理器才会原子地将该位置的值更新为新值B。否则，不做任何操作，并通常返回操作失败。这个过程是原子的。<code>AtomicInteger</code>类利用CAS来保证原子操作。 [cite: 46]</li><li><strong><code>volatile</code>关键字</strong>: Atomic类中的值通常被声明为<code>volatile</code>，以保证多线程之间的可见性（即一个线程修改了值，其他线程能立即看到最新的值）和禁止指令重排。 [cite: 47] JVM总是可以保证任意时刻的任何线程总能拿到该变量的最新值。 [cite: 47]</li><li><strong><code>sun.misc.Unsafe</code>类</strong>: 底层实现上，很多Atomic类依赖于<code>sun.misc.Unsafe</code>类提供的一些本地方法（native methods）来直接操作内存地址（如获取“原值”的内存地址，通过<code>objectFieldOffset()</code>方法获取<code>valueOffset</code> [cite: 47]）和执行CAS指令。</li></ol><p><strong>工作流程 (以<code>AtomicInteger.compareAndSet(expect, update)</code>为例)</strong>:</p><ol><li>读取当前内存中的值。</li><li>比较这个值是否与期望值<code>expect</code>相等。</li><li>如果相等，则尝试将内存中的值原子地更新为<code>update</code>。</li><li>如果比较不相等，说明在此期间值被其他线程修改了，更新失败，方法返回<code>false</code>。</li></ol><p>这种无锁的方式避免了线程阻塞和上下文切换的开销，在高并发场景下性能较好，从而避免了<code>synchronized</code>的高开销，执行效率大为提升。 [cite: 46]</p>"
        },
        {
            "id": "java-adv-12",
            "question": "12, synchronized底层实现是什么lock底层是什么有什么区别",
            "difficulty": "★★★",
            "answer": "<p><strong>Synchronized底层实现原理</strong>: [cite: 47]</p><ul><li><strong>方法级同步 (隐式)</strong>: JVM可以从方法常量池中的方法表结构 (method_info Structure) 中的<code>ACC_SYNCHRONIZED</code>访问标志来区分一个方法是否同步方法。 [cite: 47] 当方法调用时，调用指令将会检查方法的<code>ACC_SYNCHRONIZED</code>访问标志是否被设置。如果设置了，执行线程将先持有monitor（管程），然后再执行方法，最后在方法完成（无论是正常完成还是非正常完成）时释放monitor。 [cite: 47]</li><li><strong>代码块同步 (显式)</strong>: 利用<code>monitorenter</code>和<code>monitorexit</code>这两个字节码指令。 [cite: 47] 它们分别位于同步代码块的开始和结束位置。当JVM执行到<code>monitorenter</code>指令时，当前线程试图获取monitor对象的所有权。如果未加锁或者已经被当前线程所持有，就把锁的计数器+1；当执行<code>monitorexit</code>指令时，锁计数器-1；当锁计数器为0时，该锁就被释放了。 [cite: 47] 如果获取monitor对象失败，该线程则会进入阻塞状态，直到其他线程释放锁。 [cite: 47]</li><li><strong>Monitor (管程)</strong>: 每个Java对象都可以关联一个Monitor。当一个Monitor被持有后，它将处于锁定状态。线程执行<code>monitorenter</code>指令时尝试获取Monitor的所有权。</li><li><strong>锁升级</strong>: 为了提高性能，synchronized在JDK 1.6后引入了锁升级机制：偏向锁 -> 轻量级锁 -> 重量级锁。</li></ul><p><em>(参考: 一篇文章讲透synchronized底层实现原理_忘了带罗盘的船夫的博客-CSDN博客 [cite: 47])</em></p><p><strong>Lock (如ReentrantLock) 底层实现原理</strong>: [cite: 47]</p><ul><li><strong>AQS (AbstractQueuedSynchronizer)</strong>: Lock接口的实现类（如<code>ReentrantLock</code>）大多依赖于AQS框架。AQS是一个用于构建锁和同步器的基础框架。</li><li><strong>存储结构</strong>: AQS内部维护一个<code>int</code>类型的状态值<code>state</code>（volatile修饰，用于表示锁的状态变更，如是否被锁定，重入次数），以及一个FIFO的双向链表（CLH队列，用于存储等待中的线程）。 [cite: 47]</li><li><strong>获取锁过程</strong>: 本质上是通过CAS（Compare-And-Swap）操作来尝试修改<code>state</code>状态值。 [cite: 47] 如果成功，则获取锁。如果失败（例如<code>state</code>已被其他线程占用），则将当前线程包装成Node节点加入等待队列，并可能挂起线程（park）。</li><li><strong>释放锁过程</strong>: 修改<code>state</code>状态值，并唤醒等待队列中的后继节点（unpark）。 [cite: 47]</li><li><strong>CAS + 自旋</strong>: Lock大量使用CAS操作配合自旋尝试获取锁。 [cite: 47] 因此，根据CAS特性，Lock建议使用在低锁冲突的情况下。 [cite: 47]</li></ul><p><strong>Lock与synchronized的区别</strong>: [cite: 47, 48]</p><table><thead><tr><th>特性</th><th>synchronized</th><th>Lock (如ReentrantLock)</th></tr></thead><tbody><tr><td><strong>本质</strong></td><td>Java关键字，JVM层面实现。 [cite: 48]</td><td>接口和类，API层面实现 (<code>java.util.concurrent.locks</code>)。 [cite: 48]</td></tr><tr><td><strong>锁的获取与释放</strong></td><td>自动获取和释放（代码块结束或异常时JVM自动释放）。 [cite: 48]</td><td>需要手动获取（<code>lock()</code>）和释放（<code>unlock()</code>，必须在finally块中释放以保证锁一定被释放）。 [cite: 48]</td></tr><tr><td><strong>中断响应</strong></td><td>不可中断（除非抛异常）。 [cite: 47]</td><td>可中断（通过<code>lockInterruptibly()</code>方法），可响应中断。 [cite: 47]</td></tr><tr><td><strong>尝试获取锁</strong></td><td>不能。</td><td>可尝试获取锁（<code>tryLock()</code>, <code>tryLock(long time, TimeUnit unit)</code>），可带超时。 [cite: 47]</td></tr><tr><td><strong>公平性</strong></td><td>非公平锁。 [cite: 48]</td><td>可选择公平锁或非公平锁（通过构造函数指定，默认非公平）。 [cite: 48]</td></tr><tr><td><strong>条件变量 (Condition)</strong></td><td>只有一个隐式的条件队列 (通过锁对象的<code>wait()</code>, <code>notify()</code>, <code>notifyAll()</code>方法配合)。 [cite: 47]</td><td>可以绑定多个Condition对象，实现更灵活的线程间通信和分组唤醒（多路条件队列）。 [cite: 47]</td></tr><tr><td><strong>锁信息</strong></td><td>锁是一个对象，并且锁的信息保存在了对象头中（Mark Word）。 [cite: 48]</td><td>代码中通过int类型的state标识锁状态。 [cite: 48]</td></tr><tr><td><strong>锁升级</strong></td><td>有锁升级过程（偏向锁、轻量级锁、重量级锁）。 [cite: 48]</td><td>无锁升级过程（其实现基于AQS，是另一种机制）。 [cite: 48]</td></tr><tr><td><strong>同步模式</strong></td><td>仅提供独占模式。 [cite: 47]</td><td>可以提供独占模式（如ReentrantLock），也可以提供共享模式（如ReentrantReadWriteLock, Semaphore, CountDownLatch）。 [cite: 47]</td></tr></tbody></table>"
        },
        {
            "id": "java-adv-13",
            "question": "13、了解ConcurrentHashMap吗 为什么性能比HashTable高,说下原理",
            "difficulty": "★★",
            "answer": "<p><code>ConcurrentHashMap</code>是Java并发包中提供的一个线程安全的哈希表，用于替代<code>Hashtable</code>和通过<code>Collections.synchronizedMap(new HashMap&lt;&gt;())</code>创建的同步Map。</p><p><strong>为什么性能比Hashtable高</strong>:</p><p><code>Hashtable</code>（以及<code>synchronizedMap</code>）实现线程安全的方式是对整个Map进行同步，即所有访问<code>Hashtable</code>的方法（如<code>put</code>, <code>get</code>, <code>remove</code>等）都是<code>synchronized</code>修饰的。 [cite: 49] 这意味着在同一时间只允许一个线程访问该Map，锁的粒度非常大，严重限制了并发性能。当多个线程同时访问时，其他线程必须等待，导致高并发情况下效率低下。 [cite: 49]</p><p><code>ConcurrentHashMap</code>通过更细粒度的锁机制来提高并发性能： [cite: 49]</p><ul><li><strong>JDK 1.7及之前</strong>: 采用“<strong>分段锁 (Segment)</strong>”技术。 [cite: 49] <code>ConcurrentHashMap</code>内部由多个<code>Segment</code>组成，每个<code>Segment</code>本身是一个类似<code>HashMap</code>的小哈希表（继承自<code>ReentrantLock</code>），并且拥有自己独立的锁。 [cite: 49] 当对Map进行操作时，只需要锁定操作数据所在的那个<code>Segment</code>，而不是整个Map。这样，不同<code>Segment</code>上的操作可以并发进行，大大提高了并发访问的效率。默认<code>Segment</code>数量是16，意味着理论上可以支持16个线程并发写。</li><li><strong>JDK 1.8及之后</strong>: 放弃了分段锁的设计，改用<strong>CAS (Compare-And-Swap) + <code>synchronized</code>关键字</strong>（以及红黑树优化）。 [cite: 49] 底层数据结构仍然是Node数组+链表+红黑树。 [cite: 49]<ul><li>在写入操作（如<code>put</code>）时，如果数组的某个桶位（bin）是空的，则通过CAS尝试直接插入新节点。</li><li>如果桶位不为空（发生哈希冲突），则对该桶的头节点使用<code>synchronized</code>加锁。这个锁的粒度非常小，只锁住当前操作的那个桶的头节点，而不是整个Map或一个大的Segment。</li><li>这种设计进一步减小了锁的范围，提高了并发度。同时，<code>synchronized</code>在JDK 1.6之后有锁升级等优化，性能也很好。</li><li>读取操作（如<code>get</code>）大部分情况下是无锁的，通过volatile保证可见性。</li></ul></li></ul><p><strong>原理总结</strong>:</p><p><code>ConcurrentHashMap</code>的核心思想是<strong>减小锁的粒度</strong> (锁细化) [cite: 49]，允许多个线程在不冲突的情况下并发访问Map的不同部分，从而显著提升在高并发环境下的性能和吞吐量。而<code>Hashtable</code>的全局锁导致其成为并发瓶颈。</p>"
        },
        {
            "id": "java-adv-14",
            "question": "14, ConcurrentHashMap底层原理",
            "difficulty": "★★★",
            "answer": "<p><strong>JDK 1.7 中的 ConcurrentHashMap</strong>: [cite: 49]</p><ul><li><strong>数据结构</strong>: 由一个<code>Segment</code>数组和每个<code>Segment</code>内部的<code>HashEntry</code>数组（哈希桶）组成。<code>Segment</code>继承自<code>ReentrantLock</code>，充当锁的角色。 [cite: 49] <code>Segment</code>的数量一旦初始化就不能改变。 [cite: 49]</li><li><strong>Put操作</strong>: <ol><li>根据key的哈希值定位到具体的<code>Segment</code>。这个过程通常是通过对key的hash值进行位运算来确定Segment的索引。 [cite: 51]</li><li>对该<code>Segment</code>加锁 (调用<code>Segment</code>的<code>lock()</code>方法，或者在<code>put</code>方法内部如<code>tryLock()? null : scanAndLockForPut(key, hash, value)</code>来获取锁 [cite: 62])。</li><li>在<code>Segment</code>内部进行类似于<code>HashMap</code>的put操作（计算在<code>HashEntry</code>数组中的索引，处理冲突，插入或更新<code>HashEntry</code>）。如果是新节点，可能采用头插法。 [cite: 66]</li><li>如果<code>Segment</code>中的元素数量超过阈值并且数组长度小于最大容量，会进行扩容 (<code>rehash</code>)。 [cite: 68]</li><li>释放<code>Segment</code>的锁 (<code>unlock()</code>)。 [cite: 68]</li></ol></li><li><strong>ensureSegment方法</strong>: 如果根据hash计算出的Segment在<code>segments</code>数组中为null，则会调用<code>ensureSegment(j)</code>来初始化这个Segment。 [cite: 52] 这个方法会使用CAS操作来确保Segment的原子性创建和放入数组。 [cite: 61] 它会以<code>segments[0]</code>作为原型来创建新的Segment，包括容量、负载因子等。 [cite: 57, 58]</li><li><strong>Get操作</strong>: 大部分情况下不加锁。先定位<code>Segment</code>，再定位<code>HashEntry</code>。由于<code>HashEntry</code>的<code>value</code>和<code>next</code>指针是用<code>volatile</code>修饰的，可以保证可见性。</li><li><strong>Size操作</strong>: 计算size时，会先尝试不加锁地累加所有<code>Segment</code>的<code>count</code>值两次，如果两次结果一致则返回。不一致则会对所有<code>Segment</code>依次加锁再累加。</li></ul><p><em>[代码片段占位符: Java 7 ConcurrentHashMap put 及 ensureSegment 源码节选 - 根据PDF Page 23-24]</em> [cite: 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68]</p><p><strong>JDK 1.8 中的 ConcurrentHashMap</strong>: [cite: 68]</p><ul><li><strong>数据结构</strong>: 数组（<code>Node&lt;K,V&gt;[] table</code>）+ 链表 或 红黑树。 [cite: 68] 取消了<code>Segment</code>分段锁，锁的粒度更细，锁的是哈希桶的头节点。</li><li><strong>Put操作 (<code>putVal</code>方法)</strong>: [cite: 68] <ol><li>key和value不能为空。 [cite: 68] 计算hash值 (通过<code>spread()</code>方法)。 [cite: 68]</li><li>如果哈希表（<code>table</code>）未初始化，则调用<code>initTable()</code>进行初始化（CAS操作 + 自旋）。 [cite: 69]</li><li>根据key的哈希值计算在table数组中的索引<code>i</code>。</li><li>如果<code>table[i]</code>（即<code>tabAt(tab, i)</code>）为空，则通过CAS (<code>casTabAt</code>) 尝试直接插入新节点，成功则完成，不加锁。 [cite: 69]</li><li>如果<code>table[i]</code>的头节点哈希值为MOVED (-1)，表示正在扩容，则帮助扩容 (<code>helpTransfer</code>)。 [cite: 70]</li><li>否则（<code>table[i]</code>不为空且不是MOVED），对<code>table[i]</code>的头节点<code>f</code>使用<code>synchronized(f)</code>加锁： [cite: 71]<ul><li>再次检查<code>tabAt(tab, i) == f</code>确保节点未改变。 [cite: 71]</li><li>如果<code>f.hash &gt;= 0</code>，说明是链表头，则遍历链表。 [cite: 71] 如果找到key相同的节点，则更新value（除非<code>onlyIfAbsent</code>为true）。 [cite: 72] 如果未找到，则在链表尾部插入新节点。 [cite: 72] 如果链表长度达到阈值（<code>TREEIFY_THRESHOLD</code>，默认为8），则调用<code>treeifyBin</code>尝试将链表转换为红黑树（这还会检查table长度是否足够大，否则优先扩容）。 [cite: 73]</li><li>如果<code>f</code>是<code>TreeBin</code>（红黑树头），则调用红黑树的插入方法 (<code>putTreeVal</code>)。 [cite: 73]</li></ul></li><li>如果插入了新节点（<code>oldVal == null</code>），则调用<code>addCount(1L, binCount)</code>更新计数器，并检查是否需要触发扩容。 [cite: 74]</li></ol></li><li><strong>Get操作</strong>: 基本不加锁。通过<code>tabAt</code>（利用Unsafe类的方法）获取指定索引的节点，然后遍历链表或红黑树查找。由于<code>Node</code>的<code>val</code>和<code>next</code>是用<code>volatile</code>修饰的，保证了可见性。</li><li><strong>Size操作 (<code>size</code>, <code>mappingCount</code>)</strong>: 通过<code>baseCount</code>（CAS更新）和<code>CounterCell[]</code>数组（分散更新）来实现。写操作时，如果CAS更新<code>baseCount</code>失败，则会尝试更新<code>counterCells</code>数组中的某个元素。读取size时，累加<code>baseCount</code>和所有<code>CounterCell</code>的值。这是一种分摊计数的思想，减少高并发下的竞争。</li><li><strong>扩容 (<code>transfer</code>方法)</strong>: 多线程协作扩容。将旧table的数据迁移到新table（通常是两倍大小）。通过维护<code>transferIndex</code>来分配迁移任务给不同线程。</li></ul><p><em>[代码片段占位符: Java 8 ConcurrentHashMap putVal 源码节选 - 根据PDF Page 24-25]</em> [cite: 69, 70, 71, 72, 73, 74]</p>"
        },
        {
            "id": "java-adv-15",
            "question": "15、了解volatile关键字不",
            "difficulty": "★",
            "answer": "<p><code>volatile</code>是Java虚拟机提供的<strong>最轻量级</strong>的同步机制。它主要有两个作用：</p><ol><li><strong>保证可见性 (Visibility)</strong>:<ul><li>当一个共享变量被<code>volatile</code>修饰时，它会保证修改的值会立即被更新到主内存，当有其他线程需要读取该变量时，会去内存中读取新值。 [cite: 75]</li><li>这确保了多线程环境下，一个线程对<code>volatile</code>变量的修改对其他线程是立即可见的，避免出现“脏读”现象。 [cite: 75]</li></ul></li><li><strong>禁止指令重排序 (Ordering)</strong>:<ul><li><code>volatile</code>关键字通过插入内存屏障来禁止特定类型的编译器和处理器重排序，从而保证程序执行的有序性。 [cite: 75]</li><li>具体来说，它能保证：对<code>volatile</code>变量的写操作，其前面的所有普通写操作都已经完成并且对其他线程可见；对<code>volatile</code>变量的读操作，其后面的所有普通读操作都能看到<code>volatile</code>变量修改后的值。</li><li>这对于某些依赖操作顺序的场景非常重要，例如双重检查锁定（DCL）中的实例变量。</li><li>由于禁止了指令重排，所以JVM相关的优化可能会受到影响，效率可能会偏弱。 [cite: 75]</li></ul></li></ol><p><strong>与<code>synchronized</code>的区别 (部分)</strong>:</p><ul><li><code>volatile</code>仅能保证可见性和一定程度的有序性，但<strong>不保证原子性</strong>。例如，<code>volatile int i; i++;</code> 这个操作不是原子的。</li><li><code>volatile</code>不会造成线程阻塞，而<code>synchronized</code>可能会。 [cite: 75]</li></ul><p><strong>使用场景</strong>:</p><ul><li>状态标记量（如一个布尔标志，用于控制线程的终止）。</li><li>双重检查锁定（DCL）中的单例实例变量（需配合其他同步措施或正确使用）。</li><li>当一个变量的写入不依赖于当前值，或者能确保只有单个线程修改该变量的值时，可以用<code>volatile</code>来保证可见性。</li></ul>"
        },
        {
            "id": "java-adv-16",
            "question": "16、synchronized和volatile有什么区别",
            "difficulty": "★★",
            "answer": "<table><thead><tr><th>特性</th><th>synchronized</th><th>volatile</th></tr></thead><tbody><tr><td><strong>作用机制</strong></td><td>通过获取对象的监视器锁（monitor lock）来实现同步。它是一种悲观锁，锁定当前变量，只有当前线程可以访问，其他线程被阻塞。 [cite: 75]</td><td>通过内存屏障保证变量在多线程间的可见性（告诉JVM当前变量在寄存器中的值是不确定的，需要从主存中读取 [cite: 75]），并禁止指令重排序。</td></tr><tr><td><strong>保证的特性</strong></td><td>原子性、可见性、有序性。 [cite: 75]</td><td>可见性、一定程度的有序性 (不保证原子性)。 [cite: 75]</td></tr><tr><td><strong>使用范围</strong></td><td>修饰方法、代码块、类（静态方法）。 [cite: 75]</td><td>修饰成员变量、静态成员变量。 [cite: 75]</td></tr><tr><td><strong>线程阻塞</strong></td><td>可能会造成线程阻塞（当锁被其他线程持有时）。 [cite: 75]</td><td>不会造成线程阻塞。 [cite: 75]</td></tr><tr><td><strong>性能开销</strong></td><td>相对较大（涉及锁的获取和释放，上下文切换），但JDK1.6后有锁优化（偏向锁、轻量级锁、重量级锁）。</td><td>相对较小，是轻量级的同步机制。</td></tr><tr><td><strong>编译器优化</strong></td><td>被<code>synchronized</code>标记的变量可以被编译器优化（如锁消除、锁粗化）。 [cite: 75]</td><td><code>volatile</code>标记的变量会阻止编译器进行某些可能破坏其语义的优化（如指令重排）。 [cite: 75]</td></tr><tr><td><strong>底层实现</strong></td><td>JVM层面，基于Monitor对象实现。涉及<code>monitorenter</code>和<code>monitorexit</code>字节码指令。</td><td>JVM层面，通过插入特定类型的内存屏障指令实现。</td></tr></tbody></table><p><strong>总结</strong>:</p><ul><li>如果需要保证<strong>原子性</strong>操作（如计数器递增<code>i++</code>），或者需要互斥访问代码块，应使用<code>synchronized</code>（或<code>java.util.concurrent.locks.Lock</code>, <code>java.util.concurrent.atomic</code>包下的原子类）。</li><li>如果仅仅是为了保证共享变量在多线程之间的<strong>可见性</strong>，并且变量的写操作不依赖于当前值，或者能确保只有一个线程修改该变量，可以使用<code>volatile</code>。</li><li><code>volatile</code>可以看作是轻量级的<code>synchronized</code>，但功能上弱于<code>synchronized</code>。</li></ul>"
        },
        {
            "id": "java-adv-17",
            "question": "17、Java类加载过程",
            "difficulty": "★",
            "answer": "<p>Java类加载过程主要包括以下五个阶段：</p><ol><li><strong>加载 (Loading)</strong>: [cite: 76]<ul><li>这是类加载的第一个过程。 [cite: 76] 在此阶段，虚拟机需要完成三件事情：<ol><li>通过一个类的全限定名获取定义此类的二进制字节流（可以从.class文件、网络、运行时生成等）。 [cite: 76]</li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 [cite: 76]</li><li>在内存中（对于HotSpot通常是在堆中）生成一个代表这个类的<code>java.lang.Class</code>对象，作为方法区这个类的各种数据的访问入口。 [cite: 76]</li></ol></li></ul></li><li><strong>验证 (Verification)</strong>: [cite: 76]<ul><li>确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。 [cite: 76]</li><li>主要包括：文件格式验证（如主次版本号是否在当前虚拟机范围内，常量池中的常量是否有不被支持的类型 [cite: 76]）、元数据验证（对字节码描述的信息进行语义分析，如这个类是否有父类，是否继承了不被继承的类等 [cite: 76]）、字节码验证（通过数据流和控制流分析，确定程序语义是否正确，主要针对方法体，如类型转换是否正确，跳转指令是否正确等 [cite: 76]）、符号引用验证（确保解析动作能正确执行，在解析阶段发生 [cite: 76]）。</li></ul></li><li><strong>准备 (Preparation)</strong>: [cite: 76]<ul><li>正式为类中定义的变量（即静态变量，被<code>static</code>修饰的变量）分配内存并设置类变量初始值（零值，如0, null, false等）的阶段。 [cite: 76] 这些变量所使用的内存都将在方法区中进行分配。 [cite: 76]</li><li>例如，<code>public static int value = 123;</code> 在准备阶段后<code>value</code>的值是0而不是123。把<code>value</code>赋值为123的<code>putstatic</code>指令是程序被编译后，存放在类构造器<code>&lt;clinit&gt;()</code>方法之中，所以赋值操作是在初始化阶段才会执行。</li><li>但如果类字段的字段属性表中存在<code>ConstantValue</code>属性（即被<code>final static</code>修饰且在编译期能确定值的常量），那在准备阶段变量就会被初始化为<code>ConstantValue</code>属性所指定的值。</li><li>准备阶段不分配类中的实例变量的内存，实例变量将会在对象实例化时随着对象一起分配在Java堆中。 [cite: 76]</li></ul></li><li><strong>解析 (Resolution)</strong>: [cite: 76]<ul><li>虚拟机将常量池内的符号引用替换为直接引用的过程。 [cite: 76]</li><li>符号引用：以一组符号来描述所引用的目标。</li><li>直接引用：可以直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄。</li><li>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符这7类符号引用进行。</li><li>解析动作并不一定在初始化动作完成之前，也有可能在初始化之后，以支持Java的动态绑定。 [cite: 76]</li></ul></li><li><strong>初始化 (Initialization)</strong>: [cite: 76]<ul><li>类加载过程的最后一步。 [cite: 76] 在此阶段，才真正开始执行类中定义的Java程序代码（或者说是字节码）。 [cite: 76]</li><li>初始化阶段就是执行类构造器<code>&lt;clinit&gt;()</code>方法的过程。<code>&lt;clinit&gt;()</code>方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（<code>static{}</code>块）中的语句合并产生的。</li><li>虚拟机会保证一个类的<code>&lt;clinit&gt;()</code>方法在多线程环境中被正确地加锁同步，如果多个线程同时去初始化一个类，那么只会有其中一个线程去执行这个类的<code>&lt;clinit&gt;()</code>方法，其他线程都需要阻塞等待。</li></ul></li></ol><p>这五个阶段的顺序通常是固定的（加载、验证、准备、初始化），但解析阶段在某些情况下也可能在初始化阶段之后再开始。</p>"
        },
        {
            "id": "java-adv-18",
            "question": "18、什么是类加载器,类加载器有哪些",
            "difficulty": "★",
            "answer": "<p><strong>什么是类加载器 (Class Loader)</strong>:</p><p>类加载器是Java虚拟机（JVM）的一部分，负责将类的<code>.class</code>文件（或其他来源的二进制字节流）加载到JVM内存中，并转换为<code>java.lang.Class</code>类型的对象，以便程序可以使用这些类。 [cite: 76] 它的主要任务是根据类的全限定名来查找并获取描述该类的二进制字节流。 [cite: 76]</p><p><strong>Java中的类加载器主要有以下几种</strong>: [cite: 76]</p><ol><li><strong>启动类加载器 (Bootstrap ClassLoader)</strong>:<ul><li>这是最顶层的类加载器，由C++实现（并非Java类），是JVM自身的一部分。</li><li>负责加载Java的核心类库，即<code>&lt;JAVA_HOME&gt;/jre/lib</code>目录下的，或者被<code>-Xbootclasspath</code>参数所指定的路径中存放的，而且是Java虚拟机识别的（如<code>rt.jar</code>、<code>tools.jar</code>等）类库加载到虚拟机的内存中。</li><li>开发者无法直接获取到启动类加载器的引用。 [cite: 76]</li></ul></li><li><strong>扩展类加载器 (Extension ClassLoader)</strong>:<ul><li>由<code>sun.misc.Launcher$ExtClassLoader</code>实现 (具体实现类可能因JDK版本而异)。</li><li>负责加载<code>&lt;JAVA_HOME&gt;/jre/lib/ext</code>目录下的，或者被<code>java.ext.dirs</code>系统变量所指定的路径中所有的类库。 [cite: 76]</li><li>开发者可以直接使用扩展类加载器。</li></ul></li><li><strong>应用程序类加载器 (Application ClassLoader / System ClassLoader)</strong>:<ul><li>由<code>sun.misc.Launcher$AppClassLoader</code>实现 (具体实现类可能因JDK版本而异)。</li><li>这个类加载器是<code>ClassLoader</code>类中的<code>getSystemClassLoader()</code>方法的返回值，所以也称为“系统类加载器”。</li><li>它负责加载用户类路径（ClassPath）上所有的类库。 [cite: 76] 一般来说，Java应用的类都是由它来完成加载的。 [cite: 76]</li><li>如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</li></ul></li><li><strong>用户自定义类加载器 (User-defined ClassLoader)</strong>:<ul><li>开发者可以通过继承<code>java.lang.ClassLoader</code>类的方式实现自己的类加载器。 [cite: 76]</li><li>可以用来实现一些特殊的需求，如从网络加载类、运行时动态加载/卸载类、加密/解密类文件等。</li></ul></li></ol><p>这些类加载器之间通常存在一种<strong>双亲委派模型 (Parents Delegation Model)</strong> 的层次关系（除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器）。</p><p><strong>什么时候会使用到加载器 (类加载时机)？</strong> [cite: 76]</p><p>Java中的加载器是按需加载，即在需要用到类的时候才会加载，例如： [cite: 76]</p><ul><li>new对象的时候。 [cite: 76]</li><li>访问某个类或者接口的静态变量，或者对该静态变量赋值时。 [cite: 76]</li><li>调用类的静态方法时。 [cite: 76]</li><li>反射（如<code>Class.forName(\"com.example.MyClass\")</code>）。 [cite: 76]</li><li>初始化一个类的子类时，其父类首先会被加载。 [cite: 76]</li><li>JVM启动时标明的启动类（包含main方法的类）。 [cite: 76]</li></ul>"
        },
        {
            "id": "java-adv-19",
            "question": "19、简述java内存分配与回收策略以及Minor GC和Major GC (full GC)",
            "difficulty": "★★",
            "answer": "<p><strong>Java内存区域回顾 (与分配相关):</strong> [cite: 76]</p><ul><li><strong>栈区</strong>: 分为Java虚拟机栈和本地方法栈，线程私有，存放方法执行时的栈帧（局部变量、操作数栈等）。 [cite: 76]</li><li><strong>堆区</strong>: 所有线程共享，虚拟机启动时创建，唯一目的是存放对象实例。 [cite: 76] 是GC的主要区域。通常分为：<ul><li><strong>年轻代 (Young Generation)</strong>: 进一步分为Eden区和两个Survivor区 (From, To)，默认比例8:1:1。 [cite: 76] 主要存放新创建的对象。 [cite: 76]</li><li><strong>老年代 (Old/Tenured Generation)</strong>: 存放生命周期较长的对象。</li></ul></li><li><strong>方法区 (Method Area)</strong>: 所有线程共享，用于存放已被虚拟机加载的类信息、常量、静态变量等数据。 [cite: 76] 习惯上也叫永久代 (PermGen)，JDK 1.8后被元空间 (Metaspace) 取代。 [cite: 76]</li><li><strong>程序计数器</strong>: 当前线程所执行的行号指示器，线程私有。 [cite: 76]</li></ul><p><strong>Java内存分配策略:</strong> [cite: 77]</p><ol><li><strong>对象优先在Eden区分配</strong>: 大多数情况下，对象在新生代Eden区中分配。 [cite: 77] 当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。 [cite: 77]</li><li><strong>大对象直接进入老年代</strong>: 需要大量连续内存空间的Java对象，比如很长的字符串以及数组，将直接在老年代分配。这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制。可以通过<code>-XX:PretenureSizeThreshold</code>参数设置大对象的阈值。 [cite: 77]</li><li><strong>长期存活的对象将进入老年代</strong>: 虚拟机给每个对象定义了一个对象年龄（Age）计数器。 [cite: 77] 如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，该对象会被移动到Survivor空间中，并将对象年龄设为1。对象在Survivor区中每熬过一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁，可以通过<code>-XX:MaxTenuringThreshold</code>调整），就会被晋升到老年代中。 [cite: 77]</li><li><strong>动态对象年龄判定</strong>: 为了能更好地适应不同程序的内存状况，HotSpot虚拟机并不是永远要求对象的年龄必须达到<code>MaxTenuringThreshold</code>才能晋升老年代。如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到<code>MaxTenuringThreshold</code>中要求的年龄。</li><li><strong>空间分配担保</strong>: 在发生Minor GC之前，虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间。如果这个条件成立，那Minor GC可以确保是安全的。如果不成立，则虚拟机会先查看<code>HandlePromotionFailure</code>参数的设置值是否允许担保失败；如果允许，那会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次Minor GC（有风险）；如果小于，或者参数不允许冒险，那这时就要改为进行一次Full GC。</li></ol><p><strong>垃圾回收 (GC) 类型:</strong> [cite: 77]</p><ul><li><strong>Minor GC (Young GC)</strong>: 指发生在新生代的垃圾收集动作。 [cite: 77] 因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。 [cite: 77] 通常采用复制算法。</li><li><strong>Major GC / Full GC</strong>:<ul><li><strong>Major GC</strong>: 通常指发生在老年代的GC。 [cite: 77] 出现了Major GC，经常会伴随至少一次的Minor GC（但并非绝对）。Major GC的速度一般会比Minor GC慢10倍以上。</li><li><strong>Full GC</strong>: 是清理整个Java堆（包括新生代和老年代）以及方法区（元空间）的垃圾收集。 [cite: 77] Full GC的触发条件比较多，例如：老年代空间不足、方法区/元空间不足、System.gc()被显式调用、Minor GC后晋升到老年代的平均大小大于老年代剩余空间等。Full GC的代价很高，应尽量避免。通过配置，可以在Full GC之前进行一次Minor GC，这样可以加快老年代的回收速度。 [cite: 77]</li></ul></li></ul>"
        },
        {
            "id": "java-adv-20",
            "question": "20、如何查看java死锁",
            "difficulty": "★",
            "answer": "<p>查看Java死锁的常用方法有：</p><p><strong>演示死锁代码:</strong></p><div class=\"code-block\"><code>package com.ssg.mst;\n\npublic class 死锁 {\n    private static final String lock1 = \"lock1\";\n    private static final String lock2 = \"lock2\";\n\n    public static void main(String[] args) {\n        Thread thread1 = new Thread(() -> {\n            while (true) {\n                synchronized (lock1) {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \" 获取到 \" + lock1);\n                        Thread.sleep(1000);\n                        synchronized (lock2) {\n                            System.out.println(Thread.currentThread().getName() + \" 获取到 \" + lock2);\n                        }\n                    } catch (InterruptedException e) {\n                        // 在实际项目中，这里应该处理异常，例如记录日志或中断线程\n                        // throw new RuntimeException(e); // PDF中的这行在while(true)中不合适，除非要终止\n                        Thread.currentThread().interrupt(); // 恢复中断状态\n                    }\n                }\n            }\n        }, \"Thread-0\"); // 命名线程便于识别\n\n        Thread thread2 = new Thread(() -> {\n            while (true) {\n                synchronized (lock2) {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \" 获取到 \" + lock2);\n                        Thread.sleep(1000);\n                        synchronized (lock1) {\n                            System.out.println(Thread.currentThread().getName() + \" 获取到 \" + lock1);\n                        }\n                    } catch (InterruptedException e) {\n                        // 同上，处理异常\n                        // throw new RuntimeException(e);\n                        Thread.currentThread().interrupt();\n                    }\n                }\n            }\n        }, \"Thread-1\"); // 命名线程便于识别\n\n        thread1.start();\n        thread2.start();\n    }\n}</code></div><p><strong>排查步骤：</strong></p><ol><li><strong>使用<code>jps</code>命令行工具查看Java进程</strong>:<ul><li>首先，通过<code>jps -l</code> (或仅<code>jps</code>) 命令找到发生死锁的Java进程的PID。 [cite: 82]</li><li><em>[图片占位符: jps命令输出示例 - 根据PDF Page 28 CSDN @leader_song]</em> [cite: 82] (例如，PID为 9060 对应 “死锁” 类)</li></ul></li><li><strong>使用<code>jstack</code>命令行工具打印线程堆栈</strong>:<ul><li>然后，使用<code>jstack &lt;pid&gt;</code>命令打印该进程的线程堆栈信息。 [cite: 82] (例如 <code>jstack 9060</code>)</li><li>如果存在死锁，<code>jstack</code>会在输出的末尾明确指出 \"Found X Java-level deadlock(s)\"，并列出涉及死锁的线程、它们正在等待的锁（waiting to lock monitor ... which is held by ...）以及它们已经持有的锁（locked ...）。 [cite: 82, 83]</li><li><em>[图片占位符: jstack输出死锁信息示例 - 根据PDF Page 28 CSDN @leader_song]</em> [cite: 82, 83]</li></ul></li><li><strong>使用图形化监控工具</strong>:<ul><li><strong>JConsole</strong>: JDK自带的图形化监控工具。连接到Java进程后，在“线程”选项卡中，可以点击“检测死锁”按钮。</li><li><strong>VisualVM (JVisualVM)</strong>: 也是JDK自带的工具（较新版本JDK可能需要单独下载）。功能比JConsole更强大。在“线程”选项卡中，如果存在死锁，通常会有明显的提示或可以直接查看到死锁信息。它也可以进行线程Dump。</li></ul></li><li><strong>通过代码（如ThreadMXBean）</strong>:<ul><li><code>java.lang.management.ThreadMXBean</code>接口提供了检测死锁的方法：<ul><li><code>findDeadlockedThreads()</code>: 返回所有处于死锁状态的线程的ID数组。</li><li><code>findMonitorDeadlockedThreads()</code>: 专门查找因对象监视器（synchronized锁）导致的死锁。</li></ul></li><li>可以编写一个定时任务或监控端点，定期调用这些方法来检测并记录死锁信息。</li></ul></li></ol><p>当分析死锁时，关键是找出线程之间形成的资源循环等待链。<code>jstack</code>的输出会清晰地展示哪个线程持有什么锁，并等待哪个线程持有的锁。</p>"
        },
        {
            "id": "java-adv-21",
            "question": "21、Java死锁如何避免",
            "difficulty": "★",
            "answer": "<p>死锁的产生必须同时满足以下四个必要条件：</p><ol><li><strong>互斥条件 (Mutual Exclusion)</strong>: 一个资源每次只能被一个线程使用。 [cite: 83]</li><li><strong>请求与保持条件 (Hold and Wait) / 占有并等待</strong>: 一个线程因请求资源而阻塞时，对已获得的资源保持不放。 [cite: 83]</li><li><strong>不剥夺条件 (No Preemption)</strong>: 线程已获得的资源，在未使用完之前，不能被强行剥夺，只能在使用完毕后由自己释放。 [cite: 83]</li><li><strong>循环等待条件 (Circular Wait)</strong>: 若干线程之间形成一种头尾相接的循环等待资源关系。 [cite: 83]</li></ol><p>要避免死锁，就需要破坏这四个条件中的至少一个。 [cite: 83] 通常前三个条件是锁机制的基本特性，难以破坏（或者说破坏了就不再是典型的锁了），所以主要从破坏“循环等待条件”入手。 [cite: 83]</p><p><strong>避免死锁的常见策略 (在开发过程中)</strong>: [cite: 83]</p><ol><li><strong>按顺序获取锁 (破坏循环等待)</strong>:<ul><li>规定线程获取多个锁时必须按照固定的顺序。 [cite: 83] 例如，如果系统中有锁A和锁B，所有线程都必须先获取锁A，再获取锁B（或者所有线程都先获取B再获取A）。这样就不会形成A等B、B等A的循环等待。</li><li>这是最常用也是最有效的避免死锁的方法。</li></ul></li><li><strong>设置超时放弃 (破坏请求与保持)</strong>:<ul><li>线程在尝试获取锁时，设置一个超时时间。 [cite: 83] 如果超时仍未获取到锁，则放弃获取，并释放自己已经持有的所有锁，然后可以稍后重试或执行其他逻辑。</li><li>Java并发包中的<code>Lock</code>接口提供了<code>tryLock(long timeout, TimeUnit unit)</code>方法支持此功能。</li></ul></li><li><strong>死锁检测与恢复 (允许发生，事后处理)</strong>:<ul><li>系统不主动避免死锁，而是允许死锁发生，但通过某种机制检测出死锁，然后采取措施解除死锁（例如，剥夺某个线程的资源，或者终止某个线程/进程）。 [cite: 83]</li><li>这通常比较复杂，在应用层面较少直接实现，更多依赖于数据库等底层系统的死锁检测机制。</li></ul></li><li><strong>一次性申请所有资源 (破坏请求与保持)</strong>:<ul><li>线程在开始执行前，一次性申请到它需要的所有资源。如果不能一次性获取所有资源，则不持有任何资源，等待下次机会。</li><li>这种方式实现起来可能比较困难，因为很难预知一个线程在其整个生命周期中到底需要哪些资源。</li></ul></li><li><strong>避免不必要的嵌套锁</strong>:<ul><li>尽量减少在一个同步块内部再去获取另一个锁的情况，因为嵌套锁更容易导致复杂的依赖关系和潜在的死锁。</li></ul></li></ol><p>在开发过程中，最关键的是仔细设计锁的获取和释放策略，特别是当涉及到多个锁时，要严格保证获取顺序的一致性。</p>"
        }
    ]
            },
            {
                "chapterTitle": "第三章-java框架篇",
    "questions": [
        {
            "id": "java-framework-1",
            "question": "1、简单的谈一下SpringMVC的工作流程",
            "difficulty": "★",
            "answer": "<p>Spring MVC 的工作流程可以概括为以下步骤：</p><ol><li>用户发送请求至前端控制器<code>DispatcherServlet</code>。</li><li><code>DispatcherServlet</code>收到请求后，调用<code>HandlerMapping</code>（处理器映射器）。</li><li><code>HandlerMapping</code>根据请求的URL等信息找到具体的处理器（Controller中的方法），并生成处理器对象及处理器拦截器（如果配置了拦截器）一并返回给<code>DispatcherServlet</code>。</li><li><code>DispatcherServlet</code>调用<code>HandlerAdapter</code>（处理器适配器）。</li><li><code>HandlerAdapter</code>经过适配后，调用具体的处理器（Controller方法）来执行业务逻辑。</li><li>Controller执行完成后，返回一个<code>ModelAndView</code>对象（包含模型数据和视图信息）。</li><li><code>HandlerAdapter</code>将Controller执行结果<code>ModelAndView</code>返回给<code>DispatcherServlet</code>。</li><li><code>DispatcherServlet</code>将<code>ModelAndView</code>传递给<code>ViewResolver</code>（视图解析器）。</li><li><code>ViewResolver</code>解析<code>ModelAndView</code>，找到具体的<code>View</code>（例如JSP页面、Thymeleaf模板等）。</li><li><code>DispatcherServlet</code>根据<code>View</code>进行视图渲染（即将模型数据填充到视图中）。</li><li><code>DispatcherServlet</code>最终将渲染后的视图响应给用户。</li></ol>"
        },
        {
            "id": "java-framework-2",
            "question": "2、说出Spring或者SpringMVC中常用的5个注解",
            "difficulty": "★",
            "answer": "<p>以下是一些Spring和Spring MVC中常用的注解：</p><ol><li><code>@Component</code>: 基本注解,标识一个受Spring管理的组件 [cite: 84]</li><li><code>@Controller</code>: 标识为一个表示层的组件 [cite: 84]</li><li><code>@Service</code>: 标识为一个业务层的组件 [cite: 84]</li><li><code>@Repository</code>: 标识为一个持久层的组件 [cite: 84]</li><li><code>@Autowired</code>: 自动装配 [cite: 84]</li><li><code>@Qualifier(\"\")</code>: 具体指定要装配的组件的id值 [cite: 84] (PDF中还有更多, 如@RequestMapping, @PathVariable, @ResponseBody等，这里根据你原有的格式，可以酌情增减)</li></ol><p><em>(只要说出几个注解并解释含义即可)</em></p>"
        },
        {
            "id": "java-framework-3",
            "question": "3、简述SpringMVC中如何返回JSON数据",
            "difficulty": "★",
            "answer": "<ol><li>在项目中加入json转换的依赖,例如jackson, fastjson, gson等。 [cite: 84]</li><li>在请求处理方法中将返回值改为具体返回的数据的类型,例如数据的集合类List&lt;Employee&gt;等。 [cite: 84]</li><li>在请求处理方法上使用<code>@ResponseBody</code>注解。 [cite: 84]</li></ol>"
        },
        {
            "id": "java-framework-4",
            "question": "4、谈谈你对Spring的理解",
            "difficulty": "★",
            "answer": "<p>Spring 是一个开源框架,为简化企业级应用开发而生。Spring可以是使简单的JavaBean 实现以前只有EJB才能实现的功能。Spring 是一个IOC 和 AOP 容器框架。 [cite: 84]</p><p>Spring 容器的主要核心是:</p><ul><li><strong>控制反转(IOC)</strong>: 传统的java开发模式中,当需要一个对象时,我们会自己使用 new 或者 getInstance 等直接或者间接调用构造方法创建一个对象。 而在 spring 开发模式中,spring 容器使用了工厂模式为我们创建了所需要的对象,不需要我们自己创建了,直接调用spring 提供的对象就可以了,这是控制反转的思想。 [cite: 84]</li><li><strong>依赖注入(DI)</strong>: spring 使用javaBean 对象的 set 方法或者带参数的构造方法为我们在创建所需对象时将其属性自动设置所需要的值的过程,就是依赖注入的思想。 [cite: 84]</li><li><strong>面向切面编程(AOP)</strong>: 在面向对象编程(oop)思想中,我们将事物纵向抽成一个个的对象。而在面向切面编程中,我们将一个个的对象某些类似的方面横向抽成一个切面,对这个切面进行一些如权限控制、事物管理,记录日志等公用操作处理的过程就是面向切面编程的思想。AOP底层是动态代理,如果是接口采用JDK动态代理,如果是类采用CGLIB方式实现动态代理。 [cite: 84]</li></ul>"
        },
        {
            "id": "java-framework-5",
            "question": "5、Spring中常用的设计模式",
            "difficulty": "★",
            "answer": "<ol><li><strong>代理模式</strong>——spring 中两种代理方式,若目标对象实现了若干接口,spring 使用jdk 的<code>java.lang.reflect.Proxy</code>类代理。若目标对象没有实现任何接口,spring 使用CGLIB库生成目标类的子类。 [cite: 84, 85]</li><li><strong>单例模式</strong>: 在spring 的配置文件中设置 bean 默认为单例模式。 [cite: 85]</li><li><strong>模板方式模式</strong>: 用来解决代码重复的问题。比如:<code>RestTemplate</code>, <code>JmsTemplate</code>, <code>JpaTemplate</code>。 [cite: 85]</li><li><strong>工厂模式</strong>: 在工厂模式中,我们在创建对象时不会对客户端暴露创建逻辑,并且是通过使用同一个接口来指向新创建的对象。Spring 中使用 beanFactory 来创建对象的实例。 [cite: 85]</li></ol>"
        },
        {
            "id": "java-framework-6",
            "question": "6、Spring循环依赖问题",
            "difficulty": "★★",
            "answer": "<p><strong>常见问法:</strong></p><ul><li>请解释一下spring中的三级缓存 [cite: 85]</li><li>三级缓存分别是什么?三个Map有什么异同? [cite: 85]</li><li>什么是循环依赖?请你谈谈?看过spring源码吗? [cite: 85]</li><li>如何检测是否存在循环依赖?实际开发中见过循环依赖的异常吗? [cite: 85]</li><li>多例的情况下,循环依赖问题为什么无法解决? [cite: 86]</li></ul><p><strong>什么是循环依赖?</strong></p><p><a href='https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-dependency-resolution' target='_blank'>官方解释链接</a> [cite: 87]</p><p><strong>相关概念:</strong></p><ul><li>实例化: 堆内存中申请空间。 [cite: 87]</li><li>初始化: 对象属性赋值。 [cite: 87]</li></ul><p><strong>三级缓存:</strong></p><table><thead><tr><th>名称</th><th>对象名</th><th>含义</th></tr></thead><tbody><tr><td>一级缓存</td><td>singletonObjects</td><td>存放已经经历了完整生命周期的Bean对象 [cite: 88]</td></tr><tr><td>二级缓存</td><td>earlySingletonObjects</td><td>存放早期暴露出来的Bean对象,Bean的生命周期未结束(属性还未填充完) [cite: 88]</td></tr><tr><td>三级缓存</td><td>singletonFactories</td><td>存放可以生成Bean的工厂 [cite: 88]</td></tr></tbody></table><div class='code-block'><code>// 来自 DefaultSingletonBeanRegistry.java\n// 第一级缓存: 单例对象的缓存:bean名称 bean实例,即:所谓的单例池。表示已经经历了完整生命周期的Bean对象\nprivate final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);\n\n// 第二级缓存: 早期的单例对象的高速缓存:bean名称—bean实例。表示 Bean的生命周期还没走完(Bean的属性还未填充)就把这个Bean存入该缓存中也就是实例化但未初始化的bean放入该缓存里\nprivate final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);\n\n// 第三级缓存: 单例工厂的高速缓存:bean名称——ObjectFactory。表示存放生成 bean的工厂\nprivate final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);</code></div><p><strong>四个关键方法:</strong> [cite: 89]</p><ul><li>getSingleton</li><li>doCreateBean</li><li>populateBean</li><li>addSingletonFactory (或 addSingleton，根据上下文，PDF p31 提到 addSingleton)</li></ul><p><strong>debug源代码过程 (简述):</strong> [cite: 91]</p><ol><li>A创建过程中需要B,于是A将自己(的工厂)放到三级缓存里面,去实例化B。 [cite: 91]</li><li>B实例化的时候发现需要A,于是B先查一级缓存(无),再查二级缓存(无),再查三级缓存,找到了A的ObjectFactory。通过ObjectFactory获取A的早期实例(如果A需要代理，则在这里创建代理)，并将这个早期A实例放到二级缓存里面,并删除三级缓存里面的A的ObjectFactory。 [cite: 91]</li><li>B顺利初始化完毕(注入了A的早期引用),将自己放到一级缓存里面。 [cite: 91]</li><li>然后回来接着创建A,此时B已经创建结束,直接从一级缓存里面拿到B,然后完成A的属性填充和初始化,并将A自己放到一级缓存里面。 [cite: 91]</li></ol><p><strong>总结:</strong></p><ol><li>Spring创建bean主要分为两个步骤: 创建原始bean对象,接着去填充对象属性和初始化。 [cite: 91]</li><li>每次创建bean之前,都会从缓存中查找该bean。 [cite: 91]</li><li>当创建A的原始对象后,并把它(的ObjectFactory)放到三级缓存中。填充属性时发现依赖B,就去创建B。创建B时若发现依赖A,可从三级缓存中查到A的ObjectFactory,从而获得A的早期引用(并放入二级缓存),完成B的创建。然后A就可以完成属性填充和后续初始化。 [cite: 91]</li><li>Spring解决循环依赖依靠的是Bean的“中间态”这个概念,而这个中间态指的是已经实例化但还没初始化的状态。构造器的循环依赖无法解决，因为对象需要通过构造器完成实例化，无法提前暴露。 [cite: 91]</li></ol><p><strong>其他衍生问题:</strong></p><ul><li><strong>问题1: 为什么构造器注入属性无法解决循环依赖问题?</strong><p>由于spring中的bean的创建过程为先实例化再初始化。使用构造器注入,必须在调用构造器时完成对象的依赖注入操作,如果循环依赖，会导致互相等待对方实例化完成，陷入死循环的状态。 [cite: 91, 92]</p></li><li><strong>问题2: 一级缓存能不能解决循环依赖问题?</strong><p>不能。如果只有一级缓存,在并发操作下,可能取到实例化但未完全初始化的对象(半成品),导致问题。一级缓存只存完整Bean。 [cite: 92]</p></li><li><strong>问题3: 二级缓存能不能解决循环依赖问题? 为什么还需要三级缓存?</strong><p>理论上二级缓存(存早期暴露的Bean)可以解决循环依赖问题。但是三级缓存(存ObjectFactory)的引入是为了解决AOP代理的问题。如果一个Bean需要被代理，通过ObjectFactory可以在真正需要时才创建代理对象。如果直接在二级缓存中暴露普通对象，之后又需要代理对象，就会出现不一致。三级缓存确保无论是普通对象还是代理对象，都是从同一个源头（ObjectFactory）获取，保证了在合适的时机创建并暴露正确的Bean（可能是代理对象）。 [cite: 92, 93]</p></li></ul>"
        },
        {
            "id": "java-framework-7",
            "question": "7、介绍一下Spring bean 的生命周期、注入方式和作用域",
            "difficulty": "★",
            "answer": "<p><strong>Bean的生命周期:</strong></p><p>(1)默认情况下,IOC容器中bean的生命周期分为五个阶段:</p><ol><li>调用构造器或者是通过工厂的方式创建Bean对象 [cite: 93]</li><li>给bean对象的属性注入值 [cite: 93]</li><li>调用初始化方法,进行初始化,初始化方法是通过<code>init-method</code>来指定的 [cite: 93]</li><li>使用Bean [cite: 93]</li><li>IOC容器关闭时,销毁Bean对象 (通过<code>destroy-method</code>指定) [cite: 93]</li></ol><p>(2)当加入了Bean的后置处理器后,IOC容器中bean的生命周期分为七个阶段:</p><ol><li>调用构造器或者是通过工厂的方式创建Bean对象 [cite: 94]</li><li>给bean对象的属性注入值 [cite: 94]</li><li>执行Bean后置处理器中的<code>postProcessBeforeInitialization</code> [cite: 94]</li><li>调用初始化方法,进行初始化 (<code>init-method</code>) [cite: 94]</li><li>执行Bean的后置处理器中的<code>postProcessAfterInitialization</code> [cite: 94]</li><li>使用Bean [cite: 94]</li><li>IOC容器关闭时,销毁Bean对象 [cite: 94]</li></ol><p><strong>注入方式:</strong></p><ul><li>通过 setter 方法注入 [cite: 94]</li><li>通过构造方法注入 [cite: 94]</li></ul><p><strong>Bean的作用域:</strong></p><p>总共有主要以下几种作用域 (Spring Framework标准作用域):</p><ul><li><code>singleton</code>: 单例的 (默认作用域) [cite: 94]</li><li><code>prototype</code>: 原型的 (每次请求都会创建一个新的bean实例) [cite: 94]</li><li><code>request</code>: (Web环境中)每次HTTP请求都会创建一个新的bean实例,仅在当前request内有效。 [cite: 94]</li><li><code>session</code>: (Web环境中)每个HTTP会话对应一个bean实例,仅在当前session内有效。 [cite: 94]</li><li>(还有如<code>application</code>, <code>websocket</code>等特定环境作用域)</li></ul>"
        },
        {
            "id": "java-framework-8",
            "question": "8、请描述一下Spring 的事务管理",
            "difficulty": "★",
            "answer": "<p>Spring支持两种类型的事务管理：编程式事务管理和声明式事务管理。声明式事务管理是更常用的方式。</p><p><strong>(1) 声明式事务管理:</strong></p><p>在Spring配置文件中或使用注解声明式地处理事务，而不是通过编码方式处理事务。这样做的好处是，事务管理不侵入开发组件的业务逻辑。 [cite: 94] Spring提供了两种主要方式实现声明式事务：</p><ul><li><strong>基于XML配置 (传统方式,如TransactionInterceptor)</strong>: 通过在XML配置文件中定义事务增强（advice）和切点（pointcut）来管理事务。配置事务管理器（<code>transactionManager</code>）和事务属性（<code>transactionAttributes</code>），这些属性可以为不同的方法名（可使用通配符）指定不同的事务行为（如传播行为、隔离级别、只读等）。 [cite: 94]</li><li><strong>基于<code>@Transactional</code>注解</strong>: 这是更现代和推荐的方式。通过在类或方法上添加<code>@Transactional</code>注解来声明事务属性。注解可以作用于接口、接口方法、类和类方法上。当作用于类上时,该类的所有public方法将都具有该类型的事务属性。 [cite: 94] 可以配置如<code>propagation</code>, <code>isolation</code>, <code>readOnly</code>, <code>timeout</code>, <code>rollbackFor</code>, <code>noRollbackFor</code>等属性。</li></ul><p><strong>(2) 编程式事务管理:</strong></p><p>在代码中显式调用事务管理相关的方法，如<code>beginTransaction()</code>, <code>commit()</code>, <code>rollback()</code>。 [cite: 94] Spring提供了两种编程式事务管理方式：</p><ul><li><strong>基于底层API (如<code>PlatformTransactionManager</code>)</strong>: 直接使用<code>PlatformTransactionManager</code>的API来控制事务。</li><li><strong>基于<code>TransactionTemplate</code></strong>: <code>TransactionTemplate</code>是Spring提供的一个工具类，它简化了编程式事务的使用，通过回调机制来执行业务代码。 [cite: 94]</li></ul><p>核心组件包括：</p><ul><li><code>PlatformTransactionManager</code>: 事务管理器接口，定义了事务的基本操作（获取事务、提交、回滚）。具体实现类如<code>DataSourceTransactionManager</code> (JDBC), <code>JpaTransactionManager</code> (JPA), <code>HibernateTransactionManager</code> (Hibernate)。</li><li>事务定义 (<code>TransactionDefinition</code>): 包含事务的属性，如隔离级别、传播行为、超时时间、是否只读。</li><li>事务状态 (<code>TransactionStatus</code>): 表示一个特定事务的状态，可以用来控制事务的提交或回滚。</li></ul>"
        },
        {
            "id": "java-framework-9",
            "question": "9、MyBatis中 #{ 和\\${}的区别是什么",
            "difficulty": "★",
            "answer": "<p><code>#{}</code>和<code>${}</code>在MyBatis中都用于参数替换，但它们的工作方式和安全性有显著区别：</p><ol><li><strong><code>#{}</code> (预编译处理)</strong>:<ul><li>MyBatis在处理<code>#{}</code>时,会将SQL中的<code>#{}</code>替换为<code>?</code>号占位符。 [cite: 94, 95]</li><li>然后调用<code>PreparedStatement</code>的<code>set</code>方法来安全地设置参数值。 [cite: 95]</li><li>这种方式可以有效防止SQL注入攻击，因为参数值是作为数据而不是SQL代码的一部分传递给数据库的。 [cite: 95]</li><li>适用于传递绝大多数参数值。</li></ul></li><li><strong><code>${}</code> (字符串替换)</strong>:<ul><li>MyBatis在处理<code>${}</code>时,会直接将<code>${}</code>替换成变量的值，进行简单的字符串拼接。 [cite: 95]</li><li>这种方式存在SQL注入的风险，因为如果变量值包含恶意的SQL代码，这些代码会成为执行的SQL语句的一部分。</li><li>通常用于动态替换SQL语句的非参数部分，例如表名、列名、ORDER BY子句中的排序字段等。在这些场景下使用时，必须非常小心，并对输入值进行严格的校验和清理，或者确保这些值来自于可信源。</li></ul></li></ol><p><strong>总结</strong>: 出于安全考虑，应优先使用<code>#{}</code>。只有在确实需要动态替换SQL结构本身（而非仅仅是参数值）且能保证输入安全的情况下，才谨慎使用<code>${}</code>。</p>"
        },
        {
            "id": "java-framework-10",
            "question": "10、Mybatis 中一级缓存与二级缓存",
            "difficulty": "★",
            "answer": "<p>MyBatis的缓存主要分为一级缓存和二级缓存，它们用于减少数据库交互，提高查询性能。</p><ol><li><strong>一级缓存 (SqlSession Level Cache)</strong>:<ul><li>一级缓存是<code>SqlSession</code>级别的缓存，也称为本地缓存。它是默认开启的，不能关闭。 [cite: 96]</li><li>当同一个<code>SqlSession</code>执行相同的SQL查询（相同的语句、参数和<code>RowBounds</code>）时，如果一级缓存中存在结果，则直接从缓存中获取，不再查询数据库。</li><li>一级缓存的生命周期与<code>SqlSession</code>相同。当<code>SqlSession</code>关闭或提交/回滚事务（执行了更新操作 DML: INSERT, UPDATE, DELETE）时，该<code>SqlSession</code>的一级缓存会被清空。</li><li>不同<code>SqlSession</code>之间的一级缓存是相互隔离的。</li></ul></li><li><strong>二级缓存 (Namespace/Mapper Level Cache)</strong>:<ul><li>二级缓存是Mapper（Namespace）级别的缓存，它可以被多个<code>SqlSession</code>共享。 [cite: 96]</li><li>二级缓存默认是关闭的，需要显式配置开启。开启步骤通常包括：<ul><li>在MyBatis全局配置文件<code>mybatis-config.xml</code>中设置<code>&lt;setting name=\"cacheEnabled\" value=\"true\"/&gt;</code>（此为总开关，默认为true）。</li><li>在对应的Mapper XML文件中使用<code>&lt;cache/&gt;</code>标签来启用该namespace的二级缓存。</li><li>相关的POJO类需要实现<code>java.io.Serializable</code>接口，因为二级缓存可能存储到磁盘或在分布式环境中使用。</li></ul></li><li>当一个<code>SqlSession</code>查询数据时，会先查找对应的二级缓存，如果命中则返回结果。如果未命中，则查询数据库，并将结果存入二级缓存（同时也存入该<code>SqlSession</code>的一级缓存）。</li><li>当执行了DML操作（INSERT, UPDATE, DELETE）并提交事务后，会清空（或更新，取决于配置）该Namespace下的二级缓存，以避免脏读。可以通过<code>&lt;cache flushInterval=\"...\" size=\"...\" readOnly=\"...\" eviction=\"...\"/&gt;</code>等属性进行更细致的配置。</li></ul></li></ol><p><strong>缓存的查找顺序:</strong> 二级缓存 -> 一级缓存 -> 数据库。 [cite: 96]</p>"
        },
        {
            "id": "java-framework-11",
            "question": "11、MyBatis如何获取自动生成的(主)键值",
            "difficulty": "★",
            "answer": "<p>在MyBatis中，当向数据库插入一条记录后，如果主键是由数据库自动生成的（例如自增ID），可以通过在<code>&lt;insert&gt;</code>标签中配置特定属性来获取这个生成的主键值，并将其设置回传入的参数对象中。</p><p>主要使用<code>useGeneratedKeys</code>和<code>keyProperty</code>两个属性：</p><ul><li><strong><code>useGeneratedKeys=\"true\"</code></strong>: 这个属性告诉MyBatis期望数据库生成主键，并且需要获取它。</li><li><strong><code>keyProperty=\"propertyName\"</code></strong>: 这个属性指定将获取到的主键值设置到参数对象的哪个属性上。如果参数是Map，则为Map的key；如果参数是POJO，则为POJO的属性名。</li><li>(可选) <strong><code>keyColumn=\"columnName\"</code></strong>: 如果生成主键的列名与POJO属性名不一致，或者有多个生成列时，可以用这个属性指定数据库表中的列名。通常，如果主键只有一个且名称能自动匹配，则可以省略。</li></ul><p><strong>示例:</strong> [cite: 96]</p><div class=\"code-block\"><code>&lt;insert id=\"insertName\" parameterType=\"com.example.YourParameterType\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt;\n  insert into names (name) values (#{name})\n&lt;/insert&gt;</code></div><p>在上面的例子中：</p><ul><li>假设传入的参数对象有一个名为<code>id</code>的属性 (例如，一个<code>User</code>对象有<code>private Integer id;</code>)。</li><li>当这条insert语句执行完毕后，数据库生成的自增ID值会自动赋给传入参数对象的<code>id</code>属性。</li><li>如果<code>parameterType</code>是一个Map，并且你希望主键设置到Map中名为<code>generatedId</code>的键上，则<code>keyProperty=\"generatedId\"</code>。</li></ul><p>对于不支持自增主键的数据库（如Oracle，使用序列），或者需要更复杂的主键生成逻辑，可以使用<code>&lt;selectKey&gt;</code>标签来获取主键。</p>"
        },
        {
            "id": "java-framework-12",
            "question": "12、简述Mybatis的动态SQL,列出常用的6个标签及作用",
            "difficulty": "★",
            "answer": "<p>动态SQL是MyBatis的强大特性之一，它允许根据不同的条件动态地构建SQL语句。这使得SQL语句更加灵活，能够适应复杂的查询需求，避免在Java代码中拼接SQL字符串。MyBatis的动态SQL基于OGNL表达式来实现条件判断和迭代。 [cite: 96]</p><p><strong>作用：</strong>动态SQL主要用来解决查询条件不确定的情况，在程序运行期间，根据提交的条件动态地完成SQL语句的拼接。 [cite: 96]</p><p><strong>常用的动态SQL标签及其作用：</strong></p><ol><li><strong><code>&lt;if test=\"condition\"&gt;...&lt;/if&gt;</code></strong>:<ul><li>作用：进行条件判断。如果<code>test</code>属性中的OGNL表达式结果为true，则将其包含的SQL片段拼接到语句中。 [cite: 96]</li><li>例如：<code>&lt;if test=\"username != null and username != ''\"&gt;AND username = #{username}&lt;/if&gt;</code></li></ul></li><li><strong><code>&lt;where&gt;...&lt;/where&gt;</code></strong>:<ul><li>作用：主要用于在包含的SQL片段前面智能地添加<code>WHERE</code>关键字。 [cite: 96] 更重要的是，它会自动处理SQL片段开头的多余的<code>AND</code>或<code>OR</code>。如果<code>&lt;where&gt;</code>标签内的条件都不满足，则不会添加<code>WHERE</code>关键字。 [cite: 96]</li><li>例如：<code>&lt;where&gt;&lt;if test=\"...\"&gt;AND ...&lt;/if&gt;&lt;/where&gt;</code> 如果if条件满足，会生成 <code>WHERE ...</code>，而不是 <code>WHERE AND ...</code>。</li></ul></li><li><strong><code>&lt;trim prefix=\"\" suffix=\"\" prefixOverrides=\"\" suffixOverrides=\"\"&gt;...&lt;/trim&gt;</code></strong>:<ul><li>作用：一个更通用的SQL片段处理标签，可以在其包含的SQL内容前后添加指定字符（<code>prefix</code>, <code>suffix</code>），或者去掉指定的前缀/后缀字符（<code>prefixOverrides</code>, <code>suffixOverrides</code>，通常是<code>AND |OR</code> 或 <code>,</code>）。 [cite: 96]</li><li>例如，可以用来模拟<code>&lt;where&gt;</code>的功能，或者在<code>UPDATE</code>语句的<code>SET</code>子句中处理逗号。</li></ul></li><li><strong><code>&lt;set&gt;...&lt;/set&gt;</code></strong>:<ul><li>作用：主要用于<code>UPDATE</code>操作时，智能地添加<code>SET</code>关键字，并去除包含SQL片段中末尾多余的逗号。 [cite: 96]</li><li>例如：<code>&lt;set&gt;&lt;if test=\"username != null\"&gt;username = #{username},&lt;/if&gt;&lt;/set&gt;</code> 会生成 <code>SET username = ?</code> 而不是 <code>SET username = ?,</code>。</li></ul></li><li><strong><code>&lt;choose&gt;</code>, <code>&lt;when test=\"condition\"&gt;...&lt;/when&gt;</code>, <code>&lt;otherwise&gt;...&lt;/otherwise&gt;</code></strong>:<ul><li>作用：类似于Java中的<code>switch</code>语句。它会从多个<code>&lt;when&gt;</code>条件中选择第一个满足条件的分支执行，如果所有<code>&lt;when&gt;</code>都不满足，则执行<code>&lt;otherwise&gt;</code>分支（如果存在）。 [cite: 96]</li></ul></li><li><strong><code>&lt;foreach collection=\"\" item=\"\" index=\"\" open=\"\" separator=\"\" close=\"\"&gt;...&lt;/foreach&gt;</code></strong>:<ul><li>作用：用于迭代集合（如List, Set, Array, Map的entrySet）。常用于构建<code>IN</code>子句，或者批量插入/更新。 [cite: 96]</li><li>属性说明:<ul><li><code>collection</code>: 要迭代的集合参数名。</li><li><code>item</code>: 迭代过程中当前元素的变量名。</li><li><code>index</code>: 迭代过程中当前索引的变量名 (对List/Array是索引，对Map是key)。</li><li><code>open</code>: 整个迭代SQL片段的起始字符串。</li><li><code>separator</code>: 每次迭代生成的SQL片段之间的分隔符。</li><li><code>close</code>: 整个迭代SQL片段的结束字符串。</li></ul></li><li>例如构建IN子句: <code>IN &lt;foreach collection=\"ids\" item=\"id\" open=\"(\" separator=\",\" close=\")\"&gt;#{id}&lt;/foreach&gt;</code></li></ul></li></ol><p>除了以上6个，还有<code>&lt;bind&gt;</code>标签用于创建一个OGNL表达式变量并在后续使用，以及<code>&lt;sql&gt;</code>和<code>&lt;include&gt;</code>用于定义和引用可重用的SQL片段。</p>"
        },
        {
            "id": "java-framework-13",
            "question": "13、Mybatis 如何完成MySQL的批量操作",
            "difficulty": "★",
            "answer": "<p>MyBatis 完成 MySQL 的批量操作主要依赖于 <code>&lt;foreach&gt;</code> 动态 SQL 标签来构建批量 DML 语句，特别是批量插入（Batch Insert）。</p><p><strong>批量插入 (Batch Insert) 示例:</strong></p><p>假设我们有一个员工列表 <code>List&lt;Employee&gt; emps</code> 需要批量插入到 <code>tbl_employee</code> 表中。</p><div class=\"code-block\"><code>&lt;insert id=\"insertBatch\" parameterType=\"java.util.List\"&gt;\n  insert into tbl_employee(last_name, email, gender, d_id) values\n  &lt;foreach collection=\"list\" item=\"curr_emp\" separator=\",\"&gt;\n    (#{curr_emp.lastName}, #{curr_emp.email}, #{curr_emp.gender}, #{curr_emp.dept.id})\n  &lt;/foreach&gt;\n&lt;/insert&gt;</code></div><p><strong>说明:</strong> [cite: 96]</p><ul><li><code>parameterType=\"java.util.List\"</code>: 指明传入的参数是一个List。在实际调用Mapper接口方法时，如果方法参数名在<code>&lt;foreach&gt;</code>的<code>collection</code>属性中没有明确指定（如指定为<code>emps</code>），那么默认可以使用<code>list</code>作为集合参数名。如果Mapper接口方法参数使用了<code>@Param(\"emps\") List&lt;Employee&gt; emps</code>，那么<code>collection</code>应为<code>emps</code>。</li><li><code>collection=\"list\"</code>: 指定要迭代的集合。如果参数是List类型，默认可以用`list`；如果是数组，默认用`array`。推荐使用`@Param`注解指定参数名并在`collection`中明确使用。</li><li><code>item=\"curr_emp\"</code>: 定义在迭代过程中，当前元素的临时变量名。</li><li><code>separator=\",\"</code>: 定义每两个迭代元素生成的SQL片段之间用逗号分隔。</li><li><code>(#{curr_emp.lastName}, #{curr_emp.email}, ...)</code>: 这是每个元素生成的values部分，引用了<code>curr_emp</code>对象的属性。</li></ul><p>这条语句最终会生成类似如下的SQL：</p><div class=\"code-block\"><code>insert into tbl_employee(last_name, email, gender, d_id) values\n  ('员工A', 'a@example.com', '男', 1),\n  ('员工B', 'b@example.com', '女', 2),\n  ('员工C', 'c@example.com', '男', 1);</code></div><p><strong>注意事项和优化:</strong></p><ol><li><strong>JDBC URL配置</strong>: 为了使MySQL JDBC驱动真正执行批量插入，需要在JDBC连接URL中添加<code>rewriteBatchedStatements=true</code>参数。例如：<code>jdbc:mysql://localhost:3306/mydb?rewriteBatchedStatements=true</code>。没有这个参数，即使MyBatis生成了批量SQL，驱动也可能逐条发送给数据库。</li><li><strong>ExecutorType</strong>: 在获取<code>SqlSession</code>时，可以指定<code>ExecutorType.BATCH</code>。<code>SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH);</code>。这会让MyBatis在执行多条更新语句时（包括由<code>&lt;foreach&gt;</code>生成的单条批量insert语句，或者多次调用单个insert语句），进行批处理优化，减少与数据库的交互次数。使用<code>BATCH</code>模式时，需要手动调用<code>sqlSession.flushStatements()</code>来提交批处理的语句，或者在<code>sqlSession.commit()</code>时自动刷新。</li><li><strong>批量更新/删除</strong>: 类似地，<code>&lt;foreach&gt;</code>也可以用于构建批量更新或删除的条件，例如使用<code>IN</code>子句：<code>DELETE FROM tbl_employee WHERE id IN &lt;foreach collection=\"ids\" item=\"id\" open=\"(\" separator=\",\" close=\")\"&gt;#{id}&lt;/foreach&gt;</code>。但这种不是JDBC层面批处理的典型场景，而是生成一条带有IN子句的SQL。对于真正的批量更新（多条不同的update语句），则<code>ExecutorType.BATCH</code>更为关键。</li></ol>"
        },
        {
            "id": "java-framework-14",
            "question": "14、谈谈怎么理解SpringBoot框架",
            "difficulty": "★★",
            "answer": "<p>Spring Boot 是 Spring 开源组织下的子项目，它并非用来取代 Spring，而是基于 Spring Framework 构建的，旨在简化新的基于 Spring 的应用程序的初始搭建以及开发过程。可以将其理解为 Spring 组件的一站式解决方案和快速开发脚手架。 [cite: 96]</p><p><strong>核心理念：约定优于配置 (Convention over Configuration)</strong></p><p>Spring Boot 尝试尽可能地根据项目中添加的依赖自动配置 Spring 应用程序。这意味着开发者不再需要编写大量的XML配置或注解配置，从而可以更快地启动和运行项目。</p><p><strong>主要优点和特性：</strong></p><ul><li><strong>独立运行 (Standalone)</strong>: Spring Boot 应用可以内嵌 Servlet 容器（如 Tomcat, Jetty, Undertow），因此可以将应用打包成可执行的 JAR 文件（或 WAR 文件），直接通过 <code>java -jar</code> 命令运行，无需外部 Servlet 容器。 [cite: 97]</li><li><strong>简化配置 (Simplified Configuration)</strong>: 通过提供大量的“starter”依赖（例如 <code>spring-boot-starter-web</code>, <code>spring-boot-starter-data-jpa</code>），极大地简化了 Maven 或 Gradle 的配置。这些 starter 会聚合一组常用的相关依赖。 [cite: 98]</li><li><strong>自动配置 (Auto-configuration)</strong>: Spring Boot 会根据类路径下的 JAR 包、存在的类以及特定配置来尝试自动配置应用程序所需的大部分 Bean。例如，如果类路径下有 HSQLDB，并且没有配置任何数据库连接，Spring Boot 会自动配置一个内存数据库。 [cite: 98]</li><li><strong>无代码生成和XML配置</strong>: Spring Boot 鼓励使用 Java 配置和注解，避免了繁琐的 XML 配置，也不需要代码生成工具。 [cite: 98]</li><li><strong>应用监控与管理 (Actuator)</strong>: Spring Boot Actuator 模块提供了一系列生产就绪的特性，如健康检查、度量收集、审计、HTTP追踪等，可以通过 HTTP 端点或 JMX 进行访问和管理。 [cite: 98]</li><li><strong>易于上手和快速开发</strong>: 上述特性使得开发者能够非常迅速地搭建和运行一个功能完备的 Spring 应用。</li></ul><p><strong>Spring Boot 的缺点：</strong></p><ul><li><strong>学习曲线</strong>: 虽然上手容易，但要深入理解其自动配置原理和内部工作机制，仍然需要一定的学习成本。如果不了解核心技术，遇到问题时排查可能会比较棘手。 [cite: 98]</li><li><strong>封装性</strong>: 高度封装和自动化有时可能使得定制化和调试变得不那么直观，特别是对于习惯了传统 Spring XML 配置的开发者。</li></ul><p>总的来说，Spring Boot 通过简化配置、自动化管理和提供开箱即用的功能，极大地提高了 Spring 应用的开发效率和便捷性，使其成为构建微服务和现代Java应用的流行选择。</p>"
        },
        {
            "id": "java-framework-15",
            "question": "15、Spring Boot 的核心注解是哪个它主要由哪几个注解组成的",
            "difficulty": "★",
            "answer": "<p>Spring Boot 的核心注解是 <code>@SpringBootApplication</code>。 [cite: 98] 这个注解通常标记在主应用程序类（即包含 <code>main</code> 方法的类）上。</p><p><code>@SpringBootApplication</code> 是一个复合注解，它主要由以下三个注解组成：</p><ol><li><strong><code>@SpringBootConfiguration</code></strong>:<ul><li>这个注解本身是 <code>@Configuration</code> 注解的特化版本。 [cite: 98]</li><li>它表明被标记的类是一个 Spring 配置类，允许在类中使用 <code>@Bean</code> 注解来定义 Bean。Spring Boot 应用通常将主类作为其配置源。</li></ul></li><li><strong><code>@EnableAutoConfiguration</code></strong>:<ul><li>这是 Spring Boot 实现自动配置的关键。 [cite: 98]</li><li>它会启用 Spring Boot 的自动配置机制，Spring Boot 会根据项目中添加的依赖和类路径中的情况，尝试猜测并配置你可能需要的 Bean。</li><li>可以通过该注解的 <code>exclude</code> 或 <code>excludeName</code> 属性来关闭特定的自动配置项。例如：<code>@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})</code> 可以关闭数据源的自动配置。 [cite: 98]</li></ul></li><li><strong><code>@ComponentScan</code></strong>:<ul><li>这个注解启用了组件扫描功能。 [cite: 99]</li><li>默认情况下，它会扫描与 <code>@SpringBootApplication</code> 注解所在类同包及其子包下的组件（如 <code>@Component</code>, <code>@Service</code>, <code>@Repository</code>, <code>@Controller</code> 等注解标记的类），并将它们注册为 Spring Bean。</li><li>可以自定义扫描的包路径，例如：<code>@ComponentScan(basePackages = \"com.example.myapp\")</code>。</li></ul></li></ol><p>因此，一个简单的 <code>@SpringBootApplication</code> 注解就包含了配置、自动配置和组件扫描这三个核心功能，使得 Spring Boot 应用的启动类非常简洁。</p>"
        },
        {
            "id": "java-framework-16",
            "question": "16. Spring Boot自动配置原理是什么",
            "difficulty": "★",
            "answer": "<p>Spring Boot 自动配置的核心原理主要依赖于以下几个关键机制和组件：</p><ol><li><strong><code>@EnableAutoConfiguration</code> 注解</strong>:<ul><li>这是启动自动配置的入口。当你在主应用类上使用 <code>@SpringBootApplication</code> (它包含了 <code>@EnableAutoConfiguration</code>) 时，自动配置机制就被激活了。 [cite: 99]</li></ul></li><li><strong>条件注解 (Conditional Annotations)</strong>:<ul><li>Spring Boot 大量使用了 Spring Framework 提供的条件注解 (如 <code>@ConditionalOnClass</code>, <code>@ConditionalOnBean</code>, <code>@ConditionalOnMissingBean</code>, <code>@ConditionalOnProperty</code>, <code>@ConditionalOnWebApplication</code> 等)。 [cite: 99]</li><li>自动配置类 (通常以 <code>XxxAutoConfiguration</code> 命名) 会使用这些条件注解来决定某个配置是否应该生效。例如，<code>@ConditionalOnClass(DataSource.class)</code> 表示只有当类路径下存在 <code>DataSource</code> 类时，相关的数据库自动配置才会生效。<code>@ConditionalOnMissingBean</code> 表示只有当Spring容器中不存在某个特定类型的Bean时，自动配置才会创建一个默认的Bean。</li></ul></li><li><strong>Spring Factories 机制 (<code>spring.factories</code>)</strong>:<ul><li>Spring Boot 通过 <code>META-INF/spring.factories</code> 文件来加载自动配置类。</li><li>在各个 <code>spring-boot-autoconfigure</code> 模块以及其他第三方 starter 的 <code>spring.factories</code> 文件中，会列出 <code>org.springframework.boot.autoconfigure.EnableAutoConfiguration</code> 键对应的自动配置类全名。</li><li>Spring Boot 启动时会读取这些 <code>spring.factories</code> 文件，找到所有声明的自动配置类。</li></ul></li><li><strong>Starter POMs (<code>spring-boot-starter-*</code>)</strong>:<ul><li>Starter POMs 是一组方便的依赖描述符，它们聚合了特定功能所需的常见依赖。例如，<code>spring-boot-starter-web</code> 会引入 Spring MVC, Tomcat (默认内嵌), Jackson 等Web开发所需的库。</li><li>当你在项目中引入一个 starter 时，相关的类库就会被添加到类路径中，这使得相应的自动配置类中的条件注解 (如 <code>@ConditionalOnClass</code>) 得以满足，从而触发自动配置。</li></ul></li><li><strong>JavaConfig 和 <code>@Bean</code> 注解</strong>:<ul><li>自动配置类本身也是 Spring 配置类 (通常用 <code>@Configuration</code> 标记)。它们内部使用 <code>@Bean</code> 注解来定义需要自动配置的 Bean。</li></ul></li></ol><p><strong>简要流程：</strong></p><ol><li>Spring Boot 启动时，<code>@EnableAutoConfiguration</code> 注解被处理。</li><li>Spring Boot 扫描所有 JAR 包中的 <code>META-INF/spring.factories</code> 文件，找到所有在 <code>EnableAutoConfiguration</code> 键下注册的自动配置类。</li><li>对每一个自动配置类，Spring Boot 会评估其上的条件注解。</li><li>如果条件满足，该自动配置类中的 <code>@Bean</code> 定义就会被执行，相应的 Bean 就会被创建并注册到 Spring 容器中。</li></ol><p>通过这种方式，Spring Boot 能够根据项目的依赖和已有配置，智能地“猜测”并提供合理的默认配置，大大减少了开发者的手动配置工作。开发者也可以通过在自己的配置中定义同类型的 Bean 来覆盖自动配置的 Bean (因为自动配置的 Bean 通常会使用 <code>@ConditionalOnMissingBean</code>)。</p>"
        },
        {
            "id": "java-framework-17",
            "question": "17、SpringBoot配置文件有哪些 怎么实现多环境配置",
            "difficulty": "★",
            "answer": "<p>Spring Boot 支持多种配置文件格式和多环境配置策略。</p><p><strong>主要配置文件：</strong></p><ol><li><strong><code>application.properties</code></strong>:<ul><li>这是最常见的配置文件格式，使用键值对的形式。</li><li>位于 <code>src/main/resources</code> 目录下。</li></ul></li><li><strong><code>application.yml</code> (或 <code>application.yaml</code>)</strong>:<ul><li>YAML 格式的配置文件，更简洁，层次感更强。</li><li>也位于 <code>src/main/resources</code> 目录下。</li><li>如果同时存在 <code>.properties</code> 和 <code>.yml</code> 文件，<code>.properties</code> 文件的优先级通常更高（具体取决于加载顺序和配置，但Spring Boot会同时加载它们，属性会合并，相同属性后者覆盖前者或根据profile优先级）。一般推荐只使用一种格式。</li></ul></li><li><strong><code>bootstrap.properties</code> 或 <code>bootstrap.yml</code></strong>:<ul><li>这个配置文件由父 ApplicationContext 加载，比 <code>application.*</code> 文件更早加载。 [cite: 99]</li><li>它的属性不能被 <code>application.*</code> 中的同名属性覆盖。 [cite: 99]</li><li>主要应用场景包括：<ul><li>使用 Spring Cloud Config 配置中心时，需要在此文件中配置连接到配置中心的属性。 [cite: 99]</li><li>存放一些固定的、不能被覆盖的属性。 [cite: 100]</li><li>一些加密/解密的场景。 [cite: 100]</li></ul></li><li>需要添加 <code>spring-cloud-starter-bootstrap</code> 依赖 (较新版本的Spring Cloud可能不再默认需要或推荐，而是通过<code>spring.config.import</code>)。</li></ul></li></ol><p><strong>多环境配置 (Profile-specific configuration):</strong></p><p>Spring Boot 允许为不同的环境（如开发、测试、生产）定义不同的配置。这可以通过 Profile 实现：</p><ol><li><strong>命名约定</strong>:<ul><li>创建特定 Profile 的配置文件，格式为 <code>application-{profileName}.properties</code> 或 <code>application-{profileName}.yml</code>。 [cite: 100]</li><li>例如：<ul><li><code>application-dev.properties</code> (开发环境)</li><li><code>application-test.properties</code> (测试环境)</li><li><code>application-prod.properties</code> (生产环境)</li></ul></li></ul></li><li><strong>激活 Profile</strong>: 有多种方式可以激活特定的 Profile：<ul><li><strong>在主配置文件中指定</strong>: 在 <code>application.properties</code> (或 <code>.yml</code>) 中设置 <code>spring.profiles.active=dev</code>。</li><li><strong>命令行参数</strong>: 运行时通过命令行参数指定：<code>java -jar myapp.jar --spring.profiles.active=prod</code>。</li><li><strong>JVM 系统属性</strong>: <code>-Dspring.profiles.active=prod</code>。</li><li><strong>环境变量</strong>: 设置名为 <code>SPRING_PROFILES_ACTIVE</code> 的环境变量。</li><li><strong>程序中设置</strong>: 通过 <code>SpringApplication.setAdditionalProfiles(\"dev\")</code>。</li></ul></li><li><strong>YAML 多文档</strong>: 在单个 <code>application.yml</code> 文件中，可以使用三个短横线 (<code>---</code>) 来分隔不同 Profile 的配置。通过 <code>spring.config.activate.on-profile</code> 属性指定该文档块属于哪个 Profile。```yaml\nspring:\n  application:\n    name: My App\n---\nspring:\n  config:\n    activate:\n      on-profile: dev\nserver:\n  port: 8081\n---\nspring:\n  config:\n    activate:\n      on-profile: prod\nserver:\n  port: 8080\n```</li><li><strong>配置加载顺序</strong>: 特定 Profile 的配置文件会覆盖主配置文件中的同名属性。如果没有特定 Profile 的配置，则使用主配置文件中的默认值。</li></ol><p>通过这些机制，Spring Boot 使得管理不同环境下的配置变得非常方便和灵活。 [cite: 100]</p>"
        },
        {
            "id": "java-framework-18",
            "question": "18、SpringBoot和Spring Cloud是什么关系",
            "difficulty": "★",
            "answer": "<p>Spring Boot 和 Spring Cloud 是 Spring 生态系统中两个既相关又有所区别的项目，它们通常一起使用来构建现代化的分布式系统（尤其是微服务架构）。</p><p><strong>关系概述：</strong></p><ul><li><strong>Spring Boot 是基础和前提</strong>: Spring Boot 提供了一个快速开发、简化配置的脚手架，用于构建独立的、生产级别的基于 Spring 的应用程序（通常是单个微服务）。 [cite: 101] Spring Cloud 的许多组件和功能都是构建在 Spring Boot 之上的，依赖于 Spring Boot 的自动配置、内嵌服务器等特性。 [cite: 102]</li><li><strong>Spring Cloud 提供微服务治理能力</strong>: Spring Cloud 是一系列框架的有序集合，它利用 Spring Boot 的开发便利性，并在此基础上提供了一套用于构建分布式系统的完整解决方案。它关注的是全局的服务治理，如服务发现、配置管理、负载均衡、断路器、API网关等。 [cite: 101]</li></ul><p><strong>具体区别与联系：</strong></p><ol><li><strong>关注点不同</strong>:<ul><li><strong>Spring Boot</strong>: 专注于快速、方便地创建和运行单个的、独立的 Spring 应用（微服务实例）。它简化了依赖管理、自动配置、内嵌服务器等。 [cite: 101]</li><li><strong>Spring Cloud</strong>: 专注于解决分布式系统中的常见问题，提供服务治理的模式和工具，使得各个微服务能够协同工作。 [cite: 101]</li></ul></li><li><strong>依赖关系</strong>:<ul><li>Spring Cloud 依赖于 Spring Boot。 [cite: 102] 你可以单独使用 Spring Boot 开发一个单体应用或一个简单的微服务，但要使用 Spring Cloud 的功能，通常必须基于 Spring Boot 项目。 [cite: 102]</li></ul></li><li><strong>“约定优于配置”理念</strong>:<ul><li>Spring Boot 贯彻了“约定优于配置”的理念，为许多集成方案提供了默认配置。 [cite: 102]</li><li>Spring Cloud 在此基础上，也为各种分布式组件提供了与 Spring Boot 风格一致的集成方式。</li></ul></li><li><strong>生态角色</strong>:<ul><li>可以把 Spring Boot 看作是构建微服务的“发动机”或“骨架”。</li><li>Spring Cloud 则是将这些“发动机”连接起来并进行管理的“神经网络”和“交通系统”。</li></ul></li></ol><p><strong>总结来说：</strong></p><p>Spring Boot 是用来快速开发单个微服务的利器，而 Spring Cloud 是基于 Spring Boot 实现的，用于构建和管理整个微服务体系的工具集。它们共同构成了构建微服务架构的强大组合。</p>"
        },
        {
            "id": "java-framework-19",
            "question": "19、SpringCloud都用过哪些组件介绍一下作用",
            "difficulty": "★",
            "answer": "<p>Spring Cloud 包含众多子项目和组件，用于解决分布式系统中的各种问题。以下是一些常用的 Spring Cloud 组件及其作用（具体使用哪些取决于项目需求）：</p><ol><li><strong>服务注册与发现 (Service Discovery & Registration)</strong>:<ul><li><strong>Nacos (Alibaba)</strong>: 不仅可以作为注册中心，还可以作为配置中心。实现服务实例的动态注册、发现、健康监测。 [cite: 102]</li><li><strong>Eureka (Netflix - 维护模式)</strong>: 曾是广泛使用的注册中心，提供服务注册和发现功能。</li><li><strong>Consul (HashiCorp)</strong>: 提供服务发现、配置管理、健康检查等功能。</li></ul><p>   作用：允许微服务动态地注册自己的位置，并能发现其他服务的位置，从而实现服务间的通信。</p></li><li><strong>服务调用/负载均衡 (Client-Side Load Balancing)</strong>:<ul><li><strong>OpenFeign (原Netflix Feign)</strong>: 一个声明式的、模板化的HTTP客户端。通过创建接口并添加注解，就可以像调用本地方法一样调用远程HTTP服务。集成了负载均衡能力（通常与Ribbon或Spring Cloud LoadBalancer配合）。 [cite: 102]</li><li><strong>Spring Cloud LoadBalancer (替代Netflix Ribbon)</strong>: 提供客户端负载均衡功能，将服务请求分发到多个服务实例上。</li><li><strong>Ribbon (Netflix - 维护模式)</strong>: 曾是主流的客户端负载均衡器。</li></ul><p>   作用：简化服务间的调用，并实现请求在多个服务实例间的智能分发，提高系统可用性和吞吐量。</p></li><li><strong>API 网关 (API Gateway)</strong>:<ul><li><strong>Spring Cloud Gateway</strong>: Spring Cloud官方推荐的新一代网关，基于Spring WebFlux (响应式编程)。提供路由、过滤、限流、安全等API入口的统一管理。 [cite: 102]</li><li><strong>Zuul (Netflix - Zuul 1进入维护模式, Zuul 2较少直接在Spring Cloud中使用)</strong>: 曾是常用的API网关。</li></ul><p>   作用：作为所有客户端请求的统一入口，负责请求路由、聚合、安全认证、监控、限流等。</p></li><li><strong>断路器/服务容错 (Circuit Breaker / Fault Tolerance)</strong>:<ul><li><strong>Sentinel (Alibaba)</strong>: 提供流量控制、熔断降级、系统负载保护等多种功能，功能强大且有可视化控制台。 [cite: 102]</li><li><strong>Resilience4j (替代Hystrix)</strong>: 一个轻量级的、易于使用的容错库，提供了断路器、限流器、重试、舱壁隔离等模式。</li><li><strong>Hystrix (Netflix - 维护模式)</strong>: 曾是主流的断路器实现。</li></ul><p>   作用：防止分布式系统中因某个服务故障导致整个系统雪崩，通过熔断、降级等机制保证系统的弹性。</p></li><li><strong>配置管理 (Configuration Management)</strong>:<ul><li><strong>Nacos Configuration</strong>: 提供动态配置管理功能，支持配置的集中管理、版本控制、动态刷新。 [cite: 102]</li><li><strong>Spring Cloud Config</strong>: 提供服务端和客户端支持，用于集中管理应用程序在所有环境中的外部配置。</li><li><strong>Consul Config</strong>: 也可用于配置管理。</li></ul><p>   作用：将应用的配置信息从代码中分离出来，进行集中管理，并支持配置的动态更新。</p></li><li><strong>分布式链路追踪 (Distributed Tracing)</strong>:<ul><li><strong>Spring Cloud Sleuth</strong>: 为Spring Cloud应用实现分布式链路追踪，可以集成Zipkin、SkyWalking等后端系统。 [cite: 102]</li><li>(通常配合Zipkin或SkyWalking等)</li></ul><p>   作用：在复杂的微服务调用链中追踪请求的完整路径，帮助定位问题和性能瓶颈。</p></li><li><strong>消息总线/事件驱动 (Message Bus / Event-Driven)</strong>:<ul><li><strong>Spring Cloud Stream</strong>: 构建基于消息驱动的微服务应用的框架。可以轻松连接到消息中间件（如RabbitMQ, Kafka）。</li><li><strong>Spring Cloud Bus</strong>: (通常与Spring Cloud Config配合) 用于将分布式系统的节点与轻量级消息代理连接起来，可以用来广播状态更改（如配置更改）。</li></ul><p>   作用：实现服务间的异步通信、解耦和事件驱动架构。</p></li></ol><p>在面试中，通常会结合自己项目中实际使用的组件来介绍其作用和使用场景。</p>"
        },
        {
            "id": "java-framework-20",
            "question": "20、Nacos作用以及注册中心的原理",
            "difficulty": "★★",
            "answer": "<p>Nacos (Dynamic Naming and Configuration Service) 是阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。</p><p><strong>Nacos的主要作用：</strong></p><ol><li><strong>服务注册与发现 (Naming Service)</strong>:<ul><li><strong>服务注册</strong>: 服务提供者（Client）启动时，将自身的实例信息（如IP地址、端口、服务名、元数据等）注册到Nacos服务器（Server）。 [cite: 102]</li><li><strong>服务发现</strong>: 服务消费者（Client）可以从Nacos服务器查询所需服务提供者的实例列表，然后通过负载均衡算法选择一个实例进行调用。 [cite: 102]</li><li><strong>健康检查</strong>: Nacos服务器会定期对注册的服务实例进行健康检查（如心跳、TCP/HTTP检查），自动剔除不健康的实例，确保服务调用的可靠性。 [cite: 102]</li></ul></li><li><strong>动态配置管理 (Configuration Service)</strong>:<ul><li><strong>配置集中管理</strong>: 允许将应用的配置信息（如数据库连接、第三方服务地址、业务参数等）存储在Nacos服务器，实现配置的集中管理。 [cite: 102]</li><li><strong>动态配置更新</strong>: 应用可以监听Nacos中配置的变化，当配置更新时，应用能够实时获取到最新的配置，无需重启服务即可生效。</li><li><strong>版本管理与回滚</strong>: 支持配置的版本管理，方便查看历史版本和回滚到指定版本。</li><li><strong>灰度发布</strong>: 支持配置的灰度发布。</li></ul></li><li><strong>动态DNS服务</strong>: Nacos 支持基于 DNS 的服务发现，方便异构系统接入。</li><li><strong>服务元数据管理</strong>: 可以管理服务的元数据信息。</li></ol><p><strong>注册中心的基本原理 (以Nacos为例)：</strong></p><ol><li><strong>服务注册 (Register)</strong>:<ul><li>服务提供者（Client）在启动时，会向Nacos Server发送注册请求，包含服务名、IP、端口、版本、权重、元数据等信息。</li><li>Nacos Server接收到注册请求后，会将这些信息存储起来（通常在内存中，并可能持久化）。</li></ul></li><li><strong>心跳续约 (Heartbeat)</strong>:<ul><li>注册成功后，服务提供者会周期性地向Nacos Server发送心跳（通常是每5秒一次），表明自己仍然存活。 [cite: 102]</li><li>如果Nacos Server在一定时间内（如15秒）没有收到某个实例的心跳，并且主动健康检查也失败，会将其标记为不健康。 [cite: 102]</li><li>如果长时间（如30秒）未收到心跳且健康检查持续失败，Nacos Server会剔除这个不健康的实例。 [cite: 102]</li></ul></li><li><strong>服务发现 (Discovery)</strong>:<ul><li>服务消费者（Client）在启动或需要调用其他服务时，会向Nacos Server查询指定服务名下的可用实例列表。</li><li>Nacos Server会返回健康的实例列表给消费者。</li><li>消费者通常会在本地缓存这份实例列表，并根据负载均衡策略选择一个实例发起调用。</li></ul></li><li><strong>服务变更通知 (Push/Polling)</strong>:<ul><li>当服务实例列表发生变化（如新实例上线、实例下线、实例健康状态改变）时，Nacos Server会主动将变更通知给订阅了该服务的消费者（通过长轮询或gRPC推送等机制）。 [cite: 102]</li><li>消费者收到通知后，会更新本地缓存的实例列表。这确保了消费者能够及时感知服务的变化。</li></ul></li><li><strong>健康检查 (Health Check)</strong>:<ul><li>Nacos Server不仅依赖客户端的心跳，还会主动对注册的实例进行健康检查（支持TCP、HTTP、MySQL等多种检查方式），以更准确地判断实例的健康状况。 [cite: 102]</li></ul></li></ol><p>通过这些机制，注册中心（如Nacos）帮助实现了微服务架构中的服务解耦、动态伸缩和高可用性。</p>"
        },
        {
            "id": "java-framework-21",
            "question": "21、Feign工作原理",
            "difficulty": "★★",
            "answer": "<p>OpenFeign (通常简称Feign) 是一个声明式的、模板化的HTTP客户端。它使得编写Java HTTP客户端变得更简单。通过创建接口并用注解来配置，Feign可以让你像调用本地方法一样调用远程HTTP服务。</p><p><strong>核心工作原理：</strong></p><ol><li><strong>启用Feign客户端 (<code>@EnableFeignClients</code>)</strong>:<ul><li>在Spring Boot主程序或配置类上添加<code>@EnableFeignClients</code>注解，这会开启对Feign客户端接口的扫描和处理。 [cite: 103]</li></ul></li><li><strong>定义Feign接口 (<code>@FeignClient</code>)</strong>:<ul><li>开发者创建一个Java接口，并使用<code>@FeignClient(\"service-name\")</code>注解标记它。<code>service-name</code>通常是目标服务在注册中心注册的服务名。 [cite: 103]</li><li>接口中的方法使用Spring MVC的注解（如<code>@RequestMapping</code>, <code>@GetMapping</code>, <code>@PostMapping</code>, <code>@PathVariable</code>, <code>@RequestParam</code>, <code>@RequestBody</code>等）来声明HTTP请求的URL、方法、参数、请求体等。</li></ul></li><li><strong>JDK动态代理生成实现类</strong>:<ul><li>当应用程序启动时，Spring Cloud会扫描所有被<code>@FeignClient</code>注解的接口。 [cite: 103]</li><li>对于每一个Feign接口，Feign会通过JDK动态代理（<code>java.lang.reflect.Proxy</code>）在运行时为其创建一个实现类（代理对象）。 [cite: 103] 这个代理对象会被注入到需要调用该远程服务的Bean中。</li></ul></li><li><strong>请求调用与处理 (<code>InvocationHandler</code>)</strong>:<ul><li>当你调用Feign接口中的一个方法时，实际上是调用了代理对象的相应方法。</li><li>这个调用会被代理对象的<code>InvocationHandler</code>（通常是Feign内部的<code>FeignInvocationHandler</code>或类似的处理器）拦截。 [cite: 103]</li></ul></li><li><strong>构建HTTP请求 (<code>RequestTemplate</code>)</strong>:<ul><li><code>InvocationHandler</code>会根据被调用的接口方法及其上的注解（如<code>@RequestMapping</code>）、方法参数等信息，为该次调用创建一个<code>RequestTemplate</code>对象。 [cite: 103]</li><li><code>RequestTemplate</code>封装了构建一个HTTP请求所需的所有元数据，如HTTP方法、目标URL（此时可能还是一个抽象的服务名+路径）、请求头、请求参数、请求体等。</li></ul></li><li><strong>编码器 (<code>Encoder</code>)</strong>:<ul><li>如果请求方法有请求体（如<code>@RequestBody</code>注解的参数），Feign会使用配置的<code>Encoder</code>（例如JacksonEncoder）将Java对象序列化为HTTP请求体（如JSON字符串）。 [cite: 103]</li></ul></li><li><strong>拦截器 (<code>RequestInterceptor</code>)</strong>:<ul><li>在请求实际发送前，可以配置一个或多个<code>RequestInterceptor</code>。这些拦截器可以修改<code>RequestTemplate</code>，例如添加统一的请求头（如认证token、trace ID等）。 [cite: 103]</li></ul></li><li><strong>生成最终请求 (<code>Request</code>)</strong>:<ul><li><code>RequestTemplate</code>经过处理后，会生成一个具体的<code>Request</code>对象。</li></ul></li><li><strong>客户端执行 (<code>Client</code> + 负载均衡)</strong>:<ul><li>这个<code>Request</code>对象会被交给一个<code>feign.Client</code>的实现类来执行。 [cite: 103]</li><li>在Spring Cloud环境中，这个<code>Client</code>通常会被<code>LoadBalancerFeignClient</code>包装，它会集成负载均衡器（如Spring Cloud LoadBalancer，旧版为Ribbon）。</li><li>负载均衡器会根据<code>@FeignClient</code>中指定的服务名，从服务注册中心获取目标服务的实例列表，并根据负载均衡策略选择一个健康的实例。</li><li>选定实例后，<code>Client</code>（可以是JDK原生的<code>URLConnection</code>, Apache HttpClient, OkHttp等 [cite: 103]）会向该实例的IP和端口发送HTTP请求。</li></ul></li><li><strong>解码器 (<code>Decoder</code>)</strong>:<ul><li>收到HTTP响应后，Feign会使用配置的<code>Decoder</code>（例如JacksonDecoder）将HTTP响应体反序列化为Java对象（接口方法的返回类型）。 [cite: 103]</li></ul></li><li><strong>错误解码器 (<code>ErrorDecoder</code>)</strong>:<ul><li>如果HTTP响应状态码表示错误（如4xx, 5xx），<code>ErrorDecoder</code>会被调用来处理错误，可以将错误信息转换为自定义的异常。</li></ul></li><li><strong>日志记录 (<code>Logger</code>)</strong>:<ul><li>Feign允许配置不同级别的日志（如NONE, BASIC, HEADERS, FULL）来记录请求和响应的详细信息，便于调试。 [cite: 103]</li></ul></li></ol><p>通过这种方式，Feign将HTTP通信的复杂性封装起来，让开发者能够以一种更面向对象、更简洁的方式进行服务间的远程调用。</p>"
        }
    ]
            },
        {
            "chapterTitle": "第四章-MySQL",
            "questions": [
                {
                    "id": "mysql-1",
                    "question": "1、Select 语句完整的执行顺序",
                    "difficulty": "★",
                    "answer": "<p>SQL Select 语句完整的执行顺序一般如下：</p><ol><li>FROM 子句：对FROM子句中的前两个表执行笛卡尔积（Cartesian product），生成虚拟表 VT1。</li><li>ON 子句：对 VT1 应用ON筛选器，只有那些使<code>&lt;join_condition&gt;</code>为真的行才被插入到 VT2。</li><li>OUTER JOIN（如 LEFT JOIN, RIGHT JOIN）：如果指定了 OUTER JOIN，那么保留表中（如左表的行对于 LEFT JOIN）未找到匹配的行将作为外部行添加到 VT2，生成 VT3。如果 FROM 子句包含两个以上的表，则会对上一个联接生成的结果表和下一个表重复执行步骤1到步骤3，直到处理完所有表为止。</li><li>WHERE 子句：对 VT3 应用 WHERE 筛选器。只有使<code>&lt;where_condition&gt;</code>为TRUE的行才被插入到 VT4。</li><li>GROUP BY 子句：按 GROUP BY 子句中的列列表对 VT4 中的行进行分组，生成 VT5。</li><li>CUBE | ROLLUP 子句（较少见，特定数据库支持）：对 VT5 应用 CUBE 或 ROLLUP 选项，超组（supergroups）将添加到 VT6。</li><li>HAVING 子句：对 VT6 应用 HAVING 筛选器。只有使<code>&lt;having_condition&gt;</code>为TRUE的组才被插入到 VT7。</li><li>SELECT 子句：处理 SELECT 列表，产生 VT8。</li><li>DISTINCT 子句：从 VT8 中删除重复的行，产生 VT9。</li><li>ORDER BY 子句：将 VT9 中的行按 ORDER BY 子句中的列列表排序，生成 VT10 (一个游标，cursor)。</li><li>LIMIT / OFFSET 子句：从 VT10 的开始处选择指定的行数，产生最终结果集。</li></ol><p>简化的顺序（PDF中提及的8点，更易于理解）：</p><ol><li>FROM 子句组装来自不同数据源的数据。</li><li>WHERE 子句基于指定的条件对记录行进行筛选。</li><li>GROUP BY 子句将数据划分为多个分组。</li><li>使用聚集函数进行计算（在SELECT或HAVING子句中）。</li><li>使用 HAVING 子句筛选分组。</li><li>计算所有的表达式（在SELECT列表中）。</li><li>SELECT 的字段。</li><li>使用 ORDER BY 对结果集进行排序。</li></ol>"
                },
                {
                    "id": "mysql-2",
                    "question": "2、MySQL事务",
                    "difficulty": "★★",
                    "answer": "<p><strong>事务的基本要素 (ACID)</strong></p><ul><li><strong>原子性 (Atomicity)</strong>: 事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。事务执行过程中出错,会回滚到事务开始前的状态。</li><li><strong>一致性 (Consistency)</strong>: 事务开始前和结束后，数据库的完整性约束没有被破坏。例如，A向B转账，不能出现A扣了钱B没收到的情况。</li><li><strong>隔离性 (Isolation)</strong>: 多个事务并发访问时，一个事务的执行不应被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。</li><li><strong>持久性 (Durability)</strong>: 一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。</li></ul><p><strong>MySQL事务隔离级别</strong></p><table><thead><tr><th>事务隔离级别</th><th>脏读 (Dirty Read)</th><th>不可重复读 (Non-Repeatable Read)</th><th>幻读 (Phantom Read)</th></tr></thead><tbody><tr><td>读未提交 (READ UNCOMMITTED)</td><td>是</td><td>是</td><td>是</td></tr><tr><td>读提交 (READ COMMITTED)</td><td>否</td><td>是</td><td>是</td></tr><tr><td>可重复读 (REPEATABLE READ) (MySQL默认)</td><td>否</td><td>否</td><td>是 (InnoDB通过MVCC+Next-Key Locks在一定程度上避免)</td></tr><tr><td>串行化 (SERIALIZABLE)</td><td>否</td><td>否</td><td>否</td></tr></tbody></table><p><strong>事务的并发问题</strong></p><ul><li><strong>脏读</strong>: 事务A读取了事务B更新但尚未提交的数据，然后若事务B回滚，事务A读取到的数据就是临时的、无效的“脏”数据。</li><li><strong>不可重复读</strong>: 事务A多次读取同一数据，事务B在事务A多次读取的过程中，对该数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。侧重于修改。</li><li><strong>幻读</strong>: 事务A读取了某个范围的数据，事务B在该范围内插入了新的数据并提交，当事务A再次读取该范围的数据时，会发现多了一些原本不存在的记录，就像发生了幻觉一样。侧重于新增或删除。</li></ul><p><strong>如何解决脏读、幻读、不可重复读</strong></p><ul><li><strong>脏读</strong>: 隔离级别设置为“读提交”、“可重复读”或“串行化”可以解决。</li><li><strong>不可重复读</strong>: 隔离级别设置为“可重复读”或“串行化”可以解决。 (通常通过MVCC或锁机制)</li><li><strong>幻读</strong>: 隔离级别设置为“串行化”可以解决。在“可重复读”隔离级别下，InnoDB存储引擎通过MVCC (多版本并发控制) 和 Next-Key Locks (间隙锁+行锁) 来防止幻读的发生。</li></ul><p><strong>小结</strong>: 不可重复读侧重于已存在记录的修改，幻读侧重于记录数量的增减。解决不可重复读通常只需锁住满足条件的行，解决幻读（在不使用串行化的情况下）需要更复杂的锁机制，如间隙锁来锁定一个范围。</p>"
                },
                {
                    "id": "mysql-3",
                    "question": "3、MyISAM和InnoDB的区别",
                    "difficulty": "★",
                    "answer": "<table><thead><tr><th>特性</th><th>MyISAM</th><th>InnoDB</th></tr></thead><tbody><tr><td>事务支持</td><td>不支持</td><td>支持 (ACID)</td></tr><tr><td>锁级别</td><td>表锁 (Table-level locking)</td><td>行锁 (Row-level locking) 和表锁，行锁并发性能更好</td></tr><tr><td>文件存储</td><td>3个文件：.frm (表结构), .MYD (数据), .MYI (索引)</td><td>通常是1个或多个表空间文件 (.ibd, ibdata1) 和 .frm (表结构)</td></tr><tr><td>外键约束</td><td>不支持</td><td>支持</td></tr><tr><td>崩溃恢复</td><td>不支持，数据易损坏</td><td>支持，通过事务日志实现崩溃恢复</td></tr><tr><td>全文索引</td><td>支持</td><td>支持 (MySQL 5.6+，早期版本不支持或性能较差)</td></tr><tr><td>存储空间</td><td>相对较小</td><td>相对较大，因为需要存储事务和多版本信息</td></tr><tr><td>默认引擎</td><td>MySQL 5.5之前是默认</td><td>MySQL 5.5及之后版本是默认存储引擎</td></tr><tr><td>适用场景</td><td>读密集型应用，对事务完整性要求不高，表锁能接受的场景</td><td>写密集型应用，对事务完整性和并发性能有较高要求的场景</td></tr></tbody></table>"
                },
                {
                    "id": "mysql-4",
                    "question": "4、悲观锁和乐观锁的怎么实现",
                    "difficulty": "★★",
                    "answer": "<p><strong>悲观锁 (Pessimistic Locking)</strong>:</p><p>悲观锁假定会发生并发冲突，所以在读取数据时就将数据锁定，直到事务完成才释放锁，以防止其他事务修改数据。</p><p>在MySQL中，通常通过<code>SELECT ... FOR UPDATE</code>或<code>SELECT ... LOCK IN SHARE MODE</code>来实现悲观锁。</p><ul><li><code>SELECT ... FOR UPDATE</code>: 获取排他锁（写锁）。其他事务不能对这些记录进行修改（<code>UPDATE</code>, <code>DELETE</code>）或再次加<code>FOR UPDATE</code>/<code>LOCK IN SHARE MODE</code>的读锁，直到当前事务提交。</li></ul><div class=\"code-block\"><code>-- 示例：锁定id为100的商品记录\nSTART TRANSACTION;\nSELECT price FROM item WHERE id = 100 FOR UPDATE;\n-- 进行其他操作，例如更新库存等\n-- UPDATE item SET stock = stock - 1 WHERE id = 100;\nCOMMIT;</code></div><p><strong>注意</strong>: <code>SELECT ... FOR UPDATE</code>语句执行中所有扫描过的行都会被锁上（不仅仅是满足条件的行，取决于索引使用情况）。因此，在MySQL中使用悲观锁务必确保查询走了索引，而不是全表扫描，否则将会将整个数据表锁住，严重影响并发。</p><p><strong>乐观锁 (Optimistic Locking)</strong>:</p><p>乐观锁假定一般情况下不会发生并发冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。如果发现冲突了，则让用户/应用决定如何去做（例如重试或报错）。</p><p>乐观锁的实现方式通常有：</p><ol><li><strong>版本号机制 (Versioning)</strong>:<ul><li>在表中增加一个数字类型的“version”字段。</li><li>读取数据时，将version字段的值一同读出。</li><li>当更新数据时，会检查当前数据库中的version值是否与之前读取到的version值相等。</li><li>如果相等，则执行更新，并将version值加1。</li><li>如果不相等，则表示数据已被其他事务修改，本次更新失败。</li></ul><div class=\"code-block\"><code>-- 1. 查询出商品信息及版本号\nSELECT quantity, version FROM items WHERE id = 100;\n-- (假设查到 quantity=10, version=1)\n\n-- 2. (应用层面)根据商品信息生成订单 (略)\n\n-- 3. 修改商品的库存 (提交更新)\nUPDATE items \nSET quantity = quantity - 1, version = version + 1 \nWHERE id = 100 AND version = 1; -- 此处的 '1' 是步骤1中读到的version值</code></div><p>如果<code>UPDATE</code>语句影响的行数为0，则表示更新失败（发生冲突）。</p></li><li><strong>时间戳机制 (Timestamp)</strong>:<ul><li>与版本号类似，只是用时间戳字段代替version字段。</li></ul></li></ol><p>乐观锁适用于读多写少的场景，可以避免长时间的锁等待，提高并发性能。</p>"
                },
                {
                    "id": "mysql-5",
                    "question": "5、聚簇索引与非聚簇索引区别",
                    "difficulty": "★★",
                    "answer": "<p>聚簇索引（Clustered Index）和非聚簇索引（Non-Clustered Index，也叫二级索引或辅助索引）都是数据库中用于加速查询的数据结构，通常基于B+树实现，但它们在数据的存储方式上有所不同。</p><p><strong>聚簇索引 (Clustered Index)</strong>:</p><ul><li><strong>定义</strong>: 聚簇索引的叶子节点直接存储了数据行本身。数据行的物理存储顺序与索引的逻辑顺序一致。</li><li><strong>特点</strong>:<ul><li>一张表只能有一个聚簇索引 (因为数据行的物理顺序只能有一种)。</li><li>在InnoDB中，主键索引默认就是聚簇索引。如果没有显式定义主键，InnoDB会选择一个唯一的非空索引代替；如果也没有这样的索引，InnoDB会隐式定义一个6字节的ROWID作为聚簇索引。</li><li>找到索引就找到了数据，查询效率高。</li></ul></li><li><strong>优势</strong>:<ul><li>通过聚簇索引查询可以直接获取数据，相比非聚簇索引（在需要回表的情况下）效率更高。</li><li>对于范围查询（例如 <code>WHERE id BETWEEN 100 AND 200</code>）效率很高，因为相关数据在物理上是连续存储的。</li><li>适合用在排序的场合。</li></ul></li><li><strong>劣势</strong>:<ul><li>维护索引的代价较高，特别是插入新行或者主键被更新导致需要页分裂（page split）的时候。建议在大量插入新行后，选择负载较低的时间段通过<code>OPTIMIZE TABLE</code>优化表。</li><li>如果表使用UUID（随机ID）作为主键，会导致数据存储稀疏，插入性能下降，聚簇索引的优势减弱，甚至可能比全表扫描更慢。因此推荐使用自增INT作为主键。</li><li>如果主键比较大，那么辅助索引（非聚簇索引）也会变得更大，因为辅助索引的叶子节点存储的是主键值。</li></ul></li></ul><p><strong>非聚簇索引 (Non-Clustered Index / Secondary Index)</strong>:</p><ul><li><strong>定义</strong>: 非聚簇索引的叶子节点存储的不是数据行本身，而是指向数据行的“指针”。在InnoDB中，这个指针通常是对应数据行的主键值。在MyISAM中，存储的是数据行的物理地址。</li><li><strong>特点</strong>:<ul><li>一张表可以有多个非聚簇索引。</li><li>数据的物理存储顺序与索引的逻辑顺序不一定一致。</li></ul></li><li><strong>查询过程</strong>:<ul><li>通过非聚簇索引查找数据时，首先在非聚簇索引树中找到对应的主键值（InnoDB）或行地址（MyISAM）。</li><li>如果是InnoDB，并且查询的列不完全被非聚簇索引覆盖（即索引覆盖），则需要再根据主键值去聚簇索引中查找完整的数据行，这个过程称为“回表”。</li></ul></li><li><strong>优势</strong>:<ul><li>创建和维护的代价相对聚簇索引较低。</li></ul></li><li><strong>劣势</strong>:<ul><li>如果查询需要回表，则会多一次磁盘I/O（或内存查找），性能相对较低。</li><li>不适合大范围的排序操作（除非索引本身就是为了排序）。</li></ul></li></ul><p><strong>总结</strong>: InnoDB中，聚簇索引决定了表的物理存储顺序，叶子节点存数据；非聚簇索引的叶子节点存主键值，查询可能需要回表。</p>"
                },
                {
                    "id": "mysql-6",
                    "question": "6、什么情况下mysql会索引失效",
                    "difficulty": "★",
                    "answer": "<p>MySQL索引失效是指查询语句虽然涉及到已建立索引的列，但优化器由于某些原因没有使用该索引（或无法有效使用索引），导致查询性能下降，可能退化为全表扫描。以下是一些常见的导致索引失效的情况：</p><ol><li><strong>在索引列上使用函数或进行计算</strong>:<ul><li>当WHERE子句中对索引列使用了函数（如<code>SUBSTRING()</code>, <code>DATE_FORMAT()</code>, <code>ABS()</code>等）或者进行了算术运算（如<code>age + 1 = 30</code>）。</li><li>例如: <code>EXPLAIN SELECT * FROM test_slow_query WHERE age + 10 = 30;</code> (age上有索引，但age+10会导致失效)</li></ul></li><li><strong>使用<code>OR</code>条件连接非索引列或多个索引的<code>OR</code>使用不当</strong>:<ul><li>如果<code>OR</code>条件连接的列中，至少有一个列没有索引，那么索引可能会失效。</li><li>即使<code>OR</code>两边的列都有索引，MySQL优化器也可能根据成本估算放弃使用索引。</li><li>例如: <code>EXPLAIN SELECT * FROM test_slow_query WHERE NAME = '吕布' OR status = 0;</code> (如果status没索引)</li></ul></li><li><strong>模糊查询 (LIKE) 以通配符<code>%</code>开头</strong>:<ul><li>当使用<code>LIKE</code>进行模糊查询，且通配符<code>%</code>位于搜索字符串的开头时（如<code>LIKE '%keyword'</code>或<code>LIKE '%keyword%'</code>），索引会失效。</li><li>如果通配符不出现在开头（如<code>LIKE 'keyword%'</code>），对于B-Tree索引是可以利用的（最左前缀匹配）。</li><li>例如: <code>EXPLAIN SELECT * FROM test_slow_query WHERE NAME LIKE '%吕布%';</code> (失效)</li><li>对比: <code>EXPLAIN SELECT * FROM test_slow_query WHERE NAME LIKE '吕布%';</code> (可能生效)</li></ul></li><li><strong>数据类型不匹配或发生隐式类型转换</strong>:<ul><li>如果查询条件中的数据类型与索引列的数据类型不匹配，MySQL可能会进行隐式类型转换，这可能导致索引失效。例如，索引列是字符串类型，但查询条件给的是数字。</li><li>例如: <code>EXPLAIN SELECT * FROM test_slow_query WHERE NAME = 11;</code> (NAME是varchar，11是数字，可能发生转换导致失效)</li></ul></li><li><strong>组合索引未使用最左前缀原则</strong>:<ul><li>对于组合索引（例如在<code>(col1, col2, col3)</code>上建立的索引），查询条件必须从索引的最左边的列开始使用，并且不能跳过中间的列，索引才能被有效利用。</li><li>例如，索引<code>(a, b, c)</code>:<ul><li><code>WHERE a = 1</code> (生效)</li><li><code>WHERE a = 1 AND b = 2</code> (生效)</li><li><code>WHERE a = 1 AND b = 2 AND c = 3</code> (生效)</li><li><code>WHERE a = 1 AND c = 3</code> (a生效，c不一定，取决于MySQL版本和优化)</li><li><code>WHERE b = 2 AND c = 3</code> (失效)</li></ul></li></ul></li><li><strong><code>IS NULL</code> 或 <code>IS NOT NULL</code> 的使用</strong>:<ul><li>在旧版本的MySQL中，对<code>NULL</code>值的索引和查询优化不佳，<code>IS NULL</code>可能导致索引失效。新版本MySQL在这方面有所改进，但仍需具体情况具体分析。通常情况下，如果索引列允许<code>NULL</code>并且包含大量<code>NULL</code>值，查询<code>IS NULL</code>的效率可能不高。</li></ul></li><li><strong><code>NOT IN (...)</code> 和 <code>&lt;&gt;</code> (或 <code>!=</code>) 操作符</strong>:<ul><li>这些负向查询和不等于操作有时会导致索引失效或优化器选择全表扫描，尤其是在结果集占比较大的情况下。</li></ul></li><li><strong>查询结果集过大</strong>:<ul><li>如果MySQL优化器估算使用索引扫描的成本（包括回表等操作）高于全表扫描的成本（例如，查询结果占了表中大部分数据），它可能会放弃使用索引而选择全表扫描。</li></ul></li><li><strong>字符集或排序规则不一致</strong>:<ul><li>如果连接操作中，连接字段的字符集或排序规则不一致，也可能导致索引失效。</li></ul></li></ol><p>通过<code>EXPLAIN</code>命令分析SQL语句的执行计划是判断索引是否生效以及如何优化的重要手段。</p>"
                },
                {
                    "id": "mysql-7",
                    "question": "7、B+tree 与B-tree区别",
                    "difficulty": "★★",
                    "answer": "<p>B-Tree（B树，或称B-树）和B+Tree（B+树）都是平衡多路搜索树，常用于数据库和文件系统的索引结构。它们的设计目标都是为了减少磁盘I/O操作。MySQL的InnoDB存储引擎主要使用B+Tree作为索引结构。</p><p><strong>主要区别：</strong></p><ol><li><strong>数据存储位置</strong>:<ul><li><strong>B-Tree</strong>: 非叶子节点和叶子节点都会存储数据（或指向数据的指针）以及键值。这意味着查找到一个键值后，可能在非叶子节点就直接获取到数据。</li><li><strong>B+Tree</strong>: 只有叶子节点才会存储数据（或指向数据的指针）。所有非叶子节点只存储键值（作为索引），不存储实际数据。所有的数据都冗余地存储在叶子节点上。</li></ul></li><li><strong>叶子节点的连接</strong>:<ul><li><strong>B-Tree</strong>: 叶子节点之间通常没有直接的指针相连。</li><li><strong>B+Tree</strong>: 所有叶子节点之间通过指针串联起来，形成一个有序链表。这使得范围查询和全表扫描（顺序遍历所有叶子节点）非常高效。</li></ul></li><li><strong>查询效率</strong>:<ul><li><strong>B-Tree</strong>: 单个键值的查询路径可能更短，因为数据可能存在于非叶子节点。但由于数据分散在所有节点，查询性能可能不稳定。</li><li><strong>B+Tree</strong>: 所有查询都必须查找到叶子节点才能获取数据，查询路径长度相对固定。由于非叶子节点不存数据，可以存放更多的键值，使得树的阶数更大，高度更低，从而减少磁盘I/O次数。</li></ul></li><li><strong>范围查询和遍历</strong>:<ul><li><strong>B-Tree</strong>: 范围查询和遍历可能需要进行多次中序遍历，效率较低。</li><li><strong>B+Tree</strong>: 由于叶子节点形成了有序链表，范围查询和顺序遍历非常高效，只需定位到范围的起始叶子节点，然后沿着链表顺序访问即可。</li></ul></li><li><strong>节点包含的键值数量</strong>:<ul><li><strong>B+Tree</strong>: 由于非叶子节点不存储数据，只存储键值，所以在相同的节点大小下，B+Tree的非叶子节点可以容纳更多的键值，从而使得树的扇出（fan-out）更大，树的高度更低。</li></ul></li></ol><p><strong>为什么MySQL InnoDB选择B+Tree？</strong></p><ul><li><strong>更低的树高，减少I/O</strong>: B+Tree的非叶子节点不存数据，可以容纳更多索引项，使得树更“矮胖”，减少磁盘I/O。在MySQL中，一个InnoDB页（默认16KB）就是一个B+树节点。一般两三层的B+树就可以支持千万级别的数据。</li><li><strong>高效的范围查询</strong>: 叶子节点通过链表连接，非常适合数据库中常见的范围查询（如 <code>BETWEEN</code>, <code>&gt;</code>, <code>&lt;</code>）和排序操作。</li><li><strong>稳定的查询性能</strong>: 所有数据查询最终都落到叶子节点，查询路径长度一致。</li><li><strong>全表扫描优化</strong>: 叶子节点的链表结构也便于进行全表扫描。</li></ul><p><em>参考文章: B-Tree和B+Tree的区别- 简书 (PDF中提及)</em></p>"
                },
                {
                    "id": "mysql-8",
                    "question": "8、以MySQL为例Linux下如何排查问题",
                    "difficulty": "★★",
                    "answer": "<p>在Linux环境下排查MySQL相关问题（如网站卡顿、服务缓慢或瘫痪）通常需要从多个层面入手：系统层面、MySQL服务层面以及SQL语句层面。</p><p><strong>1. 系统层面检查 (Linux)</strong></p><ul><li><strong>CPU、内存、I/O使用情况</strong>:<ul><li>使用<code>top</code>或<code>htop</code>命令查看系统整体负载、CPU使用率（%us, %sy, %wa, %id）、内存使用情况（free, used, buff/cache）、Swap使用情况。关注是否有CPU瓶颈、内存不足或过高的I/O等待（%wa）。</li><li><em>[图片占位符: top命令输出示例 - 根据PDF Page 40 CSDN @leader_song]</em></li><li>使用<code>vmstat</code>命令查看系统活动、硬件和系统信息。</li><li>使用<code>iostat</code>命令监控磁盘I/O。</li></ul></li><li><strong>网络连接</strong>:<ul><li>使用<code>netstat -anp | grep mysql</code> 或 <code>ss -antp | grep mysqld</code> 查看MySQL的连接数、状态（ESTABLISHED, TIME_WAIT等）。连接数过多可能耗尽资源。</li></ul></li><li><strong>MySQL进程状态</strong>:<ul><li>使用<code>ps aux | grep mysqld</code>确认MySQL进程是否在运行，占用的CPU和内存。</li></ul></li><li><strong>系统日志</strong>:<ul><li>查看系统日志<code>/var/log/messages</code>或<code>/var/log/syslog</code> (以及<code>dmesg</code>) 是否有与硬件、内核或MySQL相关的错误信息。</li></ul></li></ul><p><strong>2. MySQL 服务层面检查</strong></p><ul><li><strong>MySQL错误日志</strong>:<ul><li>定位并查看MySQL的错误日志文件（通常在MySQL数据目录下，文件名如<code>hostname.err</code>或在<code>my.cnf</code>中配置的路径）。这里记录了MySQL启动、关闭、运行中的错误、警告等重要信息。</li></ul></li><li><strong>MySQL慢查询日志</strong>:<ul><li>如果开启了慢查询日志（通过<code>my.cnf</code>配置<code>slow_query_log=ON</code>, <code>slow_query_log_file</code>, <code>long_query_time</code>），分析慢查询日志可以找到执行效率低的SQL语句。</li></ul></li><li><strong>MySQL进程列表 (Process List)</strong>:<ul><li>登录MySQL后执行 <code>SHOW FULL PROCESSLIST;</code>。查看当前所有连接的线程状态（如Query, Locked, Sending data, Sleep等）、执行的SQL语句、执行时间。可以发现长时间运行的查询或锁等待。</li></ul></li><li><strong>MySQL状态变量 (Status Variables)</strong>:<ul><li>执行 <code>SHOW GLOBAL STATUS LIKE '%Threads%';</code> (查看线程相关状态，如Threads_connected, Threads_running)</li><li>执行 <code>SHOW GLOBAL STATUS LIKE '%Queries%';</code> (查看查询次数)</li><li>执行 <code>SHOW ENGINE INNODB STATUS;</code> (查看InnoDB存储引擎的详细状态，包括事务、锁、缓冲池等)</li></ul></li><li><strong>MySQL配置 (my.cnf)</strong>:<ul><li>检查MySQL的配置文件<code>my.cnf</code>（或<code>my.ini</code>）中的参数设置是否合理，如缓冲池大小（<code>innodb_buffer_pool_size</code>）、连接数（<code>max_connections</code>）、日志设置等。</li></ul></li><li><strong>主从复制状态 (如果使用主从架构)</strong>:<ul><li>在从库上执行 <code>SHOW SLAVE STATUS\\G</code>，检查<code>Slave_IO_Running</code>, <code>Slave_SQL_Running</code>是否都为<code>Yes</code>，以及<code>Seconds_Behind_Master</code>的值，判断主从同步是否正常，有无延迟。</li></ul></li></ul><p><strong>3. SQL语句及表结构层面检查</strong></p><ul><li><strong>Explain分析SQL</strong>:<ul><li>对于慢查询日志中或<code>SHOW PROCESSLIST</code>中发现的慢SQL，使用<code>EXPLAIN SELECT ...;</code>来分析其执行计划。</li><li>关注<code>EXPLAIN</code>输出中的关键列：<ul><li><code>type</code>: 连接类型 (如ALL-全表扫描, index-索引扫描, range-范围扫描, ref-非唯一索引访问, eq_ref-唯一索引访问, const/system-常量级)。尽量避免ALL。</li><li><code>possible_keys</code>: 可能使用的索引。</li><li><code>key</code>: 实际使用的索引。如果为NULL，表示没有使用索引。</li><li><code>key_len</code>: 索引使用的字节数。</li><li><code>rows</code>: MySQL估计需要扫描的行数。越小越好。</li><li><code>Extra</code>: 额外信息，如<code>Using filesort</code>（磁盘排序，性能差）、<code>Using temporary</code>（使用临时表）、<code>Using index</code>（索引覆盖）、<code>Using where</code>。</li></ul></li><li><em>[图片占位符: EXPLAIN输出示例 - 根据PDF Page 40]</em></li></ul></li><li><strong>索引优化</strong>: 根据<code>EXPLAIN</code>结果，判断是否需要添加、修改或删除索引。确保查询条件、排序、分组字段能有效利用索引。</li><li><strong>表结构设计</strong>: 检查表结构设计是否合理，是否存在大量冗余字段，字段类型是否选择恰当。</li><li><strong>查询语句重写</strong>: 优化SQL语句本身，如避免<code>SELECT *</code>、减少JOIN、拆分复杂查询等。</li></ul><p>排查问题时，通常需要结合这些层面进行综合分析，逐步定位问题根源。</p>"
                },
                {
                    "id": "mysql-9",
                    "question": "9、如何处理慢查询",
                    "difficulty": "★★",
                    "answer": "<p>处理慢查询是一个系统性的工作，通常包括发现、分析和优化三个主要步骤。</p><p><strong>1. 发现慢查询</strong></p><ul><li><strong>开启并监控慢查询日志 (Slow Query Log)</strong>:<ul><li>这是定位慢查询最直接的方式。需要在MySQL配置文件(<code>my.cnf</code>或<code>my.ini</code>)中启用慢查询日志：<div class=\"code-block\"><code>slow_query_log = ON\nslow_query_log_file = /path/to/mysql-slow.log # 日志文件路径\nlong_query_time = 2 # 定义超过多少秒的查询被认为是慢查询 (单位: 秒，例如2秒)\nlog_queries_not_using_indexes = ON # (可选) 记录没有使用索引的查询</code></div></li><li>定期查看和分析慢查询日志文件。可以使用工具如<code>mysqldumpslow</code>来汇总和排序慢查询。</li></ul></li><li><strong><code>SHOW FULL PROCESSLIST;</code></strong>:<ul><li>实时查看当前正在执行的查询，可以通过<code>Time</code>列发现执行时间过长的查询。但这只能捕获当前正在运行的，可能错过已完成的慢查询。</li></ul></li><li><strong>性能监控工具</strong>:<ul><li>使用第三方或云服务商提供的数据库性能监控工具（如Percona Monitoring and Management (PMM), Prometheus+Grafana, 阿里云RDS控制台的慢SQL分析等），它们通常能提供更直观的慢查询分析和趋势。</li></ul></li></ul><p><strong>2. 分析慢查询原因</strong></p><p>一旦找到慢查询SQL语句，就需要分析其缓慢的原因：</p><ul><li><strong>使用 <code>EXPLAIN</code> 分析执行计划</strong>:<ul><li>这是最重要的分析手段。<code>EXPLAIN SELECT ...;</code> 会显示MySQL优化器为该SQL选择的执行路径。</li><li>重点关注<code>EXPLAIN</code>输出的列：<ul><li><code>type</code>: 连接类型。目标是至少达到<code>range</code>, 最好是<code>ref</code>, <code>eq_ref</code>, <code>const</code>。避免<code>ALL</code>（全表扫描）。</li><li><code>possible_keys</code>: MySQL认为可能用到的索引。</li><li><code>key</code>: 实际选择使用的索引。如果为NULL，表示没有使用索引。</li><li><code>key_len</code>: 实际使用索引的长度。长度越短通常越好，但也需要足够区分度。</li><li><code>rows</code>: MySQL估计需要扫描的行数。这个值越小越好。</li><li><code>Extra</code>: 包含额外信息，如<code>Using filesort</code>（需要额外排序操作，性能瓶颈）、<code>Using temporary</code>（使用了临时表，性能瓶颈）、<code>Using index</code>（索引覆盖扫描，较好）、<code>Using where</code>。</li></ul></li><li><em>[图片占位符: EXPLAIN输出示例及关键字段说明 - 根据PDF Page 41 CSDN @leader_song]</em></li></ul></li><li><strong>检查索引情况</strong>:<ul><li>查询是否命中了合适的索引？</li><li>索引是否是最优的？是否存在冗余索引或缺失索引？</li><li>组合索引是否遵循了最左前缀原则？</li></ul></li><li><strong>数据量和表结构</strong>:<ul><li>涉及的表数据量是否过大？</li><li>是否加载了不需要的数据列（如使用了<code>SELECT *</code>）？</li><li>是否查询了多余的行然后被应用层抛弃？</li></ul></li><li><strong>SQL语句本身</strong>:<ul><li>SQL语句是否写得复杂或低效？例如，过多的JOIN，不必要的子查询，WHERE条件中对列进行了函数运算等。</li></ul></li><li><strong>服务器状态和负载</strong>:<ul><li>数据库服务器当前的CPU、内存、I/O负载是否过高？是否有其他大量请求并发执行？</li></ul></li></ul><p><strong>3. 优化慢查询</strong></p><p>根据分析结果，采取相应的优化措施：</p><ul><li><strong>索引优化</strong>:<ul><li>为WHERE子句、JOIN条件、ORDER BY、GROUP BY中频繁使用的列创建或调整索引。</li><li>删除未使用或冗余的索引。</li><li>优化组合索引的列顺序。</li></ul></li><li><strong>SQL语句重写</strong>:<ul><li>避免<code>SELECT *</code>，只查询需要的列。</li><li>改写WHERE子句，避免索引失效的情况（如避免在列上使用函数）。</li><li>将复杂的查询拆分为多个简单查询，或者使用JOIN替代某些子查询（也可能反过来，视情况而定）。</li><li>使用更有效的JOIN顺序。</li><li>对于分页查询，如果<code>LIMIT offset, count</code>中offset很大，考虑使用基于主键的延迟关联或其他优化方法。</li></ul></li><li><strong>表结构优化</strong>:<ul><li>如果数据量过大，考虑分表（水平分表或垂直分表）。</li><li>规范化或反规范化（根据具体场景权衡）。</li><li>选择合适的字段数据类型。</li></ul></li><li><strong>应用层面优化</strong>:<ul><li>增加缓存（如Redis）来缓存热点数据，减少数据库查询。</li><li>对于某些统计类查询，可以考虑异步处理或预计算。</li></ul></li><li><strong>硬件和配置优化</strong>:<ul><li>升级硬件（CPU、内存、SSD）。</li><li>调整MySQL配置参数（如<code>innodb_buffer_pool_size</code>, <code>query_cache_size</code>(较新版本已移除或不推荐), 各种连接和排序缓冲区大小）。</li></ul></li></ul><p>处理慢查询是一个持续的过程，需要定期监控和优化。</p>"
                },
                {
                    "id": "mysql-10",
                    "question": "10、数据库分表操作",
                    "difficulty": "★",
                    "answer": "<p>当单表数据量过大（例如达到几百万、上千万甚至更多行）时，查询、插入、更新、删除以及索引维护的性能都会显著下降。此时，数据库分表是常用的优化手段，旨在将一个大表的数据分散到多个小表中，以提高性能和可管理性。</p><p>主要有两种分表方式：水平分表和垂直分表。</p><p><strong>1. 水平分表 (Horizontal Partitioning / Sharding)</strong></p><ul><li><strong>定义</strong>: 按照某种规则（通常是基于某个字段的值，如用户ID、时间戳等），将一个表中的数据行分散到多个物理结构相同但存储不同数据段的表中。每个分表只包含原始表数据的一个子集。</li><li><strong>切分规则示例</strong>:<ul><li><strong>范围切分 (Range Sharding)</strong>: 根据某个字段的范围来划分。例如，按年份分表，订单表可以分为<code>orders_2023</code>, <code>orders_2024</code>等；或按ID范围，如<code>users_1_1000000</code>, <code>users_1000001_2000000</code>。PDF中提到的“步长法”（如1000万一张表拆分）属于此类。</li><li><strong>哈希/取模切分 (Hash/Modulo Sharding)</strong>: 根据某个字段（通常是ID）的哈希值或取模结果来决定数据存储到哪个分表。例如，根据用户ID对分表数量取模：<code>user_id % N</code> (N为分表数量)。</li><li><strong>时间切分</strong>: 按时间维度切分，如按月、按季度。</li></ul></li><li><strong>优点</strong>:<ul><li>单表数据量减小，提高查询性能。</li><li>索引更小，维护更快。</li><li>可以将不同的分表存储在不同的物理服务器上，进一步分散I/O压力。</li></ul></li><li><strong>缺点</strong>:<ul><li>跨分表的查询和统计变得复杂。</li><li>事务处理可能需要分布式事务。</li><li>数据迁移和扩容相对复杂。</li><li>需要选择合适的Sharding Key（分片键）。</li></ul></li></ul><p><strong>2. 垂直分表 (Vertical Partitioning)</strong></p><ul><li><strong>定义</strong>: 按照表中列的相关性或访问频率，将一个包含很多列的“宽表”拆分成多个“窄表”。每个拆分后的表包含原始表的主键和一个列子集。</li><li><strong>切分原则示例</strong>:<ul><li>将不常用的字段、大字段（如TEXT, BLOB类型）分离到单独的表中。</li><li>将经常一起查询的字段放在同一个表中。</li><li>例如，一个包含用户基本信息和用户详细描述的<code>user</code>表，可以将详细描述（大字段，访问频率低）拆分到<code>user_profile</code>表中，两个表通过<code>user_id</code>关联。PDF中提到“大表拆小表。商品信息 spu_info spu_image...”也体现了此思想。</li></ul></li><li><strong>优点</strong>:<ul><li>减少单行数据的宽度，提高查询时I/O效率（特别是当只需要访问部分列时）。</li><li>可以针对不同表的特性进行优化（如不同存储引擎，不同缓存策略）。</li><li>提高缓存命中率。</li></ul></li><li><strong>缺点</strong>:<ul><li>查询所有数据时需要进行JOIN操作，增加了查询复杂度。</li><li>可能引入数据冗余或事务管理复杂性（如果需要在多个表间保持一致性）。</li></ul></li></ul><p><strong>实现分表的方案/中间件</strong>:</p><ul><li><strong>应用层逻辑</strong>: 在应用程序代码中实现分库分表的路由逻辑。灵活性高，但开发和维护成本也高。</li><li><strong>数据库中间件</strong>:<ul><li><strong>MyCat</strong>: 开源的分布式数据库中间件，支持数据分片、读写分离、数据聚合等。</li><li><strong>ShardingSphere (原Sharding-JDBC, Sharding-Proxy)</strong>: Apache顶级项目，提供数据分片、分布式事务、数据治理、数据加密等一站式数据解决方案。可以以JDBC驱动（Sharding-JDBC）、代理（Sharding-Proxy）或Sidecar（Sharding-Sidecar，规划中）模式运行。</li></ul></li><li><strong>数据库自带分区功能</strong>: 某些数据库（如MySQL的Partitioning）提供了表内分区的能力，逻辑上仍是一张表，但物理上数据按规则存储在不同分区。这与应用层或中间件实现的分库分表有所不同，但也是处理大数据量的一种方式。</li></ul><p>选择分表策略时，需要仔细分析业务场景、数据增长趋势、查询模式等因素。<em>(参考: MySQL分库分表,写得太好了!-mysql分库分表 - PDF中提及)</em></p>"
                },
                {
                    "id": "mysql-11",
                    "question": "11、MySQL优化",
                    "difficulty": "★",
                    "answer": "<p>MySQL优化是一个多方面的工作，涉及到服务器配置、表结构设计、SQL语句编写以及应用架构等多个层面。以下是一些常见的MySQL优化点：</p><p><strong>1. 表结构与列设计优化</strong></p><ul><li><strong>选择合适的列类型</strong>: 尽量选择占用存储空间小且能满足业务需求的列类型（如用<code>TINYINT</code>代替<code>INT</code>如果范围允许）。 [cite: 121]</li><li><strong>避免<code>NULL</code>值</strong>: 尽可能将字段定义为<code>NOT NULL</code>并设置默认值。<code>NULL</code>值在索引、索引统计和值比较时都更复杂，MySQL更难优化，且<code>NULL</code>可能需要额外的存储空间。查询<code>NULL</code>只能用<code>IS NULL</code>或<code>IS NOT NULL</code>。 [cite: 122, 126]</li><li><strong>避免使用<code>TEXT</code>/<code>BLOB</code>存储大对象</strong>: 如果不是必须，考虑将大字段拆分到单独的表中，或使用其他存储方案（如对象存储系统）。</li></ul><p><strong>2. 索引优化</strong></p><ul><li><strong>为频繁查询的列建立索引</strong>: 在<code>WHERE</code>子句、<code>JOIN</code>条件、<code>ORDER BY</code>、<code>GROUP BY</code>中经常用到的列上建立索引。 [cite: 122]</li><li><strong>选择合适的索引类型</strong>: 如B-Tree索引、哈希索引（特定场景）、全文索引。</li><li><strong>组合索引与最左前缀原则</strong>: 合理设计组合索引的列顺序，并遵循最左前缀原则。</li><li><strong>避免在索引列上进行计算或使用函数</strong>: 这会导致索引失效。 [cite: 122]</li><li><strong>避免索引过多</strong>: 过多的索引会增加写操作（INSERT, UPDATE, DELETE）的开销，并影响优化器的选择。建议单表索引数量控制在5个以内。 [cite: 127]</li><li><strong>索引覆盖扫描</strong>: 如果查询所需的所有列都包含在索引中，就可以避免回表，提高查询效率。</li></ul><p><strong>3. SQL语句优化</strong></p><ul><li><strong>避免<code>SELECT *</code></strong>: 只查询需要的字段。这样可以减少网络传输量、I/O消耗，并且更容易利用索引覆盖。 [cite: 122, 127]</li><li><strong>优化<code>WHERE</code>子句</strong>: 确保条件能有效利用索引。避免使用<code>OR</code>连接非索引列、<code>LIKE '%keyword'</code>、负向查询（<code>NOT IN</code>, <code>!=</code>）等可能导致索引失效的写法。 [cite: 127]</li><li><strong>优化<code>JOIN</code>查询</strong>:<ul><li>确保<code>JOIN</code>的连接字段类型相同，并已建立索引。 [cite: 127]</li><li>选择最有效的表名顺序（对于某些类型的JOIN，如STRAIGHT_JOIN，或优化器难以判断时）。通常用小结果集驱动大结果集。 [cite: 122, 125]</li><li>避免大表JOIN，考虑拆分查询。 [cite: 127]</li></ul></li><li><strong>优化<code>ORDER BY</code>和<code>GROUP BY</code></strong>: 确保这些操作能利用索引，避免<code>Using filesort</code>。</li><li><strong>使用<code>LIMIT</code>优化</strong>: 当只需要一行数据时，使用<code>LIMIT 1</code>。 [cite: 122] 对于大偏移量的分页查询（如<code>LIMIT 100000, 10</code>），考虑使用延迟关联或其他优化技巧。 [cite: 125]</li><li><strong>避免或优化子查询</strong>: 尽量用<code>JOIN</code>替代子查询，或确保子查询高效执行。 [cite: 122]</li><li><strong>使用批量操作</strong>: 对于批量插入或更新，使用批处理方式减少数据库交互。</li></ul><p><strong>4. 数据库配置优化 (<code>my.cnf</code>)</strong></p><ul><li>调整关键参数，如<code>innodb_buffer_pool_size</code>, <code>key_buffer_size</code> (MyISAM), <code>query_cache_size</code> (较新版本已移除或不推荐), <code>max_connections</code>, <code>sort_buffer_size</code>, <code>join_buffer_size</code>等。</li></ul><p><strong>5. 架构层面优化</strong></p><ul><li><strong>读写分离</strong>: 使用主从复制，将读操作分发到从库。</li><li><strong>分库分表</strong>: 当单表数据量过大时，进行水平或垂直分表。 [cite: 122]</li><li><strong>使用缓存</strong>: 如Redis、Memcached，缓存热点数据，减少数据库访问。</li></ul><p><strong>6. 定期维护</strong></p><ul><li>分析慢查询日志，持续优化。</li><li>定期执行<code>OPTIMIZE TABLE</code>（对有大量删除或更新的表）。</li><li>监控数据库性能指标。</li></ul><p>优化是一个持续的过程，需要结合具体业务场景和性能监控数据进行调整。</p>"
                },
                {
                    "id": "mysql-12",
                    "question": "12、SQL语句优化案例",
                    "difficulty": "★",
                    "answer": "<p><strong>例1: WHERE子句中可以对字段进行NULL值判断吗？如何优化？</strong></p><ul><li><strong>原语句 (可行但可能不优)</strong>: <code>SELECT id FROM t WHERE num IS NULL;</code></li><li><strong>问题</strong>: 虽然SQL本身可行，但如果<code>num</code>列允许NULL且索引和统计信息处理复杂，性能可能不佳。最好避免在表中存储NULL，尽可能使用<code>NOT NULL</code>并设置默认值。</li><li><strong>优化建议</strong>: 将<code>num</code>列设置为<code>NOT NULL DEFAULT 0</code>，确保表中没有NULL值。然后查询：<code>SELECT id FROM t WHERE num = 0;</code></li></ul><p><strong>例2: 如何优化左连接 (LEFT JOIN) 查询？</strong></p><ul><li><strong>原语句 (可能低效)</strong>: <code>SELECT * FROM admin LEFT JOIN log ON admin.admin_id = log.admin_id WHERE log.admin_id > 10;</code></li><li><strong>问题</strong>: 如果<code>log</code>表很大，先进行全连接再用<code>log.admin_id > 10</code>过滤，可能会扫描很多不必要的行。</li><li><strong>优化建议 (先过滤驱动表)</strong>: 如果逻辑允许，并且<code>admin_id > 10</code>的条件主要作用于<code>admin</code>表，可以先缩小驱动表（左表）的结果集：<div class=\"code-block\"><code>SELECT * \nFROM (SELECT * FROM admin WHERE admin_id > 10) T1 \nLEFT JOIN log ON T1.admin_id = log.admin_id;</code></div></li><li><strong>通用JOIN优化原则</strong>: 使用JOIN时，应尽量用小的结果集驱动大的结果集（对于<code>LEFT JOIN</code>，左表结果集尽量小，若有条件应先在左边处理；<code>RIGHT JOIN</code>同理反向）。尽量把涉及多表联合的查询拆分为多个简单查询，因为复杂的连表查询效率可能较低，容易导致锁表和阻塞。 [cite: 125]</li></ul><p><strong>例3: LIMIT的基数比较大时如何优化？</strong></p><ul><li><strong>原语句 (大偏移量时性能差)</strong>: <code>SELECT * FROM admin ORDER BY admin_id LIMIT 100000, 10;</code></li><li><strong>问题</strong>: MySQL需要扫描并丢弃前100000条记录，开销很大。</li><li><strong>优化建议 (使用<code>BETWEEN</code>或子查询/延迟关联)</strong>:<ol><li>如果<code>admin_id</code>是连续或接近连续的，且可以确定范围：<div class=\"code-block\"><code>SELECT * FROM admin WHERE admin_id BETWEEN 100000 AND 100009 ORDER BY admin_id LIMIT 10; \n-- (注意：这里假设admin_id从0或1开始且连续，实际情况可能需要调整边界值，例如查询主键的最大值等)</code></div></li><li>使用子查询定位到起始ID（延迟关联）：<div class=\"code-block\"><code>SELECT a.* \nFROM admin a \nINNER JOIN (SELECT admin_id FROM admin ORDER BY admin_id LIMIT 100000, 10) b ON a.admin_id = b.admin_id;</code></div></li></ol></li></ul><p><strong>例4: 避免在索引列上做运算导致索引失效</strong></p><ul><li><strong>原语句 (索引失效)</strong>: <code>SELECT * FROM admin WHERE YEAR(admin_time) > 2014;</code> (假设<code>admin_time</code>有索引)</li><li><strong>问题</strong>: 对<code>admin_time</code>列使用<code>YEAR()</code>函数会导致索引失效。</li><li><strong>优化建议 (改写条件，让列保持原始状态)</strong>: <div class=\"code-block\"><code>SELECT * FROM admin WHERE admin_time > '2014-12-31 23:59:59'; \n-- 或者更精确地，如果只需要比较年份：\n-- SELECT * FROM admin WHERE admin_time >= '2015-01-01 00:00:00';</code></div></li></ul>"
                },
                {
                    "id": "mysql-13",
                    "question": "13、你们公司有哪些数据库设计规范",
                    "difficulty": "★",
                    "answer": "<p>数据库设计规范对于保证数据一致性、性能、可维护性和团队协作至关重要。以下是一些常见的数据库设计规范，适用于并发量大、数据量大的典型互联网业务：</p><p><strong>(一) 基础规范</strong></p><ul><li>表存储引擎必须使用<code>InnoDB</code>。表字符集默认使用<code>utf8</code>，必要时候（如存储表情符号）使用<code>utf8mb4</code>。 [cite: 126]</li><li>禁止使用存储过程、视图、触发器、Event。这些功能对数据库性能影响较大，调试、排错、迁移困难，扩展性差。尽量让应用层或服务层处理逻辑。 [cite: 126]</li><li>禁止在数据库中存储大文件（如照片、二进制大对象）。应将大文件存储在对象存储系统（如S3, OSS），数据库中仅存储其访问路径。 [cite: 126]</li><li>禁止在线上环境做数据库压力测试。 [cite: 126]</li><li>测试、开发、线上数据库环境必须严格隔离。 [cite: 126]</li></ul><p><strong>(二) 命名规范</strong></p><ul><li>库名、表名、列名必须使用小写字母，并采用下划线分隔（例如 `user_order_detail`）。 [cite: 126]</li><li>库名、表名、列名必须见名知义，清晰表达其用途，长度不宜超过32个字符。 [cite: 126]</li><li>库备份必须以<code>bak_</code>为前缀，并以日期为后缀（例如 `bak_mydatabase_20240523`）。 [cite: 126]</li><li>从库（Slave）命名必须以<code>-s</code>或<code>_slave</code>为后缀。 [cite: 126]</li><li>备库（Standby/Backup Master）命名必须以<code>-ss</code>或<code>_standby</code>为后缀。 [cite: 126]</li></ul><p><strong>(三) 表设计规范</strong></p><ul><li>单MySQL实例中的表个数建议控制在2000个以内。 [cite: 126]</li><li>单表进行分表时，分表的数量建议控制在1024个以内。 [cite: 126]</li><li>表必须有主键。推荐使用<code>UNSIGNED</code>整数类型（如<code>INT UNSIGNED</code>, <code>BIGINT UNSIGNED</code>）作为主键，通常设为自增 (<code>AUTO_INCREMENT</code>)。避免使用可能产生业务含义的字段作主键。 [cite: 126]</li><li>禁止使用外键约束。如需保证数据完整性，应由应用程序层面实现。外键会使表之间耦合，影响DML性能，可能造成死锁，在高并发下易成瓶颈。 [cite: 126]</li><li>建议将大字段（如<code>TEXT</code>, <code>BLOB</code>）、访问频度低的字段拆分到单独的表中存储，实现冷热数据分离。 [cite: 126]</li><li>单表数据量建议控制在一定范围内（例如，PDF中提到不超过200W，但这个数字有争议，更实际的是看查询性能和维护成本，一般建议单表物理大小和行数不要使其成为性能瓶颈）。</li></ul><p><strong>(四) 列设计规范</strong></p><ul><li>根据业务需求和数据范围，精确选择数值类型（如<code>TINYINT</code>, <code>INT</code>, <code>BIGINT</code>），避免浪费存储空间。 [cite: 126]</li><li>根据业务场景区分使用<code>CHAR</code>和<code>VARCHAR</code>：字段长度固定或长度近似的用<code>CHAR</code>（减少碎片，查询性能高）；字段长度相差较大或更新较少的用<code>VARCHAR</code>（节省空间）。 [cite: 126]</li><li>根据业务需求区分使用日期时间类型（如<code>YEAR</code>, <code>DATE</code>, <code>DATETIME</code>, <code>TIMESTAMP</code>）。<code>TIMESTAMP</code>占用4字节并受时区影响，<code>DATETIME</code>占用5字节（MySQL 5.6.4前是8字节）。 [cite: 126]</li><li>必须把字段定义为<code>NOT NULL</code>并设置合适的默认值。<code>NULL</code>列使索引、统计和值比较更复杂，MySQL更难优化，且<code>NULL</code>可能占用额外空间（取决于数据类型和存储格式），查询时只能用<code>IS NULL</code>或<code>IS NOT NULL</code>。 [cite: 126]</li><li>使用<code>INT UNSIGNED</code>存储IPv4地址，不要用<code>CHAR(15)</code>。 [cite: 126]</li><li>使用<code>VARCHAR(20)</code>或类似长度存储手机号，不要使用整数类型（因为手机号可能包含<code>+</code>,<code>-</code>,<code>(</code>,<code>)</code>等非数字字符，且不需要进行数学运算，<code>VARCHAR</code>还便于模糊查询）。 [cite: 126]</li><li>使用<code>TINYINT</code>来代替<code>ENUM</code>类型，因为<code>ENUM</code>增加新值需要执行DDL操作，灵活性差。 [cite: 126]</li></ul><p><strong>(五) 索引规范</strong></p><ul><li>唯一索引命名建议以<code>uniq_</code>为前缀，后跟字段名（例如 `uniq_username`）。 [cite: 126]</li><li>非唯一索引命名建议以<code>idx_</code>为前缀，后跟字段名（例如 `idx_create_time`）。 [cite: 126]</li><li>单张表的索引数量建议控制在5个以内。过多的索引会影响写性能，并可能导致优化器选择不到最优索引。 [cite: 127]</li><li>组合索引的字段数量不建议超过5个。如果5个字段还不能有效缩小查询范围，可能需要重新审视表设计或查询逻辑。 [cite: 127]</li><li>不建议在频繁更新的字段上建立索引，因为索引维护成本高。 [cite: 127]</li><li>进行<code>JOIN</code>查询时，被<code>JOIN</code>的字段必须类型相同，并为这些字段建立索引。 [cite: 127]</li><li>理解并利用组合索引的“最左前缀原则”，避免重复建设索引。例如，建立了<code>(a,b,c)</code>索引，相当于也建立了<code>(a)</code>和<code>(a,b)</code>的索引效果。 [cite: 127]</li></ul><p><strong>(六) SQL规范</strong></p><ul><li>禁止使用<code>SELECT *</code>，明确指定需要查询的字段。这能减少CPU/IO/内存/带宽消耗，有效利用索引覆盖，并在表结构变更时保证对应用程序的最小影响。 [cite: 127]</li><li><code>INSERT</code>语句必须指定字段列表，禁止使用<code>INSERT INTO T VALUES(...)</code>的隐式字段写法，以应对表结构变更。 [cite: 127]</li><li>避免隐式类型转换，它可能导致索引失效和全表扫描。 [cite: 127]</li><li>禁止在<code>WHERE</code>条件列上使用函数或表达式，这通常会导致索引失效。 [cite: 127]</li><li>禁止负向查询（如<code>NOT IN</code>, <code>!=</code>）以及<code>%</code>开头的模糊查询（如<code>LIKE '%val'</code>），这些通常无法有效利用索引。 [cite: 127]</li><li>禁止（或谨慎评估）大表之间的<code>JOIN</code>和复杂的子查询。 [cite: 127]</li><li>同一个字段上的多个<code>OR</code>条件，如果可行，尽量改写为<code>IN</code>子句，且<code>IN</code>列表中的值数量不宜过多（例如，PDF建议少于50个）。 [cite: 127]</li><li>应用程序必须捕获并妥善处理SQL异常，方便定位线上问题。 [cite: 127]</li></ul><p>这些规范旨在提高数据库的性能、稳定性和可维护性。</p>"
                },
                {
                    "id": "mysql-14",
                    "question": "14、有没有设计过数据表?你是如何设计的",
                    "difficulty": "★",
                    "answer": "<p>是的，在项目开发过程中，我有过设计数据表的经验。设计数据表时，我会遵循数据库设计的基本原则和范式，同时结合具体的业务需求和性能考虑。</p><p><strong>基本设计流程和考虑点：</strong></p><ol><li><strong>需求分析</strong>:<ul><li>明确业务需求，需要存储哪些信息，信息之间的关系是怎样的（一对一，一对多，多对多）。</li><li>了解数据的特点，如数据量预估、增长速度、查询模式（哪些查询最频繁，查询条件是什么）、更新频率等。</li></ul></li><li><strong>概念设计 (ER图)</strong>:<ul><li>识别出主要的实体（Entities）及其属性（Attributes）。</li><li>确定实体之间的关系（Relationships）。</li><li>绘制ER图（实体-关系图）来可视化数据模型。</li></ul></li><li><strong>逻辑设计 (关系模式)</strong>:<ul><li>将ER图转换为关系模式（即表结构）。</li><li>选择合适的数据类型和约束（主键、外键（如果使用）、唯一约束、非空约束、默认值、检查约束等）。</li><li>应用数据库范式进行规范化，以减少数据冗余和避免更新异常。</li></ul></li><li><strong>物理设计</strong>:<ul><li>考虑数据库管理系统（如MySQL）的具体特性。</li><li>设计索引策略，为常用查询条件、连接字段、排序字段创建索引。</li><li>考虑是否需要分区、分表等。</li><li>预估存储空间。</li></ul></li><li><strong>评审和迭代</strong>:<ul><li>与团队成员（包括其他开发人员、DBA、产品经理）一起评审表设计。</li><li>根据反馈进行修改和完善。设计是一个迭代的过程。</li></ul></li></ol><p><strong>遵循的数据库范式（主要考虑前三个）：</strong></p><p>数据库范式是设计关系数据库时遵循的一些基本规则，目的是减少数据冗余，提高数据一致性。</p><ul><li><strong>第一范式 (1NF)</strong>:<ul><li><strong>定义</strong>: 要求数据库表的每一列属性（字段）都是不可分割的原子数据项，即字段必须保证原子性。 [cite: 128]</li><li><strong>解释</strong>: 表中的每个字段都应该是最小的逻辑单元，不能再细分。例如，不应该有一个“地址”字段包含完整的省市区街道，而应将其拆分为“省”、“市”、“区”、“街道”等字段。</li></ul></li><li><strong>第二范式 (2NF)</strong>:<ul><li><strong>定义</strong>: 在满足1NF的基础上，要求表中的每一行数据只能与其中一个主键列相关（对于组合主键，非主键列必须完全依赖于整个主键，而不是部分主键）。每一行数据只能表达一个意思。 [cite: 128]</li><li><strong>解释</strong>: 如果一个表有组合主键，那么所有非主键属性必须完全依赖于这个组合主键，而不是仅依赖于组合主键的一部分。如果出现部分依赖，就需要将表拆分。例如，订单详情表（订单ID、商品ID 为组合主键），商品名称只依赖于商品ID，就应该把商品名称放到商品表中。只要数据出现对主键的部分依赖或传递依赖，就需要考虑拆分。</li></ul></li><li><strong>第三范式 (3NF)</strong>:<ul><li><strong>定义</strong>: 在满足2NF的基础上，要求表中的非主键列之间不能存在传递依赖关系。即每个非主键属性都必须直接依赖于主键，而不是间接依赖。 [cite: 128]</li><li><strong>解释</strong>: 一个非主键列不能依赖于另一个非主键列。例如，在学生表中（学号为主键），如果有“所在院系”和“院系电话”，并且院系电话是依赖于所在院系的，那么就存在传递依赖（学号 -> 所在院系 -> 院系电话）。此时应将院系信息拆分到独立的“院系表”（院系名称、院系电话）。</li></ul></li></ul><p><strong>示例（根据PDF）：</strong></p><p>假设有一个`student`表包含以下字段：<code>id, 姓名, 学号, 年龄, 性别, 所在学校, 院校电话, 院校地址</code>。 [cite: 129]</p><p>如果以`学号`为主键，那么`所在学校`, `院校电话`, `院校地址`都与学号相关。但是，`院校电话`和`院校地址`实际上是与`所在学校`直接相关的，而不是直接与`学号`相关。这就形成了传递依赖：`学号 -> 所在学校 -> (院校电话, 院校地址)`。这不符合第三范式。</p><p><strong>优化设计</strong>：应该拆分为两张表：</p><ol><li><strong>`student`表</strong>: <code>学号 (主键), 姓名, 年龄, 性别, 学校ID (外键，关联学校表)</code></li><li><strong>`school`表</strong>: <code>学校ID (主键), 学校名, 学校地址, 学校电话</code></li></ol><p><strong>反范式设计 (Denormalization)</strong>:</p><p>虽然范式很重要，但在某些追求极致查询性能的场景下（特别是读多写少的OLAP系统），可能会适度地进行反范式设计，即故意引入一些数据冗余来减少查询时的JOIN操作，以空间换时间。但这需要谨慎评估，因为它会增加数据维护的复杂性和数据不一致的风险。</p><p>在实际设计中，通常会努力达到3NF，并根据性能需求进行权衡。</p>"
                },
                {
                    "id": "mysql-15",
                    "question": "15、常见面试SQL",
                    "difficulty": "★",
                    "answer": "<p><strong>例1: 用一条SQL语句查询出每门课都大于80分的学生姓名</strong></p><p>假设表结构: <code>student_scores (name VARCHAR, kecheng VARCHAR, fenshu INT)</code></p><p>数据示例:</p><pre>name  kecheng  fenshu\n张三  语文     81\n张三  数学     75\n李四  语文     76\n李四  数学     90\n王五  语文     81\n王五  数学     100\n王五  英语     90</pre><p><strong>答1 (使用NOT IN和子查询):</strong></p><div class=\"code-block\"><code>SELECT DISTINCT name \nFROM student_scores \nWHERE name NOT IN (SELECT DISTINCT name FROM student_scores WHERE fenshu &lt;= 80);</code></div><p><strong>答2 (使用GROUP BY和HAVING MIN):</strong></p><div class=\"code-block\"><code>SELECT name \nFROM student_scores \nGROUP BY name \nHAVING MIN(fenshu) > 80;</code></div><hr/><p><strong>例2: 删除除了自动编号不同,其他都相同的学生冗余信息</strong></p><p>假设表结构: <code>student_info (自动编号 INT AUTO_INCREMENT PRIMARY KEY, 学号 VARCHAR, 姓名 VARCHAR, 课程编号 VARCHAR, 课程名称 VARCHAR, 分数 INT)</code></p><p><strong>答:</strong></p><div class=\"code-block\"><code>DELETE FROM student_info\nWHERE 自动编号 NOT IN (\n    SELECT MIN(自动编号) \n    FROM (SELECT * FROM student_info) AS temp_table -- 需要一个临时表别名在某些MySQL版本中\n    GROUP BY 学号, 姓名, 课程编号, 课程名称, 分数\n);</code></div><p>或者使用自连接的方式（更通用）：</p><div class=\"code-block\"><code>DELETE t1 FROM student_info t1\nINNER JOIN student_info t2 \nWHERE \n    t1.自动编号 > t2.自动编号 AND\n    t1.学号 = t2.学号 AND\n    t1.姓名 = t2.姓名 AND\n    t1.课程编号 = t2.课程编号 AND\n    t1.课程名称 = t2.课程名称 AND\n    t1.分数 = t2.分数;</code></div><hr/><p><strong>例3: 一个叫team的表,里面只有一个字段name,一共有4条纪录(a,b,c,d),对应四个球队,用一条sql语句显示所有可能的比赛组合 (不重复，如a vs b 和 b vs a算一种)</strong></p><p><strong>答:</strong></p><div class=\"code-block\"><code>SELECT t1.name AS team1, t2.name AS team2\nFROM team t1, team t2\nWHERE t1.name &lt; t2.name;</code></div><hr/><p><strong>例4: 行转列查询</strong></p><p>原表 (aaa):</p><pre>year month amount\n1991 1     1.1\n1991 2     1.2\n1991 3     1.3\n1991 4     1.4\n1992 1     2.1\n1992 2     2.2\n1992 3     2.3\n1992 4     2.4</pre><p>查成结果:</p><pre>year m1  m2  m3  m4\n1991 1.1 1.2 1.3 1.4\n1992 2.1 2.2 2.3 2.4</pre><p><strong>答 (使用CASE WHEN和聚合函数，或子查询如PDF所示):</strong></p><p>使用CASE WHEN (更常见和推荐):</p><div class=\"code-block\"><code>SELECT \n    year,\n    MAX(CASE WHEN month = 1 THEN amount ELSE NULL END) AS m1,\n    MAX(CASE WHEN month = 2 THEN amount ELSE NULL END) AS m2,\n    MAX(CASE WHEN month = 3 THEN amount ELSE NULL END) AS m3,\n    MAX(CASE WHEN month = 4 THEN amount ELSE NULL END) AS m4\nFROM aaa\nGROUP BY year;</code></div><p>PDF中的子查询方式 (性能可能不如CASE WHEN):</p><div class=\"code-block\"><code>SELECT \n    a.year,\n    (SELECT amount FROM aaa m WHERE month = 1 AND m.year = a.year) AS m1,\n    (SELECT amount FROM aaa m WHERE month = 2 AND m.year = a.year) AS m2,\n    (SELECT amount FROM aaa m WHERE month = 3 AND m.year = a.year) AS m3,\n    (SELECT amount FROM aaa m WHERE month = 4 AND m.year = a.year) AS m4\nFROM aaa a\nGROUP BY a.year;</code></div><hr/><p><strong>例5: 复制表结构</strong></p><p>源表名: a, 新表名: b</p><p><strong>答:</strong></p><p>MySQL:</p><div class=\"code-block\"><code>CREATE TABLE b LIKE a; -- 只复制结构，不包含数据</code></div><p>如果也要复制数据：</p><div class=\"code-block\"><code>CREATE TABLE b AS SELECT * FROM a;</code></div><p>PDF中的SQL Server / Oracle 方式 (用于理解不同数据库语法):</p><p>SQL Server (只复制结构): <code>SELECT * INTO b FROM a WHERE 1&lt;&gt;1;</code> (<code>WHERE 1=1</code> 会拷贝数据)</p><p>Oracle (只复制结构): <code>CREATE TABLE b AS SELECT * FROM a WHERE 1=2;</code> (<code>WHERE 1=1</code> 或无WHERE会拷贝数据)</p><hr/><p><strong>例6: 根据分数判断及格与否</strong></p><p>原表 (course):</p><pre>courseid coursename score\n1        java       70\n2        oracle     90\n3        xml        40\n4        jsp        30\n5        servlet    80</pre><p>查询结果显式 mark (及格分数为60):</p><pre>courseid coursename score mark\n1        java       70    pass\n2        oracle     90    pass\n3        xml        40    fail\n4        jsp        30    fail\n5        servlet    80    pass</pre><p><strong>答:</strong></p><div class=\"code-block\"><code>SELECT \n    courseid, \n    coursename, \n    score, \n    IF(score >= 60, 'pass', 'fail') AS mark \nFROM course;</code></div><p>或者使用CASE WHEN (更标准):</p><div class=\"code-block\"><code>SELECT \n    courseid, \n    coursename, \n    score, \n    CASE \n        WHEN score >= 60 THEN 'pass' \n        ELSE 'fail' \n    END AS mark \nFROM course;</code></div><hr/><p><strong>例7: 给出所有购入商品为两种或两种以上的购物人记录</strong></p><p>表名: 购物信息 (columns: 购物人, 商品名称, 数量)</p><p><strong>答:</strong></p><div class=\"code-block\"><code>SELECT * \nFROM 购物信息\nWHERE 购物人 IN (\n    SELECT 购物人 \n    FROM 购物信息 \n    GROUP BY 购物人 \n    HAVING COUNT(DISTINCT 商品名称) >= 2 -- 假设是商品种类数\n);</code></div><p>如果题目是指购买记录数（即购买次数或不同种类的商品行数，即使同种商品多次购买也算），则是<code>COUNT(*) >= 2</code>。</p><hr/><p><strong>例8: 行转列统计（日期，结果win/lose 统计）</strong></p><p>原表 (info):</p><pre>date       result\n2005-05-09 win\n2005-05-09 lose\n2005-05-09 lose\n2005-05-09 lose\n2005-05-10 win\n2005-05-10 lose\n2005-05-10 lose</pre><p>生成结果:</p><pre>date       win lose\n2005-05-09 1   3  -- (PDF中为2,2 应为1,3根据数据)\n2005-05-10 1   2</pre><p><strong>答1 (使用CASE WHEN):</strong></p><div class=\"code-block\"><code>SELECT \n    date,\n    SUM(CASE WHEN result = 'win' THEN 1 ELSE 0 END) AS win,\n    SUM(CASE WHEN result = 'lose' THEN 1 ELSE 0 END) AS lose\nFROM info\nGROUP BY date;</code></div><p><strong>答2 (使用JOIN - PDF中的方法，但通常CASE WHEN更优):</strong></p><div class=\"code-block\"><code>SELECT \n    a.date,\n    a.win_count AS win,\n    b.lose_count AS lose\nFROM\n    (SELECT date, COUNT(result) AS win_count FROM info WHERE result = 'win' GROUP BY date) AS a\nJOIN\n    (SELECT date, COUNT(result) AS lose_count FROM info WHERE result = 'lose' GROUP BY date) AS b\nON a.date = b.date;</code></div><p>注意：PDF中例8数据结果win/lose统计与示例数据不完全匹配，上述SQL是根据逻辑生成的。</p><hr/><p><strong>例9: MySQL创建了一个联合索引(a,b,c)，以下哪些查询会生效？</strong></p><p>索引: <code>INDEX যৌগ_idx (a, b, c)</code></p><ol><li><code>WHERE a=1 AND b=1 AND c=1</code></li><li><code>WHERE a=1 AND c=1</code></li><li><code>WHERE b=1 AND c=1</code></li><li><code>WHERE b=1 AND a=1 AND c=1</code> (等价于1)</li></ol><p><strong>答 (索引生效的，基于最左前缀原则):</strong></p><ul><li><strong>1. <code>WHERE a=1 AND b=1 AND c=1</code></strong>: 生效 (a,b,c都用到)</li><li><strong>2. <code>WHERE a=1 AND c=1</code></strong>: 部分生效 (只有a用到索引，c无法直接利用此组合索引进行快速定位，但MySQL可能会做index condition pushdown等优化)</li><li><strong>3. <code>WHERE b=1 AND c=1</code></strong>: 不生效 (没有从最左边的a开始)</li><li><strong>4. <code>WHERE b=1 AND a=1 AND c=1</code></strong>: 生效 (MySQL查询优化器会自动调整AND条件的顺序，等价于 <code>WHERE a=1 AND b=1 AND c=1</code>)</li></ul><p>所以PDF答案 (1,2,4) 中，第2个说生效其实是“部分生效”或“a列生效”。严格来说，要完整利用组合索引的(a,b,c)的所有部分，需要从左开始连续匹配。</p>"
                }
            ]
        },
        {
            "chapterTitle": "第五章-Redis",
            "questions": [
                {
                    "id": "redis-1",
                    "question": "1、介绍下Redis Redis有哪些数据类型",
                    "difficulty": "★",
                    "answer": "<p>Redis (Remote Dictionary Server，远程字典服务) 本质上是一个Key-Value类型的<strong>内存数据库</strong>。整个数据库的数据通常都加载在内存中进行操作，并可以通过异步操作将数据持久化到硬盘上进行保存。由于是纯内存操作，Redis的性能非常出色，每秒可以处理超过10万次读写操作，是已知性能最快的Key-Value数据库之一。</p><p>Redis的魅力不仅在于高性能，还在于它支持保存多种数据结构。单个value的最大限制是1GB (不像Memcached通常只能保存1MB的数据)。这使得Redis可以用来实现很多有用的功能，例如：</p><ul><li>使用List类型实现FIFO双向链表，作为一个轻量级的高性能消息队列服务。</li><li>使用Set类型实现高性能的标签系统。</li><li>可以对存入的Key-Value设置过期时间（expire），因此也可以被当作一个功能加强版的Memcached来使用。</li></ul><p>Redis的主要缺点是数据库容量受到物理内存的限制，不适合用作海量数据的高性能读写。因此，Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</p><p><strong>常用基本数据类型如下：</strong></p><table><thead><tr><th>数据类型</th><th>描述</th><th>特性</th></tr></thead><tbody><tr><td>string (字符串)</td><td>一个字符串类型最大存储容量为512MB。</td><td>可以是字符串、整数或浮点数；可以进行incr/decr等原子操作。</td></tr><tr><td>list (列表)</td><td>字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。</td><td>底层实现通常是双向链表或ziplist。可以作为消息队列使用。</td></tr><tr><td>set (集合)</td><td>String类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。</td><td>不可以重复的成员。支持交集、并集、差集等操作。</td></tr><tr><td>hash (哈希/散列)</td><td>一个键值(key-value)对集合。是一个string类型的field和value的映射表，hash特别适合用于存储对象。</td><td>类似于Map&lt;String, String&gt;。适合存储对象属性。</td></tr><tr><td>zset (sorted set / 有序集合)</td><td>和set一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</td><td>带分数的set，成员唯一但分数可以重复。可用于排行榜等场景。</td></tr></tbody></table><p>此外，Redis还有如Bitmaps（位图）、HyperLogLogs（基数统计）、Streams（流式数据）、Geospatial indexes（地理空间索引）等高级数据类型。</p>"
                },
                {
                    "id": "redis-2",
                    "question": "2、Redis提供了哪几种持久化方式",
                    "difficulty": "★",
                    "answer": "<p>Redis提供了以下几种主要的持久化方式，用于在服务器重启后恢复数据：</p><ol><li><strong>RDB (Redis DataBase) 持久化</strong>:<ul><li><strong>原理</strong>: RDB持久化方式能够在指定的时间间隔内对你的数据进行快照存储。Redis会单独fork一个子进程来进行持久化，先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程不进行任何IO操作，确保了极高的性能。</li><li><strong>优点</strong>: 适合进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感的情况下，RDB方式通常比AOF方式更高效。恢复速度快。</li><li><strong>缺点</strong>: 如果在两次RDB快照之间Redis发生故障，那么这部分数据会丢失。Fork子进程时，如果数据集较大，可能会造成服务器短暂的卡顿。</li><li><strong>保存策略 (通过<code>save</code>配置)</strong>: 例如：<ul><li><code>save 900 1</code> (900秒内如果至少有1个key的值变化，则保存)</li><li><code>save 300 10</code> (300秒内如果至少有10个key的值变化，则保存)</li><li><code>save 60 10000</code> (60秒内如果至少有10000个key的值变化，则保存)</li></ul></li></ul></li><li><strong>AOF (Append Only File) 持久化</strong>:<ul><li><strong>原理</strong>: AOF持久化方式记录每次对服务器执行的写操作命令（以Redis协议追加保存到文件末尾）。当服务器重启的时候会重新执行这些命令来恢复原始的数据。Redis还能对AOF文件进行后台重写（rewrite），使得AOF文件的体积不至于过大。</li><li><strong>优点</strong>: 数据完整性通常比RDB好。根据配置的同步策略，可以做到丢失很少（甚至不丢失）数据。AOF文件是可读的日志文本（经过重写后可能包含二进制内容）。</li><li><strong>缺点</strong>: AOF文件通常比RDB文件大。恢复备份速度通常比RDB慢。根据同步策略，可能会对性能有一定影响。</li><li><strong>保存策略 (通过<code>appendfsync</code>配置)</strong>:<ul><li><code>appendfsync always</code>: 每次产生一条新的修改数据的命令都执行保存操作；效率低，但是最安全。</li><li><code>appendfsync everysec</code> (默认): 每秒执行一次保存操作。如果在未保存当前秒内操作时发生了断电，仍然可能导致一部分数据丢失（最多1秒的数据）。在速度和安全性之间取得了较好的平衡。</li><li><code>appendfsync no</code>: 从不主动保存，将数据同步操作交给操作系统来处理。更快，也更不安全。</li></ul></li></ul></li><li><strong>不使用持久化</strong>:<ul><li>如果你只希望你的数据在服务器运行的时候存在（例如纯粹用作缓存），你也可以不使用任何持久化方式。</li></ul></li><li><strong>混合持久化 (Redis 4.0+ 引入)</strong>:<ul><li>在AOF重写时，新的AOF文件前半部分是RDB格式的全量数据，后半部分是重写过程中产生的增量写命令。这种方式结合了RDB的快速恢复和AOF的数据完整性优点。</li></ul></li></ol><p><strong>选择策略</strong>:</p><ul><li>官方通常推荐同时开启两种持久化方式。在这种情况下，当Redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</li><li>如果对数据不敏感，可以选单独用RDB。</li><li>不建议单独用AOF（早期版本可能存在一些bug导致恢复问题，但现在已大为改善）。</li><li>如果只是做纯内存缓存，可以都不用。</li></ul>"
                },
                {
                    "id": "redis-3",
                    "question": "3.Redis为什么快",
                    "difficulty": "★",
                    "answer": "<p>Redis之所以非常快，主要归功于以下几个核心因素：</p><ol><li><strong>完全基于内存操作</strong>:<ul><li>绝大部分请求是纯粹的内存操作，数据直接存在内存中。内存的读写速度远快于磁盘。</li><li>其内部数据结构（如哈希表）在内存中查找和操作的时间复杂度很多都是O(1)或O(log N)。</li></ul></li><li><strong>优化的数据结构</strong>:<ul><li>Redis中的数据结构是专门为高性能而设计的。例如，字符串（SDS）、哈希表（dict）、跳跃表（skiplist for zset）、压缩列表（ziplist）、整数集合（intset）等，在不同场景下都有高效的表现。</li></ul></li><li><strong>采用单线程模型 (主要指网络请求处理部分)</strong>:<ul><li>避免了不必要的上下文切换和多线程竞争条件。这消除了多线程中常见的锁竞争、线程同步开销。</li><li>不用去考虑各种锁的问题（如加锁、释放锁、死锁检测），简化了实现并减少了性能消耗。</li></ul></li><li><strong>I/O多路复用模型 (Multiplexing)</strong>:<ul><li>Redis使用I/O多路复用技术（如epoll、kqueue、select，在Linux上主要是epoll）来处理并发连接，实现了非阻塞I/O。</li><li>这意味着单个线程可以高效地处理多个客户端连接的请求，而不会因为某个连接的I/O阻塞而影响其他连接。操作系统内核会通知Redis哪些socket已准备好进行读写操作。</li></ul></li><li><strong>自定义的底层机制 (对系统调用的优化)</strong>:<ul><li>文档中提到“Redis直接自己构建了VM机制,因为一般的系统调用系统函数的话,会浪费一定的时间去移动和请求”。这可能指的是Redis对内存管理、网络通信等底层细节有自己的优化，以减少标准库或系统调用的开销，更直接地与操作系统交互。</li></ul></li></ol><p>需要注意的是，虽然Redis的网络请求处理是单线程的，但它的一些后台操作（如RDB持久化、AOF重写、Lazy Freeing）会通过子进程或后台线程来执行，以避免阻塞主线程。</p>"
                },
                {
                    "id": "redis-4",
                    "question": "4、Redis为什么是单线程的",
                    "difficulty": "★",
                    "answer": "<p>Redis采用单线程模型主要是基于以下考虑和优势，尤其针对其核心的网络请求处理部分：</p><ol><li><strong>CPU不是主要瓶颈</strong>:<ul><li>Redis官方FAQ指出，对于一个基于内存的存储系统来说，CPU通常不会是性能瓶颈。Redis的瓶颈最有可能出现在机器的内存大小或者网络带宽上。</li><li>既然单线程已经能够充分利用CPU（因为大部分操作是内存密集型，非常快），引入多线程带来的复杂性可能超过其收益。</li></ul></li><li><strong>避免多线程的开销和复杂性</strong>:<ul><li><strong>上下文切换</strong>: 多线程环境下，线程间的上下文切换会带来性能开销。单线程避免了这种开销。</li><li><strong>锁竞争</strong>: 多线程访问共享资源时，需要使用锁机制来保证数据一致性，这会引入锁的获取、释放等开销，并可能导致死锁等问题。单线程自然地避免了这些问题。</li><li><strong>实现简单</strong>: 单线程模型使得Redis的内部逻辑和数据结构实现更为简单，易于维护和调试。</li></ul></li><li><strong>高效的I/O多路复用</strong>:<ul><li>Redis使用I/O多路复用技术（如epoll）来处理并发客户端连接。这使得单个线程可以高效地管理大量的并发连接，而不会被某个慢速连接阻塞。</li></ul></li><li><strong>原子操作</strong>:<ul><li>单线程执行命令天然保证了操作的原子性（对于单个命令而言），不需要额外的同步机制。</li></ul></li></ol><p>Redis利用队列技术将并发的客户端访问请求变为串行化的命令执行序列，由一个线程依次处理。虽然网络I/O请求处理是单线程的，但值得注意的是，Redis并非完全的“单线程”。例如：</p><ul><li>RDB持久化和AOF重写通常由父进程fork出的子进程执行。</li><li>Redis 4.0引入了“Lazy Freeing”机制，可以用后台线程异步释放大的键值对占用的内存。</li><li>Redis 6.0引入了多线程I/O（Threaded I/O），主要用于处理网络数据的读写和协议解析，但命令的实际执行仍然是单线程的，以保证数据操作的原子性和一致性。</li></ul><p>因此，说Redis是单线程的，主要是指其核心的命令执行循环是单线程的。</p>"
                },
                {
                    "id": "redis-5",
                    "question": "5、Redis服务器的的内存是多大",
                    "difficulty": "★",
                    "answer": "<p>Redis服务器实际可使用的内存大小主要由以下因素决定：</p><ol><li><strong>配置文件中的<code>maxmemory</code>参数</strong>:<ul><li>这是Redis配置文件(<code>redis.conf</code>)中用于限制Redis实例最大使用内存的参数。</li><li><strong>单位</strong>: 可以是字节（如<code>1000000000</code>）、KB（如<code>1000mb</code>）、MB（如<code>1gb</code>）、GB。</li><li><strong>不设置或设置为0</strong>: 如果不设置该参数或者将其设置为0：<ul><li>在32位系统下，Redis默认的最大内存限制通常是3GB左右（因为32位进程的寻址空间限制）。</li><li>在64位系统下，理论上不受寻址空间限制，Redis会尽可能使用所有可用的物理内存。</li></ul></li></ul></li><li><strong>物理内存大小</strong>:<ul><li>即使<code>maxmemory</code>设置得很大或不设置，Redis实际能使用的内存也不会超过服务器的物理内存。操作系统和其他进程也需要内存。</li></ul></li><li><strong>操作系统限制</strong>:<ul><li>操作系统本身可能对单个进程的内存使用有所限制。</li></ul></li></ol><p><strong>设置建议</strong>:</p><ul><li>一般推荐将Redis的<code>maxmemory</code>设置为服务器最大物理内存的<strong>四分之三 (75%)</strong> 左右。这为操作系统和其他关键进程留出足够的内存，避免因内存不足导致Swap或OOM Killer介入。</li></ul><p><strong>查看和设置<code>maxmemory</code></strong>:</p><ul><li><strong>查看当前设置</strong>: 在redis-cli中执行命令 <code>CONFIG GET maxmemory</code>。</li><li><strong>运行时动态设置 (服务器重启后失效)</strong>: 在redis-cli中执行命令 <code>CONFIG SET maxmemory &lt;内存大小&gt;</code> (例如 <code>CONFIG SET maxmemory 2gb</code>)。</li><li><strong>永久设置</strong>: 修改<code>redis.conf</code>文件中的<code>maxmemory</code>参数，然后重启Redis服务。</li></ul><p>当达到<code>maxmemory</code>限制时，Redis会根据配置的内存淘汰策略 (<code>maxmemory-policy</code>) 来尝试回收空间，否则写操作可能会失败。</p>"
                },
                {
                    "id": "redis-6",
                    "question": "6、为什么Redis的操作是原子性的,怎么保证原子性的",
                    "difficulty": "★",
                    "answer": "<p><strong>Redis单个命令的原子性</strong>:</p><p>对于Redis而言，单个命令的操作是原子性的。原子性指的是：一个操作不可再分，要么完全执行，要么完全不执行，不会出现执行到一半的中间状态。</p><p>Redis的单个命令之所以能保证原子性，主要是因为它采用了<strong>单线程模型</strong>来处理客户端的命令请求。在一个时间点，Redis服务器只会执行一个客户端发送过来的命令。命令会被放入一个队列中，然后由Redis的事件循环机制逐个取出并执行。由于命令是串行执行的，所以每个命令在执行过程中不会被其他命令打断，从而天然地保证了单个命令的原子性。</p><p><strong>多个命令的原子性 (事务和Lua脚本)</strong>:</p><p>虽然单个命令是原子的，但如果需要保证多个命令作为一个整体的原子性（例如，先<code>GET</code>一个值，然后对其进行计算，再<code>SET</code>回去），仅仅连续发送这些命令并不能保证它们在并发环境下的原子性，因为其他客户端的命令可能在这多个命令之间插入执行。</p><p>为了解决多个命令的原子性问题，Redis提供了以下机制：</p><ol><li><strong>Redis事务 (MULTI/EXEC)</strong>:<ul><li>Redis的事务可以将一组命令打包在一起，然后一次性、按顺序地执行。在<code>EXEC</code>命令被调用之前，队列中的所有命令都不会被实际执行。</li><li>当一个事务执行时，Redis可以保证事务中的所有命令都会被执行，并且在执行期间不会插入其他客户端的命令。</li><li>然而，Redis事务与传统关系型数据库的事务不同，它<strong>不支持回滚</strong>。如果事务队列中的某个命令执行出错（例如语法错误），其他命令通常仍会继续执行（除非是命令入队前的语法错误导致整个事务无法执行）。</li></ul></li><li><strong>Lua脚本</strong>:<ul><li>Redis支持执行Lua脚本。可以将多个Redis命令封装在一个Lua脚本中，然后让Redis原子地执行这个脚本。</li><li>Redis保证Lua脚本的执行是原子的，即脚本在执行过程中不会被其他命令或脚本中断。这使得Lua脚本成为实现复杂原子操作的强大工具，例如实现自定义的原子CAS（Compare-And-Swap）操作。</li></ul></li></ol><p><strong>总结</strong>: Redis的单个命令由于其单线程执行模型而具有原子性。对于需要原子执行的多个命令，应使用Redis事务或Lua脚本来实现。</p>"
                },
                {
                    "id": "redis-7",
                    "question": "7、Redis有事务吗",
                    "difficulty": "★",
                    "answer": "<p>是的，Redis支持事务。但Redis的事务与传统关系型数据库（RDBMS）中的事务有所不同。</p><p><strong>Redis事务的特点：</strong></p><ol><li><strong>命令打包执行</strong>: Redis事务允许将一组命令打包在一起，然后按顺序一次性执行。</li><li><strong>原子性 (针对命令序列)</strong>: 它能保证事务中的所有命令都会被执行，并且在执行期间不会被其他客户端的命令打断。即这组命令作为一个整体被序列化执行。</li><li><strong>无隔离级别概念</strong>: 因为Redis是单线程处理命令，事务执行期间不会有其他命令插入，所以不存在传统数据库中复杂的隔离级别问题。</li><li><strong>不支持回滚 (No Rollback)</strong>: 这是Redis事务与RDBMS事务的一个重要区别。<ul><li>如果在事务的命令队列中，某个命令出现语法错误（在<code>EXEC</code>执行前就能检测到的错误），那么整个事务都不会被执行，所有命令都会失败。</li><li>但如果是在<code>EXEC</code>执行后，某个命令在执行期间发生错误（例如对一个字符串类型的值执行列表操作），那么这个命令会执行失败，但事务中的其他命令仍会继续执行。Redis不会因为某个命令失败而回滚已经执行成功的命令。</li></ul></li><li><strong>乐观锁 (CAS - Check-And-Set)</strong>: Redis事务可以配合<code>WATCH</code>命令来实现乐观锁。<code>WATCH</code>命令可以监控一个或多个键，如果在事务执行（<code>EXEC</code>）之前，任何被<code>WATCH</code>的键被其他客户端修改了，那么整个事务将被取消执行（<code>EXEC</code>返回nil）。这提供了一种“检查并设置”的机制。</li></ol><p><strong>如何使用Redis事务：</strong></p><p>Redis事务通过以下命令实现：</p><ul><li><strong><code>MULTI</code></strong>: 标记一个事务块的开始。后续的命令并不会立即执行，而是被放入一个队列中。服务器返回<code>OK</code>。</li><li><strong>(事务命令)</strong>: 在<code>MULTI</code>之后输入的命令，服务器会返回<code>QUEUED</code>，表示命令已入队。</li><li><strong><code>EXEC</code></strong>: 执行事务队列中的所有命令。服务器会按顺序返回每个命令的执行结果。</li><li><strong><code>DISCARD</code></strong>: 取消事务，清空事务队列，并退出事务状态。</li><li><strong><code>WATCH key [key ...]</code></strong>: 在<code>MULTI</code>执行之前监视一个或多个键。如果在<code>EXEC</code>执行时，被监视的键发生变化，则事务不执行。</li><li><strong><code>UNWATCH</code></strong>: 取消<code>WATCH</code>命令对所有键的监视。</li></ul><p><strong>示例：</strong></p><div class=\"code-block\"><code>MULTI\nSET mykey \"hello\"\nGET mykey\nINCR counter\nEXEC</code></div><p><em>[示意图: Redis事务命令执行流程 - 如相关文档中常见流程所示]</em></p><p>总结来说，Redis事务提供了一种将多个命令打包原子执行的方式，但它更侧重于命令执行的序列性和不受干扰，而非传统数据库事务的ACID特性中的回滚能力。</p>"
                },
                {
                    "id": "redis-8",
                    "question": "8、Redis数据和MySQL数据库的一致性如何实现",
                    "difficulty": "★★",
                    "answer": "<p>保证缓存（如Redis）与数据库（如MySQL）之间的数据一致性是分布式系统中一个常见的挑战。由于Redis通常作为数据库的缓存层，数据更新时可能导致两者不一致。以下是一些常见策略：</p><p><strong>核心问题：更新数据时，是先操作数据库还是先操作缓存？以及如何处理并发读写？</strong></p><p><strong>1. 延时双删策略 (Cache-Aside Pattern 变种)</strong></p><p>这是一种比较常用的策略，旨在减少脏数据进入缓存的概率。</p><ul><li><strong>步骤</strong>:<ol><li>先删除缓存 (<code>redis.del(key)</code>)。</li><li>再写数据库。</li><li>休眠一段时间 (例如500毫秒，具体时间需根据业务读写链路耗时和主从同步延迟评估)。</li><li>再次删除缓存 (<code>redis.del(key)</code>)。</li></ol></li><li><strong>目的</strong>: 第2次删除是为了防止在步骤1和步骤2之间，有其他读请求将旧数据（在数据库更新前）读入并写回了缓存。休眠是为了等待这些可能的并发读操作（及其造成的缓存写入）完成。</li><li><strong>休眠时间确定</strong>: 需要评估项目的读数据业务逻辑的耗时，并考虑数据库主从同步的延迟。休眠时间应大于（读业务逻辑耗时 + 主从同步延迟）。</li><li><strong>缺点</strong>: 增加了写请求的耗时。第二次删除仍有失败的可能。</li></ul><p><strong>2. 设置缓存的过期时间</strong></p><ul><li><strong>原理</strong>: 为缓存中的数据设置一个合理的过期时间。即使在某段时间内数据不一致，一旦缓存过期，后续的读请求会重新从数据库加载最新数据并回填缓存，从而达到最终一致性。</li><li><strong>优点</strong>: 实现简单，是保证最终一致性的托底方案。</li><li><strong>缺点</strong>: 在缓存过期前，数据可能不一致。过期时间的设置需要权衡一致性要求和缓存命中率。</li></ul><p><strong>3. 更新数据库后删除缓存，并确保删除成功 (Retry / Asynchronous Deletion)</strong></p><p>这是目前推荐的、更可靠的策略之一（相比先删缓存）。</p><ul><li><strong>基本流程</strong>:<ol><li>更新数据库。</li><li>删除缓存。</li></ol></li><li><strong>问题</strong>: 如果第2步删除缓存失败（例如Redis故障、网络问题），会导致数据库是新的，缓存是旧的，产生数据不一致。</li><li><strong>解决方案 - 保障重试删除</strong>:<ul><li><strong>方案一：消息队列异步删除/重试</strong><ol><li>更新数据库数据。</li><li>如果删除缓存失败，将需要删除的key发送到消息队列（如RabbitMQ, Kafka）。</li><li>由一个独立的消费者服务订阅该消息队列，获取需要删除的key，并重试删除缓存操作，直到成功。</li></ol>缺点：对业务代码有一定侵入性，需要引入消息队列。</li><li><strong>方案二：订阅数据库变更日志 (如Binlog) 异步删除</strong><ol><li>应用程序更新数据库数据。</li><li>数据库将操作信息写入binlog日志。</li><li>启动一个独立的订阅程序（如Canal, Maxwell's Daemon）订阅数据库的binlog，解析出变更的数据和对应的key。</li><li>该订阅程序（或其下游服务）尝试删除缓存。如果删除失败，可以将删除任务放入消息队列进行重试。</li></ol>优点：业务代码与缓存删除逻辑解耦。缺点：架构更复杂，需要额外部署和维护订阅组件。</li></ul></li></ul><p><strong>4. 先更新缓存，再更新数据库？(不推荐)</strong></p><ul><li>如果先更新缓存成功，但更新数据库失败，会导致缓存是新的，数据库是旧的，数据不一致。且后续没有好的时机去回滚缓存。</li></ul><p><strong>5. Read-Through / Write-Through / Write-Behind Caching (缓存模式)</strong></p><ul><li>这些是更系统化的缓存策略，通常由缓存框架或服务提供。<ul><li><strong>Read-Through</strong>: 应用向缓存读取数据，缓存没有则由缓存组件负责从数据库加载。</li><li><strong>Write-Through</strong>: 应用写数据到缓存，由缓存组件负责同步写入数据库。</li><li><strong>Write-Behind (Write-Back)</strong>: 应用写数据到缓存即返回，缓存组件异步批量写入数据库。</li></ul>这些模式能更好地封装一致性逻辑，但实现也更复杂。</li></ul><p><strong>总结</strong>: 没有完美的“一刀切”方案。通常推荐“<strong>更新数据库后删除缓存，并配合重试机制或异步通知机制来确保缓存最终被删除</strong>”，同时为缓存设置合理的过期时间作为兜底策略。具体选择哪种策略，需要根据业务场景对一致性、性能、复杂度的要求进行权衡。</p>"
                },
                {
                    "id": "redis-9",
                    "question": "9、缓存击穿,缓存穿透,缓存雪崩的原因和解决方案",
                    "difficulty": "★",
                    "answer": "<p>缓存击穿、缓存穿透和缓存雪崩是使用缓存时常见的三个问题，它们都可能导致大量请求直接打到数据库，造成数据库压力过大甚至宕机。</p><ol><li><strong>缓存穿透 (Cache Penetration)</strong>:<ul><li><strong>原因</strong>: 指查询一个<strong>一定不存在的数据</strong>。由于缓存中没有（缓存无法命中），请求会直接去查询数据库，但数据库中也无此记录。如果出于容错考虑，没有将这次“空结果”查询写入缓存，那么每次对这个不存在的数据的请求都会穿透到数据库层面，失去了缓存的意义。如果有恶意用户利用大量不存在的key频繁攻击应用，就可能导致数据库压力剧增。</li><li><strong>解决方案</strong>:<ul><li><strong>缓存空对象/空结果</strong>: 当数据库查询结果为空时，也将这个空结果缓存起来（例如缓存一个特殊的空值对象或标记），但设置一个较短的过期时间（如几分钟），以防止缓存过多无用数据。</li><li><strong>布隆过滤器 (Bloom Filter)</strong>: 在访问缓存和数据库之前，使用布隆过滤器判断请求的key是否存在。布隆过滤器可以快速判断一个元素“一定不存在”或者“可能存在”。对于它判断为“一定不存在”的key，直接返回空，不再查询缓存和数据库。这样可以拦截掉大部分对不存在数据的请求。 (Redisson等框架内置了布隆过滤器实现)</li><li><strong>接口层参数校验</strong>: 对不合理或格式错误的请求参数进行校验，直接拒绝非法请求。</li></ul></li></ul></li><li><strong>缓存雪崩 (Cache Avalanche)</strong>:<ul><li><strong>原因</strong>: 指在某个时间点，缓存中<strong>大量的key同时集中过期失效</strong>，或者Redis服务自身发生故障宕机。这导致在短时间内，大量的并发请求无法命中缓存，全部直接涌向数据库，造成数据库瞬时压力过重，可能导致雪崩效应。</li><li><strong>解决方案</strong>:<ul><li><strong>设置不同的过期时间/随机化过期时间</strong>: 在原有的失效时间基础上增加一个随机值（例如1-5分钟随机），使得每个key的过期时间点分散开，避免集体失效。</li><li><strong>多级缓存</strong>: 使用如Nginx本地缓存 + Redis分布式缓存 + Ehcache进程内缓存等多级缓存策略。</li><li><strong>高可用缓存集群</strong>: 搭建Redis高可用集群（如Sentinel或Cluster模式），确保缓存服务不易宕机。</li><li><strong>限流与降级</strong>: 在缓存失效或Redis故障时，通过限流组件（如Sentinel, Hystrix）对数据库的访问进行限流，对于非核心业务可以进行降级处理，保证核心业务可用。</li><li><strong>数据预热</strong>: 系统启动或低峰期，提前将热点数据加载到缓存中，并设置合理的过期时间。</li></ul></li></ul></li><li><strong>缓存击穿 (Cache Breakdown / Hotspot Invalid)</strong>:<ul><li><strong>原因</strong>: 指对于某个<strong>热点key</strong>（访问非常频繁的数据），在它缓存过期的瞬间，有大量的并发请求同时涌入。这些请求都无法命中缓存，于是全部去查询数据库并回设缓存，导致数据库瞬时压力增大。它与缓存雪崩的区别在于，击穿是针对单个热点key，而雪崩是大量key。</li><li><strong>解决方案</strong>:<ul><li><strong>互斥锁/分布式锁</strong>: 当缓存失效时，只允许一个线程去查询数据库并重建缓存，其他线程等待结果。获取到锁的线程负责加载数据到缓存，然后释放锁。其他线程在锁释放后直接从缓存获取数据。可以使用Redis的<code>SETNX</code>、Redlock，或Zookeeper的临时顺序节点等实现分布式锁。</li><li><strong>热点数据永不过期 (逻辑过期)</strong>: 对于某些非常核心的热点数据，可以不设置物理过期时间，或者设置一个非常长的过期时间。然后通过一个后台任务定时更新缓存中的数据，或者在获取数据时判断其逻辑过期时间，如果逻辑过期则异步更新。</li><li><strong>二级缓存/本地缓存</strong>: 配合使用进程内缓存（如Caffeine, Guava Cache）作为Redis的前置缓存，对于热点key，即使Redis的缓存失效，本地缓存可能仍然存在。</li></ul></li></ul></ol>"
                },
                {
                    "id": "redis-10",
                    "question": "10、哨兵模式是什么样的",
                    "difficulty": "★★",
                    "answer": "<p>Redis Sentinel（哨兵）是Redis官方推荐的高可用性（High Availability）解决方案。它是一个分布式系统，可以监控多个Redis主从服务器，并在主服务器（Master）下线时自动将一个从服务器（Slave）提升为新的主服务器，然后通知其他从服务器去复制新的主服务器，同时也会通知应用程序客户端新的主服务器地址。</p><p><strong>哨兵模式的核心功能：</strong></p><ul><li><strong>监控 (Monitoring)</strong>: Sentinel会持续监控主服务器、从服务器以及其他Sentinel实例的健康状态。</li><li><strong>通知 (Notification)</strong>: 当被监控的Redis实例出现问题时，Sentinel可以通过API向管理员或者其他应用程序发送通知。</li><li><strong>自动故障转移 (Automatic Failover)</strong>: 当主服务器发生故障无法正常工作时，Sentinel会自动启动故障转移过程。它会从主服务器的从服务器中选举出一个新的主服务器，并让其余的从服务器开始复制新的主服务器。</li><li><strong>配置提供者 (Configuration Provider)</strong>: 客户端在连接Redis集群时，可以先连接Sentinel，由Sentinel告知当前主服务器的地址。当发生故障转移后，Sentinel会提供新的主服务器地址。</li></ul><p><strong>下线判断：</strong></p><ul><li><strong>主观下线 (Subjectively Down - SDOWN)</strong>: 指的是单个Sentinel实例对某个Redis服务器做出的下线判断。当一个Sentinel实例在配置的<code>down-after-milliseconds</code>时间内没有收到目标服务器的有效 PING 回复时，就会将其标记为SDOWN。</li><li><strong>客观下线 (Objectively Down - ODOWN)</strong>: 指的是多个Sentinel实例（达到预设的 quorum 数量）都认为主服务器进入了SDOWN状态，并通过<code>SENTINEL is-master-down-by-addr</code>命令互相交流之后，共同得出的主服务器下线判断。只有主服务器才会有ODOWN状态。一旦主服务器被判断为ODOWN，故障转移过程就会开始。</li></ul><p><strong>工作原理简述：</strong></p><ol><li><strong>互相监控</strong>: 每个Sentinel实例不仅监控Redis主从服务器，还会监控其他Sentinel实例。它们之间通过发布订阅和命令进行通信。</li><li><strong>PING命令</strong>: 每个Sentinel以每秒钟一次的频率向它所知的Master、Slave以及其他Sentinel实例发送一个<code>PING</code>命令。 [cite: 145]</li><li><strong>主观下线判断</strong>: 如果一个实例距离最后一次有效回复PING命令的时间超过<code>down-after-milliseconds</code>（可配置）选项所指定的值，则这个实例会被该Sentinel标记为主观下线（SDOWN）。 [cite: 145]</li><li><strong>客观下线判断</strong>: 如果一个Master被标记为主观下线，则正在监视这个Master的所有Sentinel要以每秒一次的频率确认Master的确进入了主观下线状态。 [cite: 145] 当有足够数量的Sentinel（大于等于配置文件中为该Master设置的<code>quorum</code>值）在指定的时间范围内确认Master的确进入了主观下线状态，则Master会被标记为客观下线（ODOWN）。 [cite: 145]</li><li><strong>领导者选举 (Leader Election)</strong>: 一旦Master被标记为ODOWN，Sentinel集群会进行一次领导者选举（基于Raft算法的变种），选出一个Sentinel实例来负责执行故障转移。</li><li><strong>故障转移 (Failover)</strong>:<ul><li>被选为领导者的Sentinel会从已下线Master的Slaves中挑选一个“合适的”Slave提升为新的Master（挑选规则考虑优先级、复制偏移量、运行ID等）。</li><li>命令选出的Slave执行<code>SLAVEOF NO ONE</code>。</li><li>命令其余的Slaves执行<code>SLAVEOF new_master_ip new_master_port</code>，去复制新的Master。</li><li>更新原Master的配置（如果它恢复后），使其成为新Master的Slave。</li></ul></li><li><strong>INFO命令</strong>: Sentinel会以每10秒一次的频率向它已知的所有Master、Slave发送<code>INFO</code>命令获取其最新状态。 [cite: 146] 当Master被标记为ODOWN时，Sentinel向下线的Master的所有Slave发送INFO命令的频率会从10秒一次改为每秒一次。 [cite: 146]</li><li><strong>状态恢复</strong>: 若没有足够数量的Sentinel同意Master已经下线，Master的客观下线状态就会被移除。 [cite: 146] 若Master重新向Sentinel的PING命令返回有效回复，Master的主观下线状态也会被移除。 [cite: 147]</li></ol><p>通过哨兵模式，可以大大提高Redis服务的可用性，减少因主节点故障导致的服务中断时间。</p>"
                },
                {
                    "id": "redis-11",
                    "question": "11、Redis常见性能问题和解决方案",
                    "difficulty": "★",
                    "answer": "<p>Redis性能问题可能由多种因素引起，包括配置不当、使用模式不佳、硬件限制等。以下是一些常见性能问题及其解决方案：</p><ol><li><strong>Master持久化开销过大</strong>:<ul><li><strong>问题</strong>: 如果Master节点同时负责处理客户端请求和执行RDB快照或AOF重写等持久化操作，当数据量较大时，fork子进程进行持久化可能导致CPU和内存压力，甚至阻塞主进程，造成服务卡顿。</li><li><strong>解决方案</strong>:<ul><li>Master最好不要做任何持久化工作，或者只做轻量级的AOF（例如<code>appendfsync no</code>或<code>everysec</code>但需评估风险）。 [cite: 147]</li><li>将持久化任务（尤其是RDB快照和重量级的AOF同步）转移到专门的Slave节点上执行。</li></ul></li></ul></li><li><strong>AOF配置不当</strong>:<ul><li><strong>问题</strong>: <code>appendfsync always</code>策略虽然数据最安全，但每次写操作都同步刷盘，对性能影响最大。</li><li><strong>解决方案</strong>: 通常推荐使用<code>appendfsync everysec</code>，在性能和数据安全之间取得平衡。如果对数据丢失有一定容忍度，可以考虑<code>appendfsync no</code>，依赖操作系统刷盘。</li></ul></li><li><strong>主从复制延迟与风暴</strong>:<ul><li><strong>问题</strong>: Master和Slave之间网络延迟大或带宽不足，会导致复制延迟。如果Master压力很大时新增多个从库，或者多个从库同时进行全量同步，可能形成复制风暴，影响Master性能。</li><li><strong>解决方案</strong>:<ul><li>Master和Slave最好部署在同一个局域网内，保证低延迟和高带宽。 [cite: 148]</li><li>尽量避免在压力很大的主库上临时增加从库。 [cite: 148]</li><li>主从复制结构避免使用复杂的图状结构，推荐使用单向链表结构（如 Master &lt;- Slave1 &lt;- Slave2 ...）。 [cite: 148] 这种结构便于解决单点故障和Slave对Master的替换。如果Master挂了，可以较快地启用Slave1作为新的Master。 [cite: 148]</li></ul></li></ul></li><li><strong>Big Keys (大Key问题)</strong>:<ul><li><strong>问题</strong>: 存储过大的Key-Value对（例如一个String几十MB，一个Hash/List/Set包含数百万元素）会导致：<ul><li>分配和释放内存开销大，可能引发阻塞。</li><li>网络传输慢。</li><li>集群模式下数据迁移困难。</li><li>RDB/AOF时影响性能。</li></ul></li><li><strong>解决方案</strong>:<ul><li>拆分大Key：将一个大的对象或集合拆分成多个小的Key-Value对。</li><li>使用更合适的数据结构。</li><li>定期扫描和分析Big Key (如使用<code>redis-cli --bigkeys</code>)。</li></ul></li></ul></li><li><strong>热点Key问题</strong>:<ul><li><strong>问题</strong>: 某个Key被极高并发地访问，单线程的Redis处理能力可能成为瓶颈。</li><li><strong>解决方案</strong>:<ul><li>使用本地缓存（如应用内缓存）分担部分读压力。</li><li>将热点Key的数据复制多份到不同的Key中，请求时随机访问一个副本（需要应用层支持）。</li><li>对于写热点，可能需要更复杂的架构设计。</li></ul></li></ul></li><li><strong>内存达到上限 (maxmemory)</strong>:<ul><li><strong>问题</strong>: 当内存使用达到<code>maxmemory</code>限制时，如果没有配置合适的淘汰策略或淘汰速度跟不上写入速度，会导致写操作失败或Redis响应变慢。</li><li><strong>解决方案</strong>:<ul><li>合理设置<code>maxmemory</code>和<code>maxmemory-policy</code>（内存淘汰策略）。</li><li>监控内存使用情况，及时扩容或优化数据存储。</li></ul></li></ul></li><li><strong>大量短连接</strong>:<ul><li><strong>问题</strong>: 频繁地创建和关闭连接会消耗服务器资源和时间。</li><li><strong>解决方案</strong>: 使用连接池（Connection Pool）来复用连接。</li></ul></li><li><strong>不当使用慢命令</strong>:<ul><li><strong>问题</strong>: 某些命令（如<code>KEYS *</code>, <code>FLUSHALL</code>, <code>FLUSHDB</code>, 对大集合的<code>SMEMBERS</code>, <code>LRANGE 0 -1</code>等）在数据量大时执行时间可能很长，会阻塞其他命令。</li><li><strong>解决方案</strong>:<ul><li>避免在生产环境中使用<code>KEYS *</code>，改用<code>SCAN</code>命令。</li><li>谨慎使用<code>FLUSHALL</code>/<code>FLUSHDB</code>。</li><li>操作大集合时，考虑分批操作或使用<code>SSCAN</code>, <code>HSCAN</code>, <code>ZSCAN</code>。</li></ul></li></ul></li><li><strong>CPU使用率过高（非预期）</strong>:<ul><li><strong>问题</strong>: 除了正常的命令处理，可能是由于复杂的Lua脚本、排序操作、大量的计算密集型命令等。</li><li><strong>解决方案</strong>: 优化Lua脚本，避免在Redis中执行过多复杂计算，考虑将计算任务移到客户端。</li></ul></li></ol>"
                },
                {
                    "id": "redis-12",
                    "question": "12、MySQL里有大量数据,如何保证Redis中的数据都是热点数据",
                    "difficulty": "★★",
                    "answer": "<p>保证Redis中缓存的数据主要是热点数据，对于提高缓存命中率、充分利用Redis的内存资源至关重要。当MySQL中有大量数据时，不可能全部放入Redis。以下是一些策略和方法：</p><ol><li><strong>惰性加载 (Lazy Loading / Cache-Aside Pattern)</strong>:<ul><li><strong>原理</strong>: 当应用程序需要读取数据时，首先尝试从Redis中获取。如果Redis中不存在（缓存未命中），则从MySQL中查询数据，然后将查询结果存入Redis，并设置一个合理的过期时间。</li><li><strong>优点</strong>: 简单易实现，只有被实际访问到的数据才会被缓存，确保了加载到缓存中的数据是“至少被访问过一次”的。</li><li><strong>缺点</strong>: 首次访问某个数据时，由于缓存未命中，会有一次数据库查询的延迟。如果某个key突然变热，可能会有缓存击穿的风险（多个请求同时未命中，都去查库）。</li></ul></li><li><strong>数据预热 (Cache Pre-warming / Cache Priming)</strong>:<ul><li><strong>原理</strong>: 在系统启动时，或者在低峰期，根据业务预测或历史访问数据，主动将一些即将或经常被访问的热点数据提前加载到Redis中。</li><li><strong>优点</strong>: 避免了首次访问的冷启动延迟，提高了初始阶段的缓存命中率。</li><li><strong>缺点</strong>: 需要准确预测热点数据，否则可能缓存了非热点数据，浪费内存。数据预热本身也需要时间和资源。</li></ul></li><li><strong>读写策略结合（如Read-Through/Write-Through）</strong>:<ul><li>虽然不是直接保证热点，但这些模式下数据的读写都经过缓存，有助于保持缓存中数据的“新鲜度”和相关性。</li></ul></li><li><strong>合理设置缓存过期策略和时间</strong>:<ul><li>为不同的数据设置不同的过期时间。访问频率高、变动不频繁的热点数据可以设置较长的过期时间；访问频率一般或变动频繁的数据可以设置较短的过期时间或不缓存。</li><li>使用Redis的内存淘汰策略来辅助管理。</li></ul></li><li><strong>Redis内存淘汰策略 (Maxmemory Policy)</strong>:<ul><li>当Redis内存达到<code>maxmemory</code>限制时，会根据配置的淘汰策略来移除部分数据，为新数据腾出空间。选择合适的淘汰策略有助于保留热点数据： [cite: 148]<ul><li><strong><code>volatile-lru</code></strong>: (Least Recently Used - 最近最少使用) 尝试回收设置了过期时间的键中，最长时间未被使用的键。 [cite: 148]</li><li><strong><code>allkeys-lru</code></strong>: 尝试回收所有键中（无论有无过期时间），最长时间未被使用的键。<strong>这是常用的保留热点数据的策略</strong>。 [cite: 148]</li><li><strong><code>volatile-lfu</code></strong>: (Least Frequently Used - 最不经常使用，Redis 4.0+引入) 尝试回收设置了过期时间的键中，在一段时间内使用频率最低的键。</li><li><strong><code>allkeys-lfu</code></strong>: (Redis 4.0+引入) 尝试回收所有键中，在一段时间内使用频率最低的键。<strong>这也是保留热点数据的好策略</strong>。</li><li><code>volatile-ttl</code>: 回收设置了过期时间的键中，剩余存活时间（TTL）最短的键。 [cite: 148]</li><li><code>allkeys-random</code>: 随机回收键。 [cite: 148]</li><li><code>volatile-random</code>: 随机回收设置了过期时间的键。 [cite: 148]</li><li><code>noeviction</code> (默认): 不进行数据淘汰。当内存达到限制时，写操作会返回错误。 [cite: 148]</li></ul></li><li>选择<code>allkeys-lru</code>或<code>allkeys-lfu</code>通常能较好地将访问频率较低（LRU）或访问次数较少（LFU）的数据淘汰出去，从而间接保留热点数据。</li></ul></li><li><strong>监控和分析访问模式</strong>:<ul><li>通过日志分析、应用监控或Redis自身的监控命令（如<code>MONITOR</code>，慎用；<code>INFO commandstats</code>）来识别真正的热点数据。</li><li>根据分析结果动态调整哪些数据应该被缓存、预热，以及它们的过期时间。</li></ul></li><li><strong>应用层逻辑判断</strong>:<ul><li>在应用层面，可以根据业务逻辑判断某些数据是否属于热点（例如，热门商品、活跃用户信息），并优先将其放入缓存或给予更长的缓存时间。</li></ul></li></ol><p>通常是多种策略结合使用，例如以惰性加载为基础，对已知的核心热点数据进行预热，并配置合适的LRU/LFU淘汰策略。</p>"
                },
                {
                    "id": "redis-13",
                    "question": "13、Redis集群方案应该怎么做都有哪些方案",
                    "difficulty": "★★",
                    "answer": "<p>当单个Redis实例的内存容量、并发处理能力或数据安全性无法满足需求时，就需要考虑Redis集群方案。主要的集群方案有：</p><ol><li><strong>主从复制 (Master-Slave Replication)</strong>:<ul><li><strong>特点</strong>: 一个Master节点，一个或多个Slave节点。Master负责处理写操作，并将数据变更异步复制到Slave节点。Slave节点通常负责处理读操作（读写分离），也可以作为Master故障时的备份。</li><li><strong>优点</strong>: 实现简单，提高读性能和数据冗余。</li><li><strong>缺点</strong>: 写操作仍在Master上，未解决写瓶颈和单点故障问题（Master故障需要手动或配合Sentinel进行切换）。不具备自动故障转移能力（除非配合Sentinel）。</li></ul></li><li><strong>哨兵模式 (Redis Sentinel)</strong>:<ul><li><strong>特点</strong>: 在主从复制的基础上，引入一个或多个Sentinel进程（通常至少3个以形成多数派）来监控主从节点的健康状况。当Master故障时，Sentinel会自动选举一个Slave提升为新的Master，并通知客户端和其余Slave。</li><li><strong>优点</strong>: 提供了自动故障转移，提高了系统可用性。</li><li><strong>缺点</strong>: 本质上仍是主从架构，写操作压力仍在单Master上。每个Sentinel也需要资源。配置相对复杂一些。数据分片仍需客户端或代理实现。</li></ul></li><li><strong>Redis Cluster (官方集群方案, Redis 3.0+)</strong>:<ul><li><strong>特点</strong>: 去中心化的分布式集群方案。数据通过哈希槽（Hash Slot，共16384个）自动分片到多个Master节点上，每个Master节点可以有自己的Slave节点用于高可用。节点间通过Gossip协议进行通信和状态同步。客户端连接集群中任意节点即可，节点会自动将请求路由到正确的节点。 [cite: 148]</li><li><strong>优点</strong>: 实现了数据的自动分片和水平扩展（横向扩展），支持高可用（每个分片可有副本），去中心化。</li><li><strong>缺点</strong>: 实现相对复杂。批量操作多个key时，如果这些key不在同一个slot，则不支持（例如MSET, MGET，但可以使用如Redis Cluster的Smart Client库在客户端层面聚合）。事务操作也受限。</li></ul></li><li><strong>客户端分片 (Client-Side Sharding)</strong>:<ul><li><strong>特点</strong>: 在应用程序客户端层面实现数据分片逻辑。客户端根据一定的路由算法（如一致性哈希）将不同的key映射到不同的Redis实例上。这些Redis实例可以是独立的，也可以是各自的主从/哨兵集群。 [cite: 148]</li><li><strong>优点</strong>: 实现灵活，对Redis服务端无特殊要求。</li><li><strong>缺点</strong>: 分片逻辑耦合在客户端，不易统一管理和维护。增减节点时数据迁移和再平衡比较麻烦。 [cite: 148]</li></ul></li><li><strong>代理分片 (Proxy-Based Sharding)</strong>:<ul><li><strong>特点</strong>: 在应用和Redis实例之间引入一个代理层。应用将请求发送给代理，代理负责根据分片规则将请求路由到正确的Redis实例，并将结果返回给应用。</li><li><strong>常见代理</strong>:<ul><li><strong>Twemproxy (nutcracker)</strong>: Twitter开源的Redis/Memcached代理。使用一致性哈希，支持连接池。优点是使用简便，对旧项目扩展友好。缺点是自身可能成为单点瓶颈（需要高可用部署代理），增减节点时数据无法自动迁移到新节点。 [cite: 148]</li><li><strong>Codis</strong>: 国内团队开源的分布式Redis解决方案。它也使用代理，但支持在线数据迁移和动态扩缩容，对应用透明。架构比Twemproxy复杂。 [cite: 148]</li></ul></li><li><strong>优点</strong>: 分片逻辑对应用透明，便于管理。可以实现更复杂的路由和治理功能。</li><li><strong>缺点</strong>: 引入了代理层，增加了网络跳数和潜在的性能开销。代理本身也需要高可用。</li></ul></li></ol><p><strong>选择方案的考虑因素</strong>:</p><ul><li><strong>数据量和QPS</strong>: 评估是否需要数据分片。</li><li><strong>可用性要求</strong>: 是否需要自动故障转移。</li><li><strong>运维复杂度</strong>: 不同方案的部署和维护复杂度不同。</li><li><strong>现有架构和业务需求</strong>: 是否能接受客户端改造，是否需要事务支持的程度等。</li></ul><p>目前，对于需要高可用和数据分片的场景，<strong>Redis Cluster</strong> 和基于代理的方案（如<strong>Codis</strong>，或自行搭建并管理）是比较主流的选择。<strong>Sentinel</strong>则主要用于解决主从复制的自动故障转移问题。</p>"
                },
                {
                    "id": "redis-14",
                    "question": "14、说说Redis哈希槽的概念",
                    "difficulty": "★★",
                    "answer": "<p>哈希槽（Hash Slot）是Redis Cluster（官方集群方案，从Redis 3.0开始引入）用于实现数据分片和节点管理的核心概念。</p><p><strong>基本概念：</strong></p><ol><li><strong>总数固定</strong>: Redis Cluster预设了固定的<strong>16384个哈希槽</strong> (编号从 0 到 16383)。 [cite: 148]</li><li><strong>数据映射到槽</strong>:<ul><li>当一个key需要存储到Redis Cluster中时，集群会对这个key计算一个CRC16校验和。 [cite: 148]</li><li>然后，将这个CRC16值对16384进行取模运算 (<code>CRC16(key) % 16384</code>)，得到的结果就是这个key应该被分配到的哈希槽的编号。 [cite: 148]</li></ul></li><li><strong>槽分配给节点</strong>:<ul><li>集群中的每个主节点（Master Node）会负责管理这16384个哈希槽的一部分。 [cite: 148]</li><li>例如，在一个有3个主节点的集群中，可能：<ul><li>节点A负责槽 0 - 5460</li><li>节点B负责槽 5461 - 10922</li><li>节点C负责槽 10923 - 16383</li></ul></li><li>这种槽到节点的映射关系是在集群创建时确定的，并且在集群运行过程中可以动态调整（例如增减节点时进行槽的迁移）。</li></ul></li><li><strong>客户端路由</strong>:<ul><li>客户端连接到集群中的任意一个节点。当客户端发送一个关于某个key的命令时：<ul><li>如果该key所属的哈希槽正好由当前连接的节点负责，则该节点直接处理命令。</li><li>如果该key所属的哈希槽不由当前节点负责，该节点会向客户端返回一个<code>-MOVED</code>重定向错误，告知客户端这个key实际应该由哪个节点（IP和端口）处理。</li><li>智能客户端（Smart Client）会缓存槽和节点的映射关系，并根据<code>-MOVED</code>指令更新本地映射，后续直接将命令发送到正确的节点。</li></ul></li></ul></li></ol><p><strong>为什么是16384个槽？</strong></p><ul><li>这个数量不大不小。如果槽太多（如百万级别），节点间同步槽信息（心跳包中会携带槽信息）的开销会很大。如果槽太少，数据分片的粒度不够细，不利于灵活的数据迁移和负载均衡。16384 (即 $2^{14}$) 是一个折中的选择。</li><li>节点数量通常不会非常多（官方建议不要超过1000个节点），16384个槽足够分配。</li></ul><p><strong>与一致性哈希的区别：</strong></p><ul><li>Redis Cluster没有直接使用一致性哈希算法，而是使用了哈希槽这种更直接的映射方式。 [cite: 148]</li><li>一致性哈希的节点增减影响的是环上的一小段数据，而哈希槽模式下，增减节点时需要明确地迁移槽及其中的数据。</li></ul><p><strong>优点：</strong></p><ul><li><strong>数据分布相对均匀</strong>: 通过CRC16和取模，key可以较为均匀地分布到各个槽中。</li><li><strong>便于管理和迁移</strong>: 以槽为单位进行数据迁移和节点管理，操作相对清晰。</li><li><strong>去中心化</strong>: 节点间通过Gossip协议维护集群状态和槽的分配信息。</li></ul><p>通过哈希槽机制，Redis Cluster实现了数据的自动分片和高可用性，使得Redis能够支持更大规模的数据存储和更高的并发访问。</p>"
                },
                {
                    "id": "redis-15",
                    "question": "15、Redis有哪些适合的场景",
                    "difficulty": "★",
                    "answer": "<p>Redis因其高性能、丰富的数据结构和多种特性，非常适合应用于多种场景：</p><ol><li><strong>会话缓存 (Session Cache)</strong>:<ul><li>这是最常用的场景之一。将用户的会话信息（如登录状态、购物车）存储在Redis中，可以加快会话的读取速度，减轻应用服务器的压力。 [cite: 148]</li><li>相比其他缓存（如Memcached），Redis提供的持久化选项能更好地保证会话数据在服务重启后的可用性。 [cite: 148, 149]</li></ul></li><li><strong>全页缓存 (Full Page Cache - FPC)</strong>:<ul><li>缓存整个渲染好的HTML页面内容。当用户再次请求相同页面时，可以直接从Redis返回，极大提高页面加载速度。 [cite: 149]</li><li>对于内容不经常变化的静态或半静态页面非常有效。</li></ul></li><li><strong>数据缓存 (Data Cache)</strong>:<ul><li>缓存数据库查询结果、外部API调用结果等热点数据，减少对后端数据源的访问压力，提升应用响应速度。</li></ul></li><li><strong>消息队列 (Message Queue)</strong>:<ul><li>利用Redis的List数据结构（如<code>LPUSH</code>/<code>RPOP</code>实现FIFO队列，或<code>LPUSH</code>/<code>BRPOP</code>实现阻塞读的可靠队列）或Stream类型（Redis 5.0+，功能更完善的消息队列）可以构建轻量级的消息队列系统。 [cite: 149]</li><li>适用于任务分发、异步处理、削峰填谷等场景。</li></ul></li><li><strong>排行榜 / 计数器 (Leaderboards / Counters)</strong>:<ul><li>利用Redis的Sorted Set (zset) 数据结构，可以非常方便地实现带有分数的排行榜功能（如游戏积分榜、热榜）。<code>ZADD</code>添加分数，<code>ZRANGE</code>/<code>ZREVRANGE</code>获取排名。 [cite: 150]</li><li>利用String类型的原子增减操作（如<code>INCR</code>, <code>DECR</code>, <code>INCRBY</code>）可以实现高性能的计数器（如网站PV/UV统计、点赞数、库存计数等）。</li></ul></li><li><strong>发布/订阅 (Publish/Subscribe)</strong>:<ul><li>Redis提供了发布/订阅功能，可以用于构建实时的消息系统、事件通知、聊天系统等。 [cite: 150]</li><li>客户端可以订阅一个或多个频道，发布者向频道发布消息后，所有订阅该频道的客户端都会收到消息。</li></ul></li><li><strong>分布式锁 (Distributed Lock)</strong>:<ul><li>利用Redis的<code>SETNX</code> (SET if Not eXists) 命令或更完善的Redlock算法等，可以实现分布式锁，用于控制分布式环境下对共享资源的互斥访问。</li></ul></li><li><strong>地理空间索引 (Geospatial Indexing)</strong>:<ul><li>Redis的Geo类型（Redis 3.2+）支持存储地理位置信息（经纬度），并能进行基于位置的查询（如查找附近的人/地点、计算两点间距离等）。</li></ul></li><li><strong>实时数据分析/基数统计</strong>:<ul><li>利用Bitmaps可以进行用户签到、活跃用户统计等。</li><li>利用HyperLogLogs可以用极小的内存估算大数据集的基数（不重复元素的数量）。</li></ul></li><li><strong>限流器 (Rate Limiter)</strong>:<ul><li>结合Redis的计数器和过期时间特性，可以实现接口访问频率的限制。</li></ul></li></ol><p>选择Redis作为解决方案时，需要考虑其内存限制和数据持久化策略是否满足业务需求。</p>"
                },
                {
                    "id": "redis-16",
                    "question": "16、Redis在项目中的应用",
                    "difficulty": "★",
                    "answer": "<p>Redis在项目中的应用非常广泛，具体使用场景需要结合项目的实际需求来谈。以下是一些典型的应用方面，你可以根据自己项目的特点进行阐述：</p><ol><li><strong>作为缓存层，提升系统性能</strong>:<ul><li><strong>缓存热点数据</strong>: 将数据库中频繁访问的数据（如商品信息、用户信息、配置信息、首页聚合数据等）缓存到Redis中。当请求到达时，先查询Redis，如果命中则直接返回，减少对数据库的直接访问，降低数据库压力，显著提高系统响应速度。 [cite: 150]</li><li><strong>缓存计算结果</strong>: 对于一些计算成本较高但结果相对稳定的数据，可以将计算结果缓存起来，避免重复计算。</li><li><strong>会话管理</strong>: 在分布式Web应用中，使用Redis存储用户Session信息，实现Session共享和快速读取。</li></ul></li><li><strong>实现分布式锁，保证并发操作的正确性</strong>:<ul><li><strong>场景</strong>: 例如，防止缓存击穿（热点key失效时，只允许一个请求去加载数据）、秒杀系统中控制超卖、定时任务的互斥执行等。 [cite: 150]</li><li><strong>实现</strong>: 通常使用Redis的<code>SETNX</code>命令（SET if Not eXists）配合过期时间来实现。也可以使用更完善的分布式锁算法如Redlock，或者基于Lua脚本实现更复杂的锁逻辑。</li></ul></li><li><strong>作为消息队列，实现异步处理和系统解耦</strong>:<ul><li><strong>场景</strong>: 例如，用户注册后的邮件发送、订单创建后的短信通知、日志收集与分析、耗时任务的异步执行等。 [cite: 150]</li><li><strong>实现</strong>: 利用Redis的List数据结构（如<code>LPUSH</code>生产者推入任务，<code>BRPOP</code>消费者阻塞获取任务）或Stream类型（更专业的消息队列功能）。</li><li><strong>优点</strong>: 轻量、快速，适用于对消息可靠性要求不是特别严苛的场景。</li></ul></li><li><strong>实现特定业务功能</strong>:<ul><li><strong>排行榜</strong>: 使用Sorted Set (zset) 实现如用户积分榜、商品销量榜、热门帖子排行等。</li><li><strong>计数器</strong>: 使用String类型的<code>INCR</code>, <code>DECR</code>命令实现如文章阅读数、点赞数、API调用次数统计、库存数量控制等。</li><li><strong>用户签到/活跃统计</strong>: 使用Bitmaps实现每日用户签到、统计月活跃用户等。</li><li><strong>附近的人/地点</strong>: 使用Geospatial (geo) 类型实现LBS应用中的位置相关查询。</li><li><strong>限流</strong>: 结合计数器和过期时间，实现对接口访问频率的限制。</li><li><strong>存储短期令牌或验证码</strong>: 利用Redis的过期特性存储如短信验证码、登录Token等。</li></ul></li></ol><p><strong>在面试中回答这个问题时，建议：</strong></p><ul><li><strong>结合具体项目</strong>: 不要泛泛而谈，最好能结合你参与过的实际项目，说明在哪个模块、为了解决什么问题、是如何使用Redis的。</li><li><strong>说明选型理由</strong>: 为什么选择Redis而不是其他技术（如Memcached, RabbitMQ等）来实现这个功能？（例如，Redis的数据结构更丰富，支持持久化，性能满足需求等）。</li><li><strong>遇到的问题及解决方案 (加分项)</strong>: 如果在使用Redis过程中遇到过一些问题（如缓存穿透、雪崩、数据一致性、大Key问题等），并说明了如何解决的，会更有说服力。</li><li><strong>量化效果 (如果可能)</strong>: 如果能用数据说明引入Redis后带来的性能提升（如QPS提升、响应时间降低等），效果会更好。</li></ul><p>例如，你可以说：“在我们之前的电商项目中，我们将商品详情页的数据（如商品基本信息、规格、库存、评论数等）缓存在Redis中。因为这些数据访问频率非常高，通过缓存，我们将这部分请求的响应时间从平均200ms降低到了20ms以内，数据库的压力也显著减小。我们还使用了Redis的Sorted Set来实现商品的热销排行榜功能...”</p>"
                }
            ]
        },
        {
            "chapterTitle": "后续内容根据情况补充项目相关...",
            "questions": [{
                "id": "敬请期待",
                "question": "敬请期待",
                "difficulty": "★",
                "answer": "敬请期待"
            },
            ]
        }
        


        ];

        const chapterNavList = document.getElementById('chapter-nav-list');
        const questionsContainer = document.getElementById('questions-container');
        const currentChapterTitle = document.getElementById('current-chapter-title');
        const appContainer = document.getElementById('app-container');
        const toggleSidebarDesktopBtn = document.getElementById('toggle-sidebar-desktop');
        const toggleSidebarMobileBtn = document.getElementById('toggle-sidebar-mobile');
        const searchInput = document.getElementById('search-input');
        const noResultsMessage = document.getElementById('no-results-message');

        const aiModal = document.getElementById('ai-modal');
        const aiModalTitle = document.getElementById('ai-modal-title');
        const aiModalBody = document.getElementById('ai-modal-body');
        const closeAiModalBtn = document.getElementById('close-ai-modal');
        const aiLoadingSpinner = document.getElementById('ai-loading-spinner');

        let allQuestions = []; // To store all questions for searching

        function escapeHtml(unsafe) {
            if (typeof unsafe !== 'string') return '';
            return unsafe
                 .replace(/&/g, "&amp;")
                 .replace(/</g, "&lt;")
                 .replace(/>/g, "&gt;")
                 .replace(/"/g, "&quot;")
                 .replace(/'/g, "&#039;");
        }

        function formatAnswerForDisplay(answerHtml) {
            let formatted = answerHtml;
            // Order matters: first specific (```java), then generic (```)
            formatted = formatted.replace(/```java\n([\s\S]*?)\n```/g, (match, p1) => `<div class="code-block"><code>${escapeHtml(p1.trim())}</code></div>`);
            formatted = formatted.replace(/```xml\n([\s\S]*?)\n```/g, (match, p1) => `<div class="code-block"><code>${escapeHtml(p1.trim())}</code></div>`);
            formatted = formatted.replace(/```sql\n([\s\S]*?)\n```/g, (match, p1) => `<div class="code-block"><code>${escapeHtml(p1.trim())}</code></div>`);
            formatted = formatted.replace(/```bash\n([\s\S]*?)\n```/g, (match, p1) => `<div class="code-block"><code>${escapeHtml(p1.trim())}</code></div>`);
            formatted = formatted.replace(/```\n([\s\S]*?)\n```/g, (match, p1) => `<div class="code-block"><code>${escapeHtml(p1.trim())}</code></div>`);
            
            formatted = formatted.replace(/<pre><code>([\s\S]*?)<\/code><\/pre>/g, (match, p1) => `<div class="code-block"><code>${p1.trim()}</code></div>`);
            formatted = formatted.replace(/<pre>([\s\S]*?)<\/pre>/g, (match, p1) => `<div class="code-block"><code>${p1.trim()}</code></div>`);
            return formatted;
        }


        function renderChapters() {
            chapterNavList.innerHTML = ''; 
            allQuestions = []; 
            manualData.forEach((chapter, index) => {
                const listItem = document.createElement('li');
                const link = document.createElement('a');
                link.href = '#';
                link.textContent = chapter.chapterTitle;
                link.classList.add('block', 'py-2', 'px-3', 'rounded-md', 'hover:bg-slate-700', 'transition-colors', 'duration-150', 'sidebar-link');
                link.dataset.chapterIndex = index;
                link.addEventListener('click', (e) => {
                    e.preventDefault();
                    loadChapter(index);
                    if (window.innerWidth < 1024) {
                        appContainer.classList.add('sidebar-collapsed');
                    }
                    document.querySelectorAll('.sidebar-link').forEach(l => l.classList.remove('active'));
                    link.classList.add('active');
                });
                listItem.appendChild(link);
                chapterNavList.appendChild(listItem);

                chapter.questions.forEach(q => {
                    allQuestions.push({ ...q, chapterTitle: chapter.chapterTitle, chapterIndex: index });
                });
            });
        }

        function getDifficultyStars(difficultyString) {
            let stars = '';
            if (difficultyString) {
                const numStars = difficultyString.replace(/[^★]/g, "").length;
                for (let i = 0; i < numStars; i++) {
                    stars += '★';
                }
                 for (let i = numStars; i < 3; i++) { 
                    stars += '<span class="text-slate-400">☆</span>';
                }
            }
            return stars;
        }

        function displayQuestions(questionsToDisplay, chapterTitle = "搜索结果") {
            questionsContainer.innerHTML = '';
            currentChapterTitle.textContent = chapterTitle;
            noResultsMessage.classList.add('hidden');

            if (questionsToDisplay.length === 0) {
                if(searchInput.value.trim() !== "") {
                     noResultsMessage.classList.remove('hidden');
                } else if (chapterTitle !== "欢迎使用面试背诵手册" && chapterTitle !== "搜索结果") {
                     questionsContainer.innerHTML = '<p class="text-slate-600">本章节暂无问题。</p>';
                } else if (chapterTitle === "搜索结果" && searchInput.value.trim() === "") {
                     questionsContainer.innerHTML = '<p class="text-slate-600 text-lg">请从左侧选择一个章节开始学习，或使用上方搜索框查找问题。</p>';
                }
                return;
            }

            questionsToDisplay.forEach(q => {
                const questionDiv = document.createElement('div');
                questionDiv.classList.add('bg-white', 'p-4', 'sm:p-6', 'rounded-lg', 'shadow-lg', 'hover:shadow-xl', 'transition-shadow', 'duration-300');
                
                const answerTextForAI = q.answer.replace(/<[^>]*>/g, ' ').replace(/\s+/g, ' ').trim();
                const displayAnswerHtml = formatAnswerForDisplay(q.answer);

                questionDiv.innerHTML = `
                    <div class="flex justify-between items-start cursor-pointer question-header">
                        <h3 class="text-lg sm:text-xl font-semibold text-slate-700">${q.question}</h3>
                        <div class="flex items-center ml-2 flex-shrink-0">
                            <span class="text-sm difficulty-star mr-2">${getDifficultyStars(q.difficulty)}</span>
                            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" class="w-5 h-5 text-sky-500 transform transition-transform duration-300 chevron">
                                <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5" />
                            </svg>
                        </div>
                    </div>
                    <div class="mt-3 flex flex-wrap gap-2 items-center">
                        <button class="ai-button btn-ai-explain">AI深入解释 ✨</button>
                        <button class="ai-button btn-ai-related-questions">AI出相关题 ✨</button>
                    </div>
                    <div class="answer mt-3 pt-3 pl-4">
                        ${displayAnswerHtml}
                        <button class="ai-button btn-ai-summarize-answer mt-3">AI总结答案 ✨</button>
                    </div>
                `;
                questionsContainer.appendChild(questionDiv);

                const header = questionDiv.querySelector('.question-header');
                const answerDiv = questionDiv.querySelector('.answer');
                const chevron = questionDiv.querySelector('.chevron');
                const btnSummarize = questionDiv.querySelector('.btn-ai-summarize-answer');
                btnSummarize.style.display = 'none'; 

                header.addEventListener('click', () => {
                    answerDiv.classList.toggle('active');
                    chevron.classList.toggle('rotate-180');
                    btnSummarize.style.display = answerDiv.classList.contains('active') ? 'inline-block' : 'none';
                });

                questionDiv.querySelector('.btn-ai-explain').addEventListener('click', () => {
                    handleAIInteraction('explain', q.question, answerTextForAI);
                });
                questionDiv.querySelector('.btn-ai-related-questions').addEventListener('click', () => {
                    handleAIInteraction('related_questions', q.question);
                });
                btnSummarize.addEventListener('click', () => {
                    handleAIInteraction('summarize', answerTextForAI);
                });
            });
        }
        
        function loadChapter(chapterIndex) {
            const chapter = manualData[chapterIndex];
            if (chapter) {
                displayQuestions(chapter.questions, chapter.chapterTitle);
                searchInput.value = '';
            }
        }

        function handleSearch() {
            const searchTerm = searchInput.value.trim().toLowerCase();
            if (searchTerm === "") {
                const activeLink = document.querySelector('.sidebar-link.active');
                if (activeLink) {
                    loadChapter(parseInt(activeLink.dataset.chapterIndex));
                } else {
                    questionsContainer.innerHTML = '<p class="text-slate-600 text-lg">请从左侧选择一个章节开始学习，或使用上方搜索框查找问题。</p>';
                    currentChapterTitle.textContent = "欢迎使用面试背诵手册";
                    noResultsMessage.classList.add('hidden');
                }
                return;
            }
            const filteredQuestions = allQuestions.filter(q => 
                q.question.toLowerCase().includes(searchTerm) || 
                (q.answer && q.answer.toLowerCase().includes(searchTerm))
            );
            displayQuestions(filteredQuestions, `关于 "${searchTerm}" 的搜索结果`);
        }

        function toggleSidebar() {
            appContainer.classList.toggle('sidebar-collapsed');
        }

        toggleSidebarDesktopBtn.addEventListener('click', toggleSidebar);
        toggleSidebarMobileBtn.addEventListener('click', toggleSidebar);
        searchInput.addEventListener('input', handleSearch);

        function openAiModal(title) {
            aiModalTitle.textContent = title;
            aiModalBody.innerHTML = '';
            aiLoadingSpinner.classList.remove('hidden');
            aiModal.classList.remove('hidden');
            document.body.style.overflow = 'hidden';
        }

        function closeAiModal() {
            aiModal.classList.add('hidden');
            aiLoadingSpinner.classList.add('hidden');
            document.body.style.overflow = '';
        }
        closeAiModalBtn.addEventListener('click', closeAiModal);
        aiModal.addEventListener('click', (e) => {
            if (e.target === aiModal) {
                closeAiModal();
            }
        });
        
        async function callDeepSeekAPI(prompt) {
            // 1. 将 YOUR_DEEPSEEK_API_KEY 替换为你的 DeepSeek API 密钥
            const apiKey = "sk-9df4a7e8d372410f86c8c35f6cbc1527";

            // 2. 这是 DeepSeek API 的通用端点，请确认是否为最新或适用于你的模型
            const apiUrl = "https://api.deepseek.com/v1/chat/completions";

            // 3. 构建符合 OpenAI/DeepSeek 格式的请求体
            const payload = {
                // 4. 选择你希望使用的 DeepSeek 模型，例如 "deepseek-chat" 或 "deepseek-coder"
                model: "deepseek-chat",
                messages: [
                    { role: "user", content: prompt }
                    // 如果你的应用维护了聊天历史，可以在这里加入更多消息：
                    // { role: "assistant", content: "Previous AI response" },
                    // { role: "user", content: "Another user prompt" }
                ]
                // 你也可以在这里添加其他参数，如 temperature, max_tokens 等
                // "temperature": 0.7,
                // "max_tokens": 1000
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        // 5. DeepSeek/OpenAI 使用 Bearer Token 进行认证
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    console.error("API Error Data:", errorData); // 打印详细错误信息
                    let errorMessage = `API请求失败: ${response.status} ${response.statusText}.`;
                    if (errorData.error && errorData.error.message) {
                        errorMessage += ` 详情: ${errorData.error.message}`;
                    } else if (typeof errorData.detail === 'string') { // 有些API错误信息在 detail 字段
                        errorMessage += ` 详情: ${errorData.detail}`;
                    } else {
                        errorMessage += ` 详情: 未知错误。`;
                    }
                    return errorMessage;
                }

                const result = await response.json();

                // 6. 解析符合 OpenAI/DeepSeek 格式的响应
                if (result.choices && result.choices.length > 0 && result.choices[0].message && result.choices[0].message.content) {
                    return result.choices[0].message.content;
                } else {
                    console.error("Unexpected API response structure:", result);
                    return "未能从AI获取有效回复（响应结构不符合预期）。";
                }
            } catch (error) {
                console.error("Fetch Error:", error);
                return `请求AI服务时发生网络错误: ${error.message}`;
            }
        }
        
        function formatAIResponse(text) {
            let html = text.split('\n\n').map(paragraph => `<p>${paragraph.replace(/\n/g, '<br>')}</p>`).join('');
            
            html = html.replace(/<p>\* (.*?)<\/p>/g, '<li>$1</li>'); // Unordered list item
            html = html.replace(/<li>([\s\S]*?)<\/li>(?=(<li>|<\/ul>))/g, '<li>$1</li>'); // Ensure proper list structure
            html = html.replace(/(<li>.*?<\/li>)/g, '<ul>$1</ul>').replace(/<\/ul><\/p><p><ul>/g, '').replace(/<\/ul><ul>/g, ''); // Group LIs

            html = html.replace(/<p>([0-9]+\.) (.*?)<\/p>/g, '<li>$2</li>'); // Ordered list item
            html = html.replace(/<li>([\s\S]*?)<\/li>(?=(<li>|<\/ol>))/g, '<li>$1</li>');
            html = html.replace(/(<li>.*?<\/li>)/g, '<ol>$1</ol>').replace(/<\/ol><\/p><p><ol>/g, '').replace(/<\/ol><ol>/g, '');


            html = html.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>'); 
            html = html.replace(/\*(.*?)\*/g, '<em>$1</em>'); 

            html = html.replace(/<p><\/p>/g, '');
            return html;
        }


        // 新的或修改后的函数，使用 Marked.js
        function formatAIResponseWithMarked(markdownText) {
            if (typeof marked === 'function') {
                // marked.parse() 会将 Markdown 文本转换为 HTML 字符串
                // 你可以根据需要配置 marked 的选项，例如启用 GFM (GitHub Flavored Markdown) 等
                marked.setOptions({ gfm: true, breaks: true }); // 示例：启用GFM和自动换行
                return marked.parse(markdownText.trim());
            } else {
                console.error("Marked.js library not loaded!");
                // 如果 Marked.js 加载失败，可以回退到简单的文本显示或旧的正则处理
                return `<p>Error: Markdown library not loaded. Displaying raw text:</p><pre>${escapeHtml(markdownText)}</pre>`;
            }
        }
        

        async function handleAIInteraction(type, ...args) {
            let prompt = "";
            let modalTitle = "AI助手";

            if (type === 'explain') {
                const [question, answer] = args;
                prompt = `请用中文详细解释以下面试问题及其概念。如果已有答案，请在此基础上进行补充或用不同角度解释。注意言简意赅。\n问题: "${question}"\n已有答案参考: "${answer}"\n请提供言简意赅的解释，使用可以在html展示的形式，易于阅读：`; // 提示AI使用Markdown
                modalTitle = "AI深入解释 ✨";
            } else if (type === 'related_questions') {
                const [question] = args;
                prompt = `针对以下面试问题: "${question}", 请用中文生成3-5个相关的、可以进一步考察理解深度的面试问题。请直接列出问题，每个问题一行，使用数字编号和可以在html展示的形式。`; // 提示AI使用Markdown
                modalTitle = "AI生成相关问题 ✨";
            } else if (type === 'summarize') {
                const [answerText] = args;
                if (!answerText || answerText.trim().length < 30) { 
                    openAiModal("提示");
                    aiModalBody.innerHTML = "<p>答案内容较短，无需AI总结。</p>";
                    aiLoadingSpinner.classList.add('hidden');
                    return;
                }
                prompt = `请用中文总结以下答案的核心要点，使其更易于记忆，使用1-3个要点的可以在html展示的形式呈现:\n"${answerText}"\n总结应简洁明了。`; // 提示AI使用Markdown
                modalTitle = "AI总结答案 ✨";
            }

            openAiModal(modalTitle);
            const aiResponse = await callDeepSeekAPI(prompt);
            aiLoadingSpinner.classList.add('hidden');
            aiModalBody.innerHTML = formatAIResponseWithMarked(aiResponse);
        }

        renderChapters();
        if (manualData.length > 0) {
        }

        if (window.innerWidth < 1024) {
            appContainer.classList.add('sidebar-collapsed');
        }
    </script>
</body>
</html>
